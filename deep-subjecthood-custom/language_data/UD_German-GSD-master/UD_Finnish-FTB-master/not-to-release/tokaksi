#! /usr/bin/env python3
# -*- mode: Python; -*-

# http://universaldependencies.org/v2/summary.html

from argparse import ArgumentParser
from itertools import groupby

import signal
signal.signal(signal.SIGINT, signal.SIG_DFL)
signal.signal(signal.SIGPIPE, signal.SIG_DFL)

def sentences(source):
   for kind, lines in groupby(source, str.isspace):
      if kind: continue

      # Split each line in the group into its tab-separated fields and
      # separate content (the tokens) from the one comment line and
      # from the j-k lines that join tokens into words.

      records = ( line.rstrip('\n').split('\t') for line in lines )

      # Always one comment line _in the source FTB_.
      comment = next(records)
      content = {}
      joining = {}
      for record in records:
         if record[0].isdigit():
            # A token line. Make ID and HEAD ints for greater ease of
            # further processing.
            ID, HEAD = int(record[0]), int(record[6])
            record[0], record[6] = ID, HEAD
            content[ID] = record
            continue

         # A j-k line. Must leave "j-k" as string but store the record
         # at j. This should crash if not a j-k line.
         first, last = ( int(ID) for ID in record[0].split('-') )
         joining[first] = record
      
      yield comment, content, joining

def print_comment(comment, content, joining):
   '''Prints v2 comment lines for the sentence. Input in v1
   Finnish-FTB contains exactly one comment line for each sentence:
   unique id and token sequence, as two fields at this point. Note:
   leaving sentence ids as they were, though martinpopel has wanted to
   disallow the occasional dots, too; there are no slashes there and
   that was the important point that got codified for v2.'''
   ident, toks = comment
   print('# sent_id = {}'.format(ident.lstrip('#')))
   print('# text = {}'.format(repair_text(toks, content, joining)))

def repair_text(text, content, joining):
   '''Rebuild text from content altogether - nerd-view spacing was not
   accepted.'''
   pieces = []
   for k, token in sorted(content.items()):
      if k - 1 in joining:
         pass
      elif k in joining:
         pieces.append(joining[k][1])
      else:
         pieces.append(token[1])
      
   return ' '.join(pieces)

def rename(line):
   '''Return a new content line with v2 names for various elements.'''
   ID, FORM, LEMMA, POS, FTB, FEATS, HEAD, REL, WEV, MISC = line

   # Some spaces might be allowed in FORM and LEMMA now. TODO?

   # Also something about AUX (expansion), PART (restriction), and
   # PROJ/DET (more flexible). TODO.
   if POS == 'CONJ': POS = 'CCONJ'

   FEATS = rename_feats(FEATS, pos = POS, ftb = FTB)

   # All *pass are removed but they are not used in Finnish-FTB
   # either? Also some nmod->obl, but cannot be done locally? And cop
   # is more restricted, but is it already so in Finnish-FTB?
   if REL == 'dobj': REL = 'obj'
   elif REL == 'neg': REL = 'aux' # aux ok?
   elif REL == 'mwe': REL = 'fixed'
   elif REL == 'name': REL = 'flat' # could be flat:name
   elif REL == 'foreign': REL = 'flat' # could be flat:foreign

   if REL == 'cop' and POS == 'VERB': POS = 'AUX'

   return [ID, FORM, LEMMA, POS, FTB, FEATS, HEAD, REL, WEV, MISC]

def rename_feats(FEATS, *, pos, ftb):
   '''Renames Negative to Polarity, adds Foreign=Yes, and Abbr=Yes is
   already used so do nothing about Abbr=Yes.'''

   if FEATS == '_':
      feats = dict()
   else:   
      feats = dict(feat.split('=') for feat in FEATS.split('|'))

   if 'Negative' in feats:
      assert 'Polarity' not in feats
      feats['Polarity'] = feats.pop('Negative')

   if 'Foreign' in ftb:
      assert 'Foreign' not in feats
      feats['Foreign'] = 'Yes' # right?

   # does one still want to sort features str.lower? yes
   FEATS = '|'.join('{}={}'.format(k, feats[k])
                    for k in sorted(feats, key = str.lower))
   return FEATS or '_'

def restruct(content, joining):
   restruct_cc(content)

def restruct_cc(content):
   # "attach cc and internal punct to the immediately succeeding
   # conjunct (instead of the first conjunct)" - should find the
   # succeeding conjunct by following the token sequence until there
   # is a conj to the old head; how to recognize a relevant punct?
   # http://universaldependencies.org/v2/coordination.html

   for record in content.values():
      ID, HEAD, REL = record[0], record[6], record[7]
      if REL == 'cc' and HEAD < ID:

         # Re HEAD < ID: A handful of cc are already attached forward.
         # These seem to be sentences that start with the cc, and
         # coordinations that involve truncated compounds. Ignore
         # those. Only re-attach when the original may have been
         # according to the old convention (was attached backward).

         them = ( content[k] for k in range(ID + 1, len(content) + 1)
                  if content[k][6] == HEAD
                  if content[k][7] == 'conj' )
         it = next(them, None)
         if it:
            record[6] = it[0]
         else:
            # a handful of cc are at the end of the sentence, with
            # nothing after them to re-attach them to - leave them
            pass

def main():
   args = interface()
   with open(args.file) as source:
      for comment, content, joining in sentences(source):
         new_content = { ID:rename(content[ID]) for ID in content }

         restruct(new_content, joining)

         print_comment(comment, new_content, joining)
         for record in sorted(new_content.values()):
            ID = record[0]
            if ID in joining: print(*joining[ID], sep = '\t')
            print(*record, sep = '\t')
         print()

def interface():
   parser = ArgumentParser(description = '''
                Transform a v1 UD_Finnish-FTB file to v2 stdout.
                Approximately as usual.
            ''')
   parser.add_argument('file',
                       help = 'the input file')

   return parser.parse_args()

if __name__ == '__main__':
   main()
