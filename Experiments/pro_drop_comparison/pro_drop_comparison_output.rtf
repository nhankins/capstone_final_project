{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset129 AppleSDGothicNeo-Regular;\f2\fnil\fcharset134 PingFangSC-Regular;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 (erg_nom) Nick deep-subjecthood-custom % ./run_batch_0.sh\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/pt_cintil-ud_ko_kaist-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Korean-Kaist-master/ko_kaist-ud-train.conllu', train_lang_base_path='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Counts of each role Counter(\{'O': 1285, 'S': 607, 'A': 108\})\
Case counts per role defaultdict(<class 'collections.Counter'>, \{None: Counter(\{None: 28303\}), 'S': Counter(\{None: 607\}), 'O': Counter(\{None: 1285\}), 'A': Counter(\{None: 108\})\})\
lengths of bert ids etc 2817 2817 2817 2817\
Saving all of the tokens and non-bert stuff to cached_datasets/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2817 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.hdf5\
Running 2817 sentences through BERT. This takes a while\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2817/2817 [01:39<00:00, 28.38it/s]\
length of bert outputs 2817\
On layer 12\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9315403422982885, 'O': 0.8970099667774086\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999997    12                0.93154                 0.89701\
1       O                            ...      0.000003    12                0.93154                 0.89701\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.033137    12                0.93154                 0.89701\
3       O                            ...      0.990771    12                0.93154                 0.89701\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.055552    12                0.93154                 0.89701\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.852059    12                0.93154                 0.89701\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.544825    12                0.93154                 0.89701\
1997    O                            ...      0.001001    12                0.93154                 0.89701\
1998    O                            ...      0.966439    12                0.93154                 0.89701\
1999    O                            ...      0.000055    12                0.93154                 0.89701\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9535452322738386, 'O': 0.9346622369878184\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999874e-01    11               0.953545                0.934662\
1       O                            ...  9.739827e-05    11               0.953545                0.934662\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.395351e-02    11               0.953545                0.934662\
3       O                            ...  9.932822e-01    11               0.953545                0.934662\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  3.103438e-02    11               0.953545                0.934662\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.571841e-01    11               0.953545                0.934662\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.458924e-03    11               0.953545                0.934662\
1997    O                            ...  2.602199e-04    11               0.953545                0.934662\
1998    O                            ...  7.557098e-01    11               0.953545                0.934662\
1999    O                            ...  4.483175e-08    11               0.953545                0.934662\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9633251833740831, 'O': 0.9446290143964563\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999524e-01    10               0.963325                0.944629\
1       O                            ...  5.638235e-10    10               0.963325                0.944629\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  4.396544e-01    10               0.963325                0.944629\
3       O                            ...  9.999919e-01    10               0.963325                0.944629\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.765297e-02    10               0.963325                0.944629\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.930769e-01    10               0.963325                0.944629\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  3.358651e-05    10               0.963325                0.944629\
1997    O                            ...  6.882717e-05    10               0.963325                0.944629\
1998    O                            ...  2.931007e-02    10               0.963325                0.944629\
1999    O                            ...  5.036667e-05    10               0.963325                0.944629\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.960880195599022, 'O': 0.9501661129568106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999993e-01     9                0.96088                0.950166\
1       O                            ...  2.467969e-10     9                0.96088                0.950166\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  8.709288e-02     9                0.96088                0.950166\
3       O                            ...  9.999754e-01     9                0.96088                0.950166\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  7.131338e-04     9                0.96088                0.950166\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.918935e-01     9                0.96088                0.950166\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  4.081850e-01     9                0.96088                0.950166\
1997    O                            ...  1.266928e-07     9                0.96088                0.950166\
1998    O                            ...  9.175197e-01     9                0.96088                0.950166\
1999    O                            ...  5.754903e-10     9                0.96088                0.950166\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.964562569213732\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.995924e-01     8                0.95599                0.964563\
1       O                            ...  5.948967e-09     8                0.95599                0.964563\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  6.488331e-02     8                0.95599                0.964563\
3       O                            ...  9.992394e-01     8                0.95599                0.964563\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  2.479922e-06     8                0.95599                0.964563\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  2.567372e-02     8                0.95599                0.964563\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.540962e-01     8                0.95599                0.964563\
1997    O                            ...  1.907737e-07     8                0.95599                0.964563\
1998    O                            ...  1.277134e-02     8                0.95599                0.964563\
1999    O                            ...  1.712237e-10     8                0.95599                0.964563\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.9512735326688815\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     7                0.95599                0.951274\
1       O                            ...  1.786632e-05     7                0.95599                0.951274\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  2.120497e-01     7                0.95599                0.951274\
3       O                            ...  9.237587e-01     7                0.95599                0.951274\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.323538e-03     7                0.95599                0.951274\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  1.613268e-03     7                0.95599                0.951274\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  5.989513e-02     7                0.95599                0.951274\
1997    O                            ...  8.539352e-07     7                0.95599                0.951274\
1998    O                            ...  9.955598e-01     7                0.95599                0.951274\
1999    O                            ...  2.323167e-08     7                0.95599                0.951274\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9437652811735942, 'O': 0.9678848283499446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     6               0.943765                0.967885\
1       O                            ...  8.500164e-05     6               0.943765                0.967885\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  3.729379e-03     6               0.943765                0.967885\
3       O                            ...  5.238358e-02     6               0.943765                0.967885\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  3.333281e-02     6               0.943765                0.967885\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  6.762856e-01     6               0.943765                0.967885\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  3.429615e-02     6               0.943765                0.967885\
1997    O                            ...  1.113008e-03     6               0.943765                0.967885\
1998    O                            ...  3.273722e-03     6               0.943765                0.967885\
1999    O                            ...  1.252135e-07     6               0.943765                0.967885\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9388753056234719, 'O': 0.9335548172757475\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     5               0.938875                0.933555\
1       O                            ...  8.387115e-04     5               0.938875                0.933555\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  6.328574e-02     5               0.938875                0.933555\
3       O                            ...  1.706757e-05     5               0.938875                0.933555\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  2.750995e-01     5               0.938875                0.933555\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  7.895289e-01     5               0.938875                0.933555\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.437203e-02     5               0.938875                0.933555\
1997    O                            ...  1.800410e-03     5               0.938875                0.933555\
1998    O                            ...  9.720252e-01     5               0.938875                0.933555\
1999    O                            ...  3.276547e-08     5               0.938875                0.933555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9070904645476773, 'O': 0.9080841638981174\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     4                0.90709                0.908084\
1       O                            ...  2.708610e-02     4                0.90709                0.908084\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.566267e-04     4                0.90709                0.908084\
3       O                            ...  1.346144e-04     4                0.90709                0.908084\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  9.952238e-01     4                0.90709                0.908084\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.940841e-01     4                0.90709                0.908084\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.454923e-01     4                0.90709                0.908084\
1997    O                            ...  8.801915e-02     4                0.90709                0.908084\
1998    O                            ...  2.517959e-01     4                0.90709                0.908084\
1999    O                            ...  1.236876e-08     4                0.90709                0.908084\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8997555012224939, 'O': 0.9136212624584718\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     3               0.899756                0.913621\
1       O                            ...      0.387397     3               0.899756                0.913621\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.154898     3               0.899756                0.913621\
3       O                            ...      0.058658     3               0.899756                0.913621\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.976239     3               0.899756                0.913621\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.999963     3               0.899756                0.913621\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.017924     3               0.899756                0.913621\
1997    O                            ...      0.956953     3               0.899756                0.913621\
1998    O                            ...      0.000424     3               0.899756                0.913621\
1999    O                            ...      0.001036     3               0.899756                0.913621\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7652811735941321, 'O': 0.858250276854928\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     2               0.765281                 0.85825\
1       O                            ...  9.016833e-02     2               0.765281                 0.85825\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  8.919601e-08     2               0.765281                 0.85825\
3       O                            ...  5.493132e-05     2               0.765281                 0.85825\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  8.641904e-01     2               0.765281                 0.85825\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.347409e-01     2               0.765281                 0.85825\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  7.623284e-03     2               0.765281                 0.85825\
1997    O                            ...  3.008324e-01     2               0.765281                 0.85825\
1998    O                            ...  4.173671e-03     2               0.765281                 0.85825\
1999    O                            ...  5.000000e-01     2               0.765281                 0.85825\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7555012224938875, 'O': 0.8217054263565892\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     1               0.755501                0.821705\
1       O                            ...      0.000055     1               0.755501                0.821705\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.000169     1               0.755501                0.821705\
3       O                            ...      0.000383     1               0.755501                0.821705\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.557914     1               0.755501                0.821705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.874858     1               0.755501                0.821705\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000192     1               0.755501                0.821705\
1997    O                            ...      0.893553     1               0.755501                0.821705\
1998    O                            ...      0.006141     1               0.755501                0.821705\
1999    O                            ...      0.025592     1               0.755501                0.821705\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6968215158924206, 'O': 0.8073089700996677\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999999     0               0.696822                0.807309\
1       O                            ...      0.007342     0               0.696822                0.807309\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.002422     0               0.696822                0.807309\
3       O                            ...      0.006061     0               0.696822                0.807309\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.218091     0               0.696822                0.807309\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.256706     0               0.696822                0.807309\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.005163     0               0.696822                0.807309\
1997    O                            ...      0.019053     0               0.696822                0.807309\
1998    O                            ...      0.284732     0               0.696822                0.807309\
1999    O                            ...      0.197293     0               0.696822                0.807309\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_ko_kaist-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Korean-Kaist-master/ko_kaist-ud-train.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2817 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2817/2817 [00:01<00:00, 1893.66it/s]\
Loaded 2816 sentences from disk.\
length of bert outputs 2817\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999710    12               0.960976                 0.85929\
1       O                            ...      0.949278    12               0.960976                 0.85929\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.999997    12               0.960976                 0.85929\
3       O                            ...      0.999999    12               0.960976                 0.85929\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.997148    12               0.960976                 0.85929\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.999795    12               0.960976                 0.85929\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.988657    12               0.960976                 0.85929\
1997    O                            ...      0.408610    12               0.960976                 0.85929\
1998    O                            ...      0.999987    12               0.960976                 0.85929\
1999    O                            ...      0.989399    12               0.960976                 0.85929\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999360    11               0.980488                0.912568\
1       O                            ...      0.156347    11               0.980488                0.912568\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.913993    11               0.980488                0.912568\
3       O                            ...      0.996458    11               0.980488                0.912568\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.983063    11               0.980488                0.912568\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.997340    11               0.980488                0.912568\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.419368    11               0.980488                0.912568\
1997    O                            ...      0.022163    11               0.980488                0.912568\
1998    O                            ...      0.992570    11               0.980488                0.912568\
1999    O                            ...      0.247189    11               0.980488                0.912568\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.997969    10                0.97561                0.904372\
1       O                            ...      0.000253    10                0.97561                0.904372\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.972713    10                0.97561                0.904372\
3       O                            ...      0.999913    10                0.97561                0.904372\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.974496    10                0.97561                0.904372\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.993203    10                0.97561                0.904372\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.792873    10                0.97561                0.904372\
1997    O                            ...      0.000002    10                0.97561                0.904372\
1998    O                            ...      0.974129    10                0.97561                0.904372\
1999    O                            ...      0.310959    10                0.97561                0.904372\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.998004e-01     9               0.980488                0.924863\
1       O                            ...  3.729786e-06     9               0.980488                0.924863\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  7.327563e-01     9               0.980488                0.924863\
3       O                            ...  9.951944e-01     9               0.980488                0.924863\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  6.609832e-01     9               0.980488                0.924863\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.547917e-01     9               0.980488                0.924863\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  4.403432e-01     9               0.980488                0.924863\
1997    O                            ...  9.661028e-07     9               0.980488                0.924863\
1998    O                            ...  9.226459e-01     9               0.980488                0.924863\
1999    O                            ...  1.929699e-05     9               0.980488                0.924863\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.992522     8               0.985366                0.941257\
1       O                            ...      0.000015     8               0.985366                0.941257\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.939259     8               0.985366                0.941257\
3       O                            ...      0.994934     8               0.985366                0.941257\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.018151     8               0.985366                0.941257\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.227821     8               0.985366                0.941257\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.335710     8               0.985366                0.941257\
1997    O                            ...      0.000010     8               0.985366                0.941257\
1998    O                            ...      0.898864     8               0.985366                0.941257\
1999    O                            ...      0.000279     8               0.985366                0.941257\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999992     7               0.980488                0.939891\
1       O                            ...      0.000053     7               0.980488                0.939891\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.938346     7               0.980488                0.939891\
3       O                            ...      0.985308     7               0.980488                0.939891\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.036596     7               0.980488                0.939891\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.404729     7               0.980488                0.939891\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.444741     7               0.980488                0.939891\
1997    O                            ...      0.000004     7               0.980488                0.939891\
1998    O                            ...      0.865561     7               0.980488                0.939891\
1999    O                            ...      0.004598     7               0.980488                0.939891\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999915e-01     6                0.97561                0.927596\
1       O                            ...  4.927757e-04     6                0.97561                0.927596\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  5.457345e-02     6                0.97561                0.927596\
3       O                            ...  9.485387e-01     6                0.97561                0.927596\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.993267e-01     6                0.97561                0.927596\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.292227e-01     6                0.97561                0.927596\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  8.479684e-01     6                0.97561                0.927596\
1997    O                            ...  7.246157e-03     6                0.97561                0.927596\
1998    O                            ...  5.247882e-02     6                0.97561                0.927596\
1999    O                            ...  2.052767e-08     6                0.97561                0.927596\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999996     5               0.970732                0.901639\
1       O                            ...      0.906261     5               0.970732                0.901639\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.009235     5               0.970732                0.901639\
3       O                            ...      0.988410     5               0.970732                0.901639\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.748048     5               0.970732                0.901639\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.998108     5               0.970732                0.901639\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.987946     5               0.970732                0.901639\
1997    O                            ...      0.214252     5               0.970732                0.901639\
1998    O                            ...      0.916559     5               0.970732                0.901639\
1999    O                            ...      0.000002     5               0.970732                0.901639\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     4               0.912195                0.826503\
1       O                            ...  9.992468e-01     4               0.912195                0.826503\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  8.546263e-05     4               0.912195                0.826503\
3       O                            ...  7.814893e-01     4               0.912195                0.826503\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  3.970356e-01     4               0.912195                0.826503\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.756142e-01     4               0.912195                0.826503\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  9.600483e-01     4               0.912195                0.826503\
1997    O                            ...  1.285499e-02     4               0.912195                0.826503\
1998    O                            ...  9.998312e-01     4               0.912195                0.826503\
1999    O                            ...  9.249526e-09     4               0.912195                0.826503\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.991507     3               0.936585                0.815574\
1       O                            ...      0.955611     3               0.936585                0.815574\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.009450     3               0.936585                0.815574\
3       O                            ...      0.612470     3               0.936585                0.815574\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.005092     3               0.936585                0.815574\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.971824     3               0.936585                0.815574\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.933453     3               0.936585                0.815574\
1997    O                            ...      0.752053     3               0.936585                0.815574\
1998    O                            ...      0.889008     3               0.936585                0.815574\
1999    O                            ...      0.000406     3               0.936585                0.815574\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     2               0.858537                0.717213\
1       O                            ...      0.964103     2               0.858537                0.717213\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.007134     2               0.858537                0.717213\
3       O                            ...      0.565895     2               0.858537                0.717213\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.994205     2               0.858537                0.717213\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.328212     2               0.858537                0.717213\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.242279     2               0.858537                0.717213\
1997    O                            ...      0.005698     2               0.858537                0.717213\
1998    O                            ...      0.931169     2               0.858537                0.717213\
1999    O                            ...      0.500000     2               0.858537                0.717213\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999990     1               0.780488                0.709016\
1       O                            ...      0.372824     1               0.780488                0.709016\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.100299     1               0.780488                0.709016\
3       O                            ...      0.825608     1               0.780488                0.709016\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.998956     1               0.780488                0.709016\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.902725     1               0.780488                0.709016\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.106102     1               0.780488                0.709016\
1997    O                            ...      0.227458     1               0.780488                0.709016\
1998    O                            ...      0.987516     1               0.780488                0.709016\
1999    O                            ...      0.000607     1               0.780488                0.709016\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999993     0               0.790244                0.665301\
1       O                            ...      0.641633     0               0.790244                0.665301\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.842876     0               0.790244                0.665301\
3       O                            ...      0.915726     0               0.790244                0.665301\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.999999     0               0.790244                0.665301\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.837378     0               0.790244                0.665301\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000086     0               0.790244                0.665301\
1997    O                            ...      0.050070     0               0.790244                0.665301\
1998    O                            ...      0.678374     0               0.790244                0.665301\
1999    O                            ...      0.078918     0               0.790244                0.665301\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_ko_kaist-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Korean-Kaist-master/ko_kaist-ud-train.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2817 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2817/2817 [00:01<00:00, 2426.06it/s]\
Loaded 2816 sentences from disk.\
length of bert outputs 2817\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.997461    12               0.958763                0.929329\
1       O                            ...      0.000007    12               0.958763                0.929329\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.999994    12               0.958763                0.929329\
3       O                            ...      0.920768    12               0.958763                0.929329\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.954234    12               0.958763                0.929329\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.893149    12               0.958763                0.929329\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.176432    12               0.958763                0.929329\
1997    O                            ...      0.193521    12               0.958763                0.929329\
1998    O                            ...      0.981704    12               0.958763                0.929329\
1999    O                            ...      0.000555    12               0.958763                0.929329\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999715    11               0.958763                0.975265\
1       O                            ...      0.000093    11               0.958763                0.975265\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.997317    11               0.958763                0.975265\
3       O                            ...      0.927392    11               0.958763                0.975265\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.882240    11               0.958763                0.975265\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.007220    11               0.958763                0.975265\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.633973    11               0.958763                0.975265\
1997    O                            ...      0.000014    11               0.958763                0.975265\
1998    O                            ...      0.433742    11               0.958763                0.975265\
1999    O                            ...      0.000076    11               0.958763                0.975265\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  5.565324e-01    10               0.958763                0.961131\
1       O                            ...  1.788867e-09    10               0.958763                0.961131\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.981477e-01    10               0.958763                0.961131\
3       O                            ...  9.996985e-01    10               0.958763                0.961131\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  8.348064e-01    10               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.588452e-01    10               0.958763                0.961131\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  5.998306e-01    10               0.958763                0.961131\
1997    O                            ...  2.463686e-05    10               0.958763                0.961131\
1998    O                            ...  1.184721e-02    10               0.958763                0.961131\
1999    O                            ...  2.699703e-03    10               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  6.529716e-01     9               0.958763                0.971731\
1       O                            ...  1.946170e-11     9               0.958763                0.971731\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.990477e-01     9               0.958763                0.971731\
3       O                            ...  3.284746e-01     9               0.958763                0.971731\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.506008e-03     9               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  3.660779e-01     9               0.958763                0.971731\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.500193e-01     9               0.958763                0.971731\
1997    O                            ...  5.308612e-07     9               0.958763                0.971731\
1998    O                            ...  1.493581e-03     9               0.958763                0.971731\
1999    O                            ...  1.540789e-08     9               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  4.142466e-01     8               0.958763                0.961131\
1       O                            ...  1.601626e-08     8               0.958763                0.961131\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.999812e-01     8               0.958763                0.961131\
3       O                            ...  2.668233e-02     8               0.958763                0.961131\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.247840e-06     8               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  5.264408e-02     8               0.958763                0.961131\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  3.528855e-02     8               0.958763                0.961131\
1997    O                            ...  4.145337e-06     8               0.958763                0.961131\
1998    O                            ...  3.469220e-05     8               0.958763                0.961131\
1999    O                            ...  1.252417e-07     8               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.918506e-01     7               0.958763                0.971731\
1       O                            ...  7.518033e-09     7               0.958763                0.971731\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.682233e-01     7               0.958763                0.971731\
3       O                            ...  4.278795e-02     7               0.958763                0.971731\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  4.577074e-04     7               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  3.028338e-02     7               0.958763                0.971731\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  5.969998e-04     7               0.958763                0.971731\
1997    O                            ...  2.599200e-08     7               0.958763                0.971731\
1998    O                            ...  8.068065e-03     7               0.958763                0.971731\
1999    O                            ...  2.184226e-07     7               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999472e-01     6               0.938144                0.968198\
1       O                            ...  1.836185e-06     6               0.938144                0.968198\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  7.538659e-01     6               0.938144                0.968198\
3       O                            ...  3.475972e-01     6               0.938144                0.968198\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.457251e-02     6               0.938144                0.968198\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  6.615627e-02     6               0.938144                0.968198\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  3.312875e-01     6               0.938144                0.968198\
1997    O                            ...  2.580227e-05     6               0.938144                0.968198\
1998    O                            ...  6.521847e-01     6               0.938144                0.968198\
1999    O                            ...  9.330183e-09     6               0.938144                0.968198\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999998e-01     5               0.969072                0.943463\
1       O                            ...  1.647286e-02     5               0.969072                0.943463\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  2.894275e-01     5               0.969072                0.943463\
3       O                            ...  3.588783e-02     5               0.969072                0.943463\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.821754e-02     5               0.969072                0.943463\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.045911e-05     5               0.969072                0.943463\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  8.643302e-05     5               0.969072                0.943463\
1997    O                            ...  1.112973e-04     5               0.969072                0.943463\
1998    O                            ...  9.068021e-01     5               0.969072                0.943463\
1999    O                            ...  3.565020e-07     5               0.969072                0.943463\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  1.000000e+00     4               0.917526                0.946996\
1       O                            ...  1.097289e-03     4               0.917526                0.946996\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  4.147610e-04     4               0.917526                0.946996\
3       O                            ...  1.008381e-05     4               0.917526                0.946996\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  2.102146e-01     4               0.917526                0.946996\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  4.649309e-04     4               0.917526                0.946996\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.786740e-03     4               0.917526                0.946996\
1997    O                            ...  1.323822e-05     4               0.917526                0.946996\
1998    O                            ...  9.907178e-01     4               0.917526                0.946996\
1999    O                            ...  8.490275e-08     4               0.917526                0.946996\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999996     3               0.938144                0.936396\
1       O                            ...      0.736996     3               0.938144                0.936396\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.256735     3               0.938144                0.936396\
3       O                            ...      0.017699     3               0.938144                0.936396\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.484695     3               0.938144                0.936396\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.016072     3               0.938144                0.936396\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.001764     3               0.938144                0.936396\
1997    O                            ...      0.077128     3               0.938144                0.936396\
1998    O                            ...      0.283354     3               0.938144                0.936396\
1999    O                            ...      0.003264     3               0.938144                0.936396\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     2               0.783505                0.795053\
1       O                            ...      0.597715     2               0.783505                0.795053\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.003906     2               0.783505                0.795053\
3       O                            ...      0.028179     2               0.783505                0.795053\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.616561     2               0.783505                0.795053\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.423698     2               0.783505                0.795053\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.014534     2               0.783505                0.795053\
1997    O                            ...      0.001641     2               0.783505                0.795053\
1998    O                            ...      0.997323     2               0.783505                0.795053\
1999    O                            ...      0.500000     2               0.783505                0.795053\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     1               0.793814                0.773852\
1       O                            ...      0.023528     1               0.793814                0.773852\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.004214     1               0.793814                0.773852\
3       O                            ...      0.001310     1               0.793814                0.773852\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.312864     1               0.793814                0.773852\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.106748     1               0.793814                0.773852\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.010545     1               0.793814                0.773852\
1997    O                            ...      0.000395     1               0.793814                0.773852\
1998    O                            ...      0.962286     1               0.793814                0.773852\
1999    O                            ...      0.000010     1               0.793814                0.773852\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     0               0.721649                0.816254\
1       O                            ...      0.904099     0               0.721649                0.816254\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.114746     0               0.721649                0.816254\
3       O                            ...      0.557680     0               0.721649                0.816254\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.553554     0               0.721649                0.816254\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.585116     0               0.721649                0.816254\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.029468     0               0.721649                0.816254\
1997    O                            ...      0.040112     0               0.721649                0.816254\
1998    O                            ...      0.783278     0               0.721649                0.816254\
1999    O                            ...      0.003038     0               0.721649                0.816254\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_ko_kaist-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Korean-Kaist-master/ko_kaist-ud-train.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2817 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2817/2817 [00:01<00:00, 2745.66it/s]\
Loaded 2816 sentences from disk.\
length of bert outputs 2817\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.997546    12                0.84556                0.873118\
1       O                            ...      0.001556    12                0.84556                0.873118\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.700951    12                0.84556                0.873118\
3       O                            ...      0.999999    12                0.84556                0.873118\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.996105    12                0.84556                0.873118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.995588    12                0.84556                0.873118\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.998754    12                0.84556                0.873118\
1997    O                            ...      0.005097    12                0.84556                0.873118\
1998    O                            ...      0.821717    12                0.84556                0.873118\
1999    O                            ...      0.013123    12                0.84556                0.873118\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.729049    11               0.880309                0.896774\
1       O                            ...      0.002540    11               0.880309                0.896774\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.991691    11               0.880309                0.896774\
3       O                            ...      0.996744    11               0.880309                0.896774\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.993100    11               0.880309                0.896774\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.978565    11               0.880309                0.896774\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.999774    11               0.880309                0.896774\
1997    O                            ...      0.000002    11               0.880309                0.896774\
1998    O                            ...      0.295429    11               0.880309                0.896774\
1999    O                            ...      0.000032    11               0.880309                0.896774\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  5.163811e-02    10               0.915058                0.922581\
1       O                            ...  1.249124e-08    10               0.915058                0.922581\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.902649e-01    10               0.915058                0.922581\
3       O                            ...  9.828497e-01    10               0.915058                0.922581\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  7.336923e-01    10               0.915058                0.922581\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.954638e-01    10               0.915058                0.922581\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  9.737625e-01    10               0.915058                0.922581\
1997    O                            ...  3.680550e-08    10               0.915058                0.922581\
1998    O                            ...  1.243902e-03    10               0.915058                0.922581\
1999    O                            ...  8.734991e-04    10               0.915058                0.922581\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  7.589924e-03     9               0.903475                0.909677\
1       O                            ...  1.007580e-08     9               0.903475                0.909677\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.990168e-01     9               0.903475                0.909677\
3       O                            ...  9.893984e-01     9               0.903475                0.909677\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  7.600931e-01     9               0.903475                0.909677\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  1.668654e-01     9               0.903475                0.909677\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  9.954826e-01     9               0.903475                0.909677\
1997    O                            ...  6.693354e-08     9               0.903475                0.909677\
1998    O                            ...  4.824947e-05     9               0.903475                0.909677\
1999    O                            ...  9.975900e-07     9               0.903475                0.909677\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  6.747947e-01     8               0.891892                0.913978\
1       O                            ...  4.519059e-09     8               0.891892                0.913978\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.984512e-01     8               0.891892                0.913978\
3       O                            ...  9.995589e-01     8               0.891892                0.913978\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  8.947466e-01     8               0.891892                0.913978\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  4.362395e-01     8               0.891892                0.913978\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  9.998574e-01     8               0.891892                0.913978\
1997    O                            ...  3.835224e-05     8               0.891892                0.913978\
1998    O                            ...  2.581996e-06     8               0.891892                0.913978\
1999    O                            ...  4.033841e-05     8               0.891892                0.913978\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.871479e-01     7               0.911197                0.892473\
1       O                            ...  1.378441e-08     7               0.911197                0.892473\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.979290e-01     7               0.911197                0.892473\
3       O                            ...  9.966540e-01     7               0.911197                0.892473\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  9.985496e-01     7               0.911197                0.892473\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.065185e-04     7               0.911197                0.892473\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  9.574307e-01     7               0.911197                0.892473\
1997    O                            ...  2.254215e-06     7               0.911197                0.892473\
1998    O                            ...  4.568665e-03     7               0.911197                0.892473\
1999    O                            ...  6.446157e-04     7               0.911197                0.892473\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.998263     6               0.888031                0.890323\
1       O                            ...      0.000052     6               0.888031                0.890323\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.991741     6               0.888031                0.890323\
3       O                            ...      0.994081     6               0.888031                0.890323\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.725832     6               0.888031                0.890323\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.116177     6               0.888031                0.890323\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000912     6               0.888031                0.890323\
1997    O                            ...      0.690511     6               0.888031                0.890323\
1998    O                            ...      0.000065     6               0.888031                0.890323\
1999    O                            ...      0.000040     6               0.888031                0.890323\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999981     5               0.803089                 0.84086\
1       O                            ...      0.000170     5               0.803089                 0.84086\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.999669     5               0.803089                 0.84086\
3       O                            ...      0.213215     5               0.803089                 0.84086\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.408753     5               0.803089                 0.84086\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.002562     5               0.803089                 0.84086\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000561     5               0.803089                 0.84086\
1997    O                            ...      0.497321     5               0.803089                 0.84086\
1998    O                            ...      0.058982     5               0.803089                 0.84086\
1999    O                            ...      0.000018     5               0.803089                 0.84086\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999111e-01     4               0.826255                0.756989\
1       O                            ...  4.655020e-05     4               0.826255                0.756989\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.776939e-01     4               0.826255                0.756989\
3       O                            ...  8.469431e-01     4               0.826255                0.756989\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  9.891689e-01     4               0.826255                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.440570e-01     4               0.826255                0.756989\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  7.858258e-04     4               0.826255                0.756989\
1997    O                            ...  6.006218e-01     4               0.826255                0.756989\
1998    O                            ...  6.451777e-01     4               0.826255                0.756989\
1999    O                            ...  6.808153e-07     4               0.826255                0.756989\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.950942e-01     3                0.80695                0.787097\
1       O                            ...  1.619344e-03     3                0.80695                0.787097\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  8.340718e-01     3                0.80695                0.787097\
3       O                            ...  7.723868e-01     3                0.80695                0.787097\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  9.992100e-01     3                0.80695                0.787097\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.930626e-01     3                0.80695                0.787097\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.866803e-07     3                0.80695                0.787097\
1997    O                            ...  8.595800e-01     3                0.80695                0.787097\
1998    O                            ...  3.994755e-04     3                0.80695                0.787097\
1999    O                            ...  9.947130e-03     3                0.80695                0.787097\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999341     2               0.722008                0.825806\
1       O                            ...      0.004695     2               0.722008                0.825806\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.719668     2               0.722008                0.825806\
3       O                            ...      0.777069     2               0.722008                0.825806\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.584776     2               0.722008                0.825806\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.580061     2               0.722008                0.825806\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.011305     2               0.722008                0.825806\
1997    O                            ...      0.418842     2               0.722008                0.825806\
1998    O                            ...      0.000157     2               0.722008                0.825806\
1999    O                            ...      0.500000     2               0.722008                0.825806\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.891120     1               0.675676                0.756989\
1       O                            ...      0.042554     1               0.675676                0.756989\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.725145     1               0.675676                0.756989\
3       O                            ...      0.989845     1               0.675676                0.756989\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.177126     1               0.675676                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.539905     1               0.675676                0.756989\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000162     1               0.675676                0.756989\
1997    O                            ...      0.274811     1               0.675676                0.756989\
1998    O                            ...      0.032202     1               0.675676                0.756989\
1999    O                            ...      0.131562     1               0.675676                0.756989\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999394     0               0.722008                0.673118\
1       O                            ...      0.002188     0               0.722008                0.673118\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.994661     0               0.722008                0.673118\
3       O                            ...      0.951179     0               0.722008                0.673118\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.233872     0               0.722008                0.673118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.657937     0               0.722008                0.673118\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.001853     0               0.722008                0.673118\
1997    O                            ...      0.848885     0               0.722008                0.673118\
1998    O                            ...      0.460174     0               0.722008                0.673118\
1999    O                            ...      0.003859     0               0.722008                0.673118\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_ko_kaist-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Korean-Kaist-master/ko_kaist-ud-train.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2817 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_ko_kaist-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2817/2817 [00:00<00:00, 2908.15it/s]\
Loaded 2816 sentences from disk.\
length of bert outputs 2817\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.962077e-01    12               0.978723                0.872247\
1       O                            ...  2.393974e-06    12               0.978723                0.872247\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.304059e-05    12               0.978723                0.872247\
3       O                            ...  6.557832e-01    12               0.978723                0.872247\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  4.640144e-04    12               0.978723                0.872247\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.216915e-01    12               0.978723                0.872247\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.035676e-02    12               0.978723                0.872247\
1997    O                            ...  2.759531e-04    12               0.978723                0.872247\
1998    O                            ...  2.381624e-04    12               0.978723                0.872247\
1999    O                            ...  4.525772e-08    12               0.978723                0.872247\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  6.414663e-01    11               0.978723                0.898678\
1       O                            ...  9.517295e-06    11               0.978723                0.898678\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  2.017185e-06    11               0.978723                0.898678\
3       O                            ...  9.168897e-02    11               0.978723                0.898678\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.697299e-06    11               0.978723                0.898678\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  7.750438e-01    11               0.978723                0.898678\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.758290e-05    11               0.978723                0.898678\
1997    O                            ...  2.260586e-08    11               0.978723                0.898678\
1998    O                            ...  3.482839e-09    11               0.978723                0.898678\
1999    O                            ...  5.200289e-11    11               0.978723                0.898678\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.983550e-01    10               0.978723                0.929515\
1       O                            ...  3.358054e-10    10               0.978723                0.929515\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  2.433746e-04    10               0.978723                0.929515\
3       O                            ...  6.403084e-01    10               0.978723                0.929515\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  9.036190e-04    10               0.978723                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.869982e-01    10               0.978723                0.929515\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.256399e-05    10               0.978723                0.929515\
1997    O                            ...  1.339335e-08    10               0.978723                0.929515\
1998    O                            ...  8.912356e-08    10               0.978723                0.929515\
1999    O                            ...  9.920524e-06    10               0.978723                0.929515\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.910259e-01     9               0.989362                0.920705\
1       O                            ...  5.057975e-11     9               0.989362                0.920705\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.614299e-04     9               0.989362                0.920705\
3       O                            ...  6.656479e-01     9               0.989362                0.920705\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  3.002402e-02     9               0.989362                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.815228e-01     9               0.989362                0.920705\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.882907e-02     9               0.989362                0.920705\
1997    O                            ...  1.201948e-09     9               0.989362                0.920705\
1998    O                            ...  1.069692e-08     9               0.989362                0.920705\
1999    O                            ...  2.612316e-12     9               0.989362                0.920705\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.816191e-01     8               0.989362                0.929515\
1       O                            ...  9.388695e-10     8               0.989362                0.929515\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.743952e-05     8               0.989362                0.929515\
3       O                            ...  1.045620e-03     8               0.989362                0.929515\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  2.469948e-05     8               0.989362                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.809085e-01     8               0.989362                0.929515\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  4.514078e-03     8               0.989362                0.929515\
1997    O                            ...  3.147097e-07     8               0.989362                0.929515\
1998    O                            ...  9.498655e-11     8               0.989362                0.929515\
1999    O                            ...  6.445255e-11     8               0.989362                0.929515\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.962914e-01     7               0.978723                 0.92511\
1       O                            ...  2.629508e-08     7               0.978723                 0.92511\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  6.092108e-02     7               0.978723                 0.92511\
3       O                            ...  7.227575e-03     7               0.978723                 0.92511\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.236716e-07     7               0.978723                 0.92511\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.416324e-01     7               0.978723                 0.92511\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.049814e-04     7               0.978723                 0.92511\
1997    O                            ...  2.096698e-08     7               0.978723                 0.92511\
1998    O                            ...  2.900192e-08     7               0.978723                 0.92511\
1999    O                            ...  8.239057e-09     7               0.978723                 0.92511\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.984846e-01     6               0.957447                0.920705\
1       O                            ...  1.868545e-07     6               0.957447                0.920705\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.844822e-02     6               0.957447                0.920705\
3       O                            ...  9.582340e-01     6               0.957447                0.920705\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  2.642520e-02     6               0.957447                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  8.022054e-01     6               0.957447                0.920705\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.060757e-02     6               0.957447                0.920705\
1997    O                            ...  2.229882e-04     6               0.957447                0.920705\
1998    O                            ...  7.851772e-04     6               0.957447                0.920705\
1999    O                            ...  1.536534e-11     6               0.957447                0.920705\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.973309e-01     5               0.968085                0.863436\
1       O                            ...  6.047080e-08     5               0.968085                0.863436\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  3.422356e-02     5               0.968085                0.863436\
3       O                            ...  1.875160e-03     5               0.968085                0.863436\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  1.079235e-03     5               0.968085                0.863436\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  6.939638e-01     5               0.968085                0.863436\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  2.924859e-07     5               0.968085                0.863436\
1997    O                            ...  5.692906e-04     5               0.968085                0.863436\
1998    O                            ...  1.265312e-01     5               0.968085                0.863436\
1999    O                            ...  1.689674e-09     5               0.968085                0.863436\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.999816e-01     4               0.957447                0.797357\
1       O                            ...  6.417459e-05     4               0.957447                0.797357\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  1.954050e-01     4               0.957447                0.797357\
3       O                            ...  1.451136e-02     4               0.957447                0.797357\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  3.354508e-04     4               0.957447                0.797357\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  4.642409e-01     4               0.957447                0.797357\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.774611e-04     4               0.957447                0.797357\
1997    O                            ...  3.858659e-06     4               0.957447                0.797357\
1998    O                            ...  6.502469e-01     4               0.957447                0.797357\
1999    O                            ...  3.225263e-08     4               0.957447                0.797357\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...  9.998090e-01     3               0.914894                0.810573\
1       O                            ...  5.872374e-01     3               0.914894                0.810573\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...  9.840059e-01     3               0.914894                0.810573\
3       O                            ...  2.801664e-01     3               0.914894                0.810573\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...  5.617013e-03     3               0.914894                0.810573\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...  9.999530e-01     3               0.914894                0.810573\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...  1.480663e-08     3               0.914894                0.810573\
1997    O                            ...  9.608142e-01     3               0.914894                0.810573\
1998    O                            ...  2.099202e-03     3               0.914894                0.810573\
1999    O                            ...  7.892383e-03     3               0.914894                0.810573\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     2               0.787234                0.674009\
1       O                            ...      0.020057     2               0.787234                0.674009\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.041363     2               0.787234                0.674009\
3       O                            ...      0.992135     2               0.787234                0.674009\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.157567     2               0.787234                0.674009\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.998005     2               0.787234                0.674009\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.008602     2               0.787234                0.674009\
1997    O                            ...      0.316849     2               0.787234                0.674009\
1998    O                            ...      0.000006     2               0.787234                0.674009\
1999    O                            ...      0.500000     2               0.787234                0.674009\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      0.999999     1               0.765957                 0.69163\
1       O                            ...      0.000306     1               0.765957                 0.69163\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.082989     1               0.765957                 0.69163\
3       O                            ...      0.689972     1               0.765957                 0.69163\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.490520     1               0.765957                 0.69163\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.918803     1               0.765957                 0.69163\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.000385     1               0.765957                 0.69163\
1997    O                            ...      0.525828     1               0.765957                 0.69163\
1998    O                            ...      0.001371     1               0.765957                 0.69163\
1999    O                            ...      0.005349     1               0.765957                 0.69163\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                       
\f1 \'bb\'e7\'b6\'f7\'c0\'cc
\f0   ...      1.000000     0               0.712766                0.788546\
1       O                            ...      0.006946     0               0.712766                0.788546\
2       S                       
\f1 \'b0\'ee\'bd\'c4\'c0\'cc
\f0   ...      0.834612     0               0.712766                0.788546\
3       O                            ...      0.977276     0               0.712766                0.788546\
4       S                      
\f1 \'b5\'b5\'b4\'f6\'bc\'ba\'c0\'cc
\f0   ...      0.562263     0               0.712766                0.788546\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    S                     
\f1 \'b0\'b3\'c7\'f5\'c0\'c7\'c1\'f6\'b0\'a1
\f0   ...      0.833612     0               0.712766                0.788546\
1996    S                        
\f1 \'b8\'bb\'c0\'cc
\f0   ...      0.371364     0               0.712766                0.788546\
1997    O                            ...      0.318782     0               0.712766                0.788546\
1998    O                            ...      0.361399     0               0.712766                0.788546\
1999    O                            ...      0.041401     0               0.712766                0.788546\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/ko_kaist-ud_pt_cintil-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud-train.conllu', train_lang_base_path='language_data/UD_Korean-Kaist-master/ko_kaist-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Counts of each role Counter(\{'O': 963, 'S': 599, 'A': 424, 'S-aux': 14\})\
Case counts per role defaultdict(<class 'collections.Counter'>, \{None: Counter(\{None: 17697\}), 'S': Counter(\{None: 599\}), 'A': Counter(\{None: 424\}), 'O': Counter(\{None: 963\}), 'S-aux': Counter(\{None: 14\})\})\
lengths of bert ids etc 2089 2089 2089 2089\
Saving all of the tokens and non-bert stuff to cached_datasets/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2089 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.hdf5\
Running 2089 sentences through BERT. This takes a while\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2089/2089 [01:14<00:00, 28.00it/s]\
length of bert outputs 2089\
On layer 12\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9186991869918699, 'O': 0.7310278578290106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.996608e-01    12               0.918699                0.731028\
1       S                   crian\'e7a  ...  9.299222e-01    12               0.918699                0.731028\
2       S                 encomenda  ...  7.052976e-01    12               0.918699                0.731028\
3       S                 encomenda  ...  9.833750e-01    12               0.918699                0.731028\
4       S                 encomenda  ...  9.884065e-01    12               0.918699                0.731028\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.768610e-08    12               0.918699                0.731028\
1996    O                            ...  1.444282e-03    12               0.918699                0.731028\
1997    S                     Laura  ...  1.257091e-05    12               0.918699                0.731028\
1998    A                       pai  ...  9.999993e-01    12               0.918699                0.731028\
1999    S                  mensagem  ...  9.121094e-01    12               0.918699                0.731028\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.7905859750240154\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999995e-01    11               0.910569                0.790586\
1       S                   crian\'e7a  ...  9.978139e-01    11               0.910569                0.790586\
2       S                 encomenda  ...  9.999928e-01    11               0.910569                0.790586\
3       S                 encomenda  ...  9.991632e-01    11               0.910569                0.790586\
4       S                 encomenda  ...  9.999998e-01    11               0.910569                0.790586\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.047617e-11    11               0.910569                0.790586\
1996    O                            ...  1.525621e-04    11               0.910569                0.790586\
1997    S                     Laura  ...  1.239317e-05    11               0.910569                0.790586\
1998    A                       pai  ...  9.999998e-01    11               0.910569                0.790586\
1999    S                  mensagem  ...  9.999983e-01    11               0.910569                0.790586\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.8213256484149856\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999993e-01    10               0.886179                0.821326\
1       S                   crian\'e7a  ...  9.999937e-01    10               0.886179                0.821326\
2       S                 encomenda  ...  9.977711e-01    10               0.886179                0.821326\
3       S                 encomenda  ...  9.999557e-01    10               0.886179                0.821326\
4       S                 encomenda  ...  9.999189e-01    10               0.886179                0.821326\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.177687e-10    10               0.886179                0.821326\
1996    O                            ...  9.894530e-06    10               0.886179                0.821326\
1997    S                     Laura  ...  4.468066e-02    10               0.886179                0.821326\
1998    A                       pai  ...  9.999965e-01    10               0.886179                0.821326\
1999    S                  mensagem  ...  9.939874e-01    10               0.886179                0.821326\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     9               0.910569                0.855908\
1       S                   crian\'e7a  ...  9.999999e-01     9               0.910569                0.855908\
2       S                 encomenda  ...  9.999951e-01     9               0.910569                0.855908\
3       S                 encomenda  ...  9.999989e-01     9               0.910569                0.855908\
4       S                 encomenda  ...  9.999976e-01     9               0.910569                0.855908\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  8.086691e-11     9               0.910569                0.855908\
1996    O                            ...  3.565044e-02     9               0.910569                0.855908\
1997    S                     Laura  ...  4.789781e-02     9               0.910569                0.855908\
1998    A                       pai  ...  9.999982e-01     9               0.910569                0.855908\
1999    S                  mensagem  ...  9.999855e-01     9               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999659e-01     8               0.910569                0.855908\
1       S                   crian\'e7a  ...  9.999998e-01     8               0.910569                0.855908\
2       S                 encomenda  ...  8.956255e-01     8               0.910569                0.855908\
3       S                 encomenda  ...  9.993469e-01     8               0.910569                0.855908\
4       S                 encomenda  ...  9.978431e-01     8               0.910569                0.855908\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.684374e-09     8               0.910569                0.855908\
1996    O                            ...  8.965796e-04     8               0.910569                0.855908\
1997    S                     Laura  ...  1.783856e-02     8               0.910569                0.855908\
1998    A                       pai  ...  9.999936e-01     8               0.910569                0.855908\
1999    S                  mensagem  ...  9.999995e-01     8               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8914505283381364\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     7               0.934959                0.891451\
1       S                   crian\'e7a  ...      0.999987     7               0.934959                0.891451\
2       S                 encomenda  ...      0.919460     7               0.934959                0.891451\
3       S                 encomenda  ...      0.999682     7               0.934959                0.891451\
4       S                 encomenda  ...      0.997752     7               0.934959                0.891451\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000002     7               0.934959                0.891451\
1996    O                            ...      0.000014     7               0.934959                0.891451\
1997    S                     Laura  ...      0.012868     7               0.934959                0.891451\
1998    A                       pai  ...      0.999853     7               0.934959                0.891451\
1999    S                  mensagem  ...      0.998885     7               0.934959                0.891451\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8194044188280499\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     6               0.934959                0.819404\
1       S                   crian\'e7a  ...  9.999999e-01     6               0.934959                0.819404\
2       S                 encomenda  ...  9.999448e-01     6               0.934959                0.819404\
3       S                 encomenda  ...  9.999987e-01     6               0.934959                0.819404\
4       S                 encomenda  ...  9.990583e-01     6               0.934959                0.819404\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.643909e-03     6               0.934959                0.819404\
1996    O                            ...  4.481004e-07     6               0.934959                0.819404\
1997    S                     Laura  ...  9.999136e-01     6               0.934959                0.819404\
1998    A                       pai  ...  9.999696e-01     6               0.934959                0.819404\
1999    S                  mensagem  ...  9.995952e-01     6               0.934959                0.819404\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9024390243902439, 'O': 0.7425552353506244\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     5               0.902439                0.742555\
1       S                   crian\'e7a  ...  9.996424e-01     5               0.902439                0.742555\
2       S                 encomenda  ...  5.866885e-01     5               0.902439                0.742555\
3       S                 encomenda  ...  9.674158e-01     5               0.902439                0.742555\
4       S                 encomenda  ...  9.451836e-01     5               0.902439                0.742555\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.827037e-07     5               0.902439                0.742555\
1996    O                            ...  4.399773e-07     5               0.902439                0.742555\
1997    S                     Laura  ...  9.896595e-01     5               0.902439                0.742555\
1998    A                       pai  ...  6.068068e-01     5               0.902439                0.742555\
1999    S                  mensagem  ...  3.551773e-03     5               0.902439                0.742555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.7300672430355427\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999839e-01     4               0.886179                0.730067\
1       S                   crian\'e7a  ...  9.999405e-01     4               0.886179                0.730067\
2       S                 encomenda  ...  1.829565e-01     4               0.886179                0.730067\
3       S                 encomenda  ...  9.355405e-01     4               0.886179                0.730067\
4       S                 encomenda  ...  9.047985e-01     4               0.886179                0.730067\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.569399e-10     4               0.886179                0.730067\
1996    O                            ...  3.255267e-04     4               0.886179                0.730067\
1997    S                     Laura  ...  8.493023e-02     4               0.886179                0.730067\
1998    A                       pai  ...  5.664816e-03     4               0.886179                0.730067\
1999    S                  mensagem  ...  8.031249e-04     4               0.886179                0.730067\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8699186991869918, 'O': 0.7598463016330451\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.779939e-01     3               0.869919                0.759846\
1       S                   crian\'e7a  ...  9.383389e-01     3               0.869919                0.759846\
2       S                 encomenda  ...  1.957457e-01     3               0.869919                0.759846\
3       S                 encomenda  ...  3.586215e-01     3               0.869919                0.759846\
4       S                 encomenda  ...  5.072023e-01     3               0.869919                0.759846\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.956164e-08     3               0.869919                0.759846\
1996    O                            ...  1.261718e-09     3               0.869919                0.759846\
1997    S                     Laura  ...  7.807990e-01     3               0.869919                0.759846\
1998    A                       pai  ...  2.880551e-05     3               0.869919                0.759846\
1999    S                  mensagem  ...  4.656676e-02     3               0.869919                0.759846\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8536585365853658, 'O': 0.5524542829643888\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999981     2               0.853659                0.552454\
1       S                   crian\'e7a  ...      0.042457     2               0.853659                0.552454\
2       S                 encomenda  ...      0.947267     2               0.853659                0.552454\
3       S                 encomenda  ...      0.962712     2               0.853659                0.552454\
4       S                 encomenda  ...      0.962957     2               0.853659                0.552454\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000080     2               0.853659                0.552454\
1996    O                            ...      0.000005     2               0.853659                0.552454\
1997    S                     Laura  ...      0.993597     2               0.853659                0.552454\
1998    A                       pai  ...      0.000024     2               0.853659                0.552454\
1999    S                  mensagem  ...      0.500000     2               0.853659                0.552454\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.8373983739837398, 'O': 0.5620789220404235\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999973     1               0.837398                0.562079\
1       S                   crian\'e7a  ...      0.000390     1               0.837398                0.562079\
2       S                 encomenda  ...      0.565444     1               0.837398                0.562079\
3       S                 encomenda  ...      0.536777     1               0.837398                0.562079\
4       S                 encomenda  ...      0.561542     1               0.837398                0.562079\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.009112     1               0.837398                0.562079\
1996    O                            ...      0.001145     1               0.837398                0.562079\
1997    S                     Laura  ...      0.871915     1               0.837398                0.562079\
1998    A                       pai  ...      0.015469     1               0.837398                0.562079\
1999    S                  mensagem  ...      0.000058     1               0.837398                0.562079\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6422764227642277, 'O': 0.5851780558229066\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999999     0               0.642276                0.585178\
1       S                   crian\'e7a  ...      0.291985     0               0.642276                0.585178\
2       S                 encomenda  ...      0.843701     0               0.642276                0.585178\
3       S                 encomenda  ...      0.843701     0               0.642276                0.585178\
4       S                 encomenda  ...      0.843701     0               0.642276                0.585178\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.040148     0               0.642276                0.585178\
1996    O                            ...      0.836510     0               0.642276                0.585178\
1997    S                     Laura  ...      0.888757     0               0.642276                0.585178\
1998    A                       pai  ...      0.067321     0               0.642276                0.585178\
1999    S                  mensagem  ...      0.000153     0               0.642276                0.585178\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_pt_cintil-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud-train.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2089 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2089/2089 [00:00<00:00, 4726.77it/s]\
Loaded 2088 sentences from disk.\
length of bert outputs 2089\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999976    12               0.960976                 0.85929\
1       S                   crian\'e7a  ...      0.999921    12               0.960976                 0.85929\
2       S                 encomenda  ...      0.777306    12               0.960976                 0.85929\
3       S                 encomenda  ...      0.748536    12               0.960976                 0.85929\
4       S                 encomenda  ...      0.848295    12               0.960976                 0.85929\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.001448    12               0.960976                 0.85929\
1996    O                            ...      0.003375    12               0.960976                 0.85929\
1997    S                     Laura  ...      0.996855    12               0.960976                 0.85929\
1998    A                       pai  ...      0.999997    12               0.960976                 0.85929\
1999    S                  mensagem  ...      0.999992    12               0.960976                 0.85929\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999998e-01    11               0.980488                0.912568\
1       S                   crian\'e7a  ...  9.987245e-01    11               0.980488                0.912568\
2       S                 encomenda  ...  9.911924e-01    11               0.980488                0.912568\
3       S                 encomenda  ...  9.431111e-01    11               0.980488                0.912568\
4       S                 encomenda  ...  9.971139e-01    11               0.980488                0.912568\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.162073e-07    11               0.980488                0.912568\
1996    O                            ...  2.527422e-01    11               0.980488                0.912568\
1997    S                     Laura  ...  9.999142e-01    11               0.980488                0.912568\
1998    A                       pai  ...  1.000000e+00    11               0.980488                0.912568\
1999    S                  mensagem  ...  9.999787e-01    11               0.980488                0.912568\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000    10                0.97561                0.904372\
1       S                   crian\'e7a  ...      1.000000    10                0.97561                0.904372\
2       S                 encomenda  ...      0.994405    10                0.97561                0.904372\
3       S                 encomenda  ...      0.982275    10                0.97561                0.904372\
4       S                 encomenda  ...      0.986013    10                0.97561                0.904372\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000046    10                0.97561                0.904372\
1996    O                            ...      0.774356    10                0.97561                0.904372\
1997    S                     Laura  ...      1.000000    10                0.97561                0.904372\
1998    A                       pai  ...      1.000000    10                0.97561                0.904372\
1999    S                  mensagem  ...      0.999925    10                0.97561                0.904372\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     9               0.980488                0.924863\
1       S                   crian\'e7a  ...  1.000000e+00     9               0.980488                0.924863\
2       S                 encomenda  ...  1.000000e+00     9               0.980488                0.924863\
3       S                 encomenda  ...  1.000000e+00     9               0.980488                0.924863\
4       S                 encomenda  ...  1.000000e+00     9               0.980488                0.924863\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.209952e-07     9               0.980488                0.924863\
1996    O                            ...  2.762958e-01     9               0.980488                0.924863\
1997    S                     Laura  ...  1.000000e+00     9               0.980488                0.924863\
1998    A                       pai  ...  1.000000e+00     9               0.980488                0.924863\
1999    S                  mensagem  ...  1.000000e+00     9               0.980488                0.924863\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999780     8               0.985366                0.941257\
1       S                   crian\'e7a  ...      1.000000     8               0.985366                0.941257\
2       S                 encomenda  ...      1.000000     8               0.985366                0.941257\
3       S                 encomenda  ...      1.000000     8               0.985366                0.941257\
4       S                 encomenda  ...      1.000000     8               0.985366                0.941257\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000009     8               0.985366                0.941257\
1996    O                            ...      0.556539     8               0.985366                0.941257\
1997    S                     Laura  ...      1.000000     8               0.985366                0.941257\
1998    A                       pai  ...      1.000000     8               0.985366                0.941257\
1999    S                  mensagem  ...      1.000000     8               0.985366                0.941257\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     7               0.980488                0.939891\
1       S                   crian\'e7a  ...      1.000000     7               0.980488                0.939891\
2       S                 encomenda  ...      0.999476     7               0.980488                0.939891\
3       S                 encomenda  ...      1.000000     7               0.980488                0.939891\
4       S                 encomenda  ...      0.999999     7               0.980488                0.939891\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000003     7               0.980488                0.939891\
1996    O                            ...      0.862535     7               0.980488                0.939891\
1997    S                     Laura  ...      1.000000     7               0.980488                0.939891\
1998    A                       pai  ...      1.000000     7               0.980488                0.939891\
1999    S                  mensagem  ...      1.000000     7               0.980488                0.939891\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     6                0.97561                0.927596\
1       S                   crian\'e7a  ...      1.000000     6                0.97561                0.927596\
2       S                 encomenda  ...      1.000000     6                0.97561                0.927596\
3       S                 encomenda  ...      1.000000     6                0.97561                0.927596\
4       S                 encomenda  ...      0.999957     6                0.97561                0.927596\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000233     6                0.97561                0.927596\
1996    O                            ...      0.954907     6                0.97561                0.927596\
1997    S                     Laura  ...      1.000000     6                0.97561                0.927596\
1998    A                       pai  ...      1.000000     6                0.97561                0.927596\
1999    S                  mensagem  ...      1.000000     6                0.97561                0.927596\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     5               0.970732                0.901639\
1       S                   crian\'e7a  ...      1.000000     5               0.970732                0.901639\
2       S                 encomenda  ...      0.999957     5               0.970732                0.901639\
3       S                 encomenda  ...      0.999994     5               0.970732                0.901639\
4       S                 encomenda  ...      0.999992     5               0.970732                0.901639\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000005     5               0.970732                0.901639\
1996    O                            ...      0.384318     5               0.970732                0.901639\
1997    S                     Laura  ...      1.000000     5               0.970732                0.901639\
1998    A                       pai  ...      0.999106     5               0.970732                0.901639\
1999    S                  mensagem  ...      1.000000     5               0.970732                0.901639\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     4               0.912195                0.826503\
1       S                   crian\'e7a  ...      1.000000     4               0.912195                0.826503\
2       S                 encomenda  ...      0.999999     4               0.912195                0.826503\
3       S                 encomenda  ...      1.000000     4               0.912195                0.826503\
4       S                 encomenda  ...      1.000000     4               0.912195                0.826503\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000069     4               0.912195                0.826503\
1996    O                            ...      0.507114     4               0.912195                0.826503\
1997    S                     Laura  ...      1.000000     4               0.912195                0.826503\
1998    A                       pai  ...      0.999999     4               0.912195                0.826503\
1999    S                  mensagem  ...      1.000000     4               0.912195                0.826503\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.992979e-01     3               0.936585                0.815574\
1       S                   crian\'e7a  ...  9.990861e-01     3               0.936585                0.815574\
2       S                 encomenda  ...  9.928831e-01     3               0.936585                0.815574\
3       S                 encomenda  ...  9.960468e-01     3               0.936585                0.815574\
4       S                 encomenda  ...  9.999850e-01     3               0.936585                0.815574\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  6.771522e-07     3               0.936585                0.815574\
1996    O                            ...  4.509466e-01     3               0.936585                0.815574\
1997    S                     Laura  ...  9.998507e-01     3               0.936585                0.815574\
1998    A                       pai  ...  9.864442e-01     3               0.936585                0.815574\
1999    S                  mensagem  ...  9.999590e-01     3               0.936585                0.815574\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999998     2               0.858537                0.717213\
1       S                   crian\'e7a  ...      0.997562     2               0.858537                0.717213\
2       S                 encomenda  ...      0.999845     2               0.858537                0.717213\
3       S                 encomenda  ...      0.999969     2               0.858537                0.717213\
4       S                 encomenda  ...      0.999964     2               0.858537                0.717213\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000603     2               0.858537                0.717213\
1996    O                            ...      0.457899     2               0.858537                0.717213\
1997    S                     Laura  ...      1.000000     2               0.858537                0.717213\
1998    A                       pai  ...      0.983004     2               0.858537                0.717213\
1999    S                  mensagem  ...      0.500000     2               0.858537                0.717213\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.969298     1               0.780488                0.709016\
1       S                   crian\'e7a  ...      0.994003     1               0.780488                0.709016\
2       S                 encomenda  ...      0.999946     1               0.780488                0.709016\
3       S                 encomenda  ...      0.999976     1               0.780488                0.709016\
4       S                 encomenda  ...      0.994613     1               0.780488                0.709016\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.017272     1               0.780488                0.709016\
1996    O                            ...      0.007201     1               0.780488                0.709016\
1997    S                     Laura  ...      0.998828     1               0.780488                0.709016\
1998    A                       pai  ...      0.999998     1               0.780488                0.709016\
1999    S                  mensagem  ...      1.000000     1               0.780488                0.709016\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     0               0.790244                0.665301\
1       S                   crian\'e7a  ...      1.000000     0               0.790244                0.665301\
2       S                 encomenda  ...      0.999732     0               0.790244                0.665301\
3       S                 encomenda  ...      0.999732     0               0.790244                0.665301\
4       S                 encomenda  ...      0.999732     0               0.790244                0.665301\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.702626     0               0.790244                0.665301\
1996    O                            ...      0.922541     0               0.790244                0.665301\
1997    S                     Laura  ...      1.000000     0               0.790244                0.665301\
1998    A                       pai  ...      0.999912     0               0.790244                0.665301\
1999    S                  mensagem  ...      1.000000     0               0.790244                0.665301\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_pt_cintil-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud-train.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2089 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2089/2089 [00:00<00:00, 4797.80it/s]\
Loaded 2088 sentences from disk.\
length of bert outputs 2089\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999917    12               0.958763                0.929329\
1       S                   crian\'e7a  ...      0.999987    12               0.958763                0.929329\
2       S                 encomenda  ...      0.258876    12               0.958763                0.929329\
3       S                 encomenda  ...      0.277972    12               0.958763                0.929329\
4       S                 encomenda  ...      0.561804    12               0.958763                0.929329\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000003    12               0.958763                0.929329\
1996    O                            ...      0.001698    12               0.958763                0.929329\
1997    S                     Laura  ...      0.980803    12               0.958763                0.929329\
1998    A                       pai  ...      1.000000    12               0.958763                0.929329\
1999    S                  mensagem  ...      0.999587    12               0.958763                0.929329\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999998e-01    11               0.958763                0.975265\
1       S                   crian\'e7a  ...  9.999685e-01    11               0.958763                0.975265\
2       S                 encomenda  ...  9.991347e-01    11               0.958763                0.975265\
3       S                 encomenda  ...  9.582087e-01    11               0.958763                0.975265\
4       S                 encomenda  ...  9.993135e-01    11               0.958763                0.975265\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  4.319539e-10    11               0.958763                0.975265\
1996    O                            ...  1.171412e-05    11               0.958763                0.975265\
1997    S                     Laura  ...  9.999924e-01    11               0.958763                0.975265\
1998    A                       pai  ...  1.000000e+00    11               0.958763                0.975265\
1999    S                  mensagem  ...  9.999995e-01    11               0.958763                0.975265\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999999e-01    10               0.958763                0.961131\
1       S                   crian\'e7a  ...  1.000000e+00    10               0.958763                0.961131\
2       S                 encomenda  ...  9.999889e-01    10               0.958763                0.961131\
3       S                 encomenda  ...  9.999334e-01    10               0.958763                0.961131\
4       S                 encomenda  ...  9.999408e-01    10               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.802643e-09    10               0.958763                0.961131\
1996    O                            ...  2.331378e-06    10               0.958763                0.961131\
1997    S                     Laura  ...  9.999998e-01    10               0.958763                0.961131\
1998    A                       pai  ...  1.000000e+00    10               0.958763                0.961131\
1999    S                  mensagem  ...  9.999626e-01    10               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999994e-01     9               0.958763                0.971731\
1       S                   crian\'e7a  ...  1.000000e+00     9               0.958763                0.971731\
2       S                 encomenda  ...  9.999999e-01     9               0.958763                0.971731\
3       S                 encomenda  ...  9.999998e-01     9               0.958763                0.971731\
4       S                 encomenda  ...  9.999995e-01     9               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.389718e-12     9               0.958763                0.971731\
1996    O                            ...  6.441917e-04     9               0.958763                0.971731\
1997    S                     Laura  ...  1.000000e+00     9               0.958763                0.971731\
1998    A                       pai  ...  1.000000e+00     9               0.958763                0.971731\
1999    S                  mensagem  ...  1.000000e+00     9               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.976190e-01     8               0.958763                0.961131\
1       S                   crian\'e7a  ...  1.000000e+00     8               0.958763                0.961131\
2       S                 encomenda  ...  9.998618e-01     8               0.958763                0.961131\
3       S                 encomenda  ...  9.997296e-01     8               0.958763                0.961131\
4       S                 encomenda  ...  9.997810e-01     8               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  4.835108e-10     8               0.958763                0.961131\
1996    O                            ...  1.626150e-04     8               0.958763                0.961131\
1997    S                     Laura  ...  9.999940e-01     8               0.958763                0.961131\
1998    A                       pai  ...  1.000000e+00     8               0.958763                0.961131\
1999    S                  mensagem  ...  1.000000e+00     8               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999921e-01     7               0.958763                0.971731\
1       S                   crian\'e7a  ...  1.000000e+00     7               0.958763                0.971731\
2       S                 encomenda  ...  9.981267e-01     7               0.958763                0.971731\
3       S                 encomenda  ...  9.999979e-01     7               0.958763                0.971731\
4       S                 encomenda  ...  9.999986e-01     7               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.887746e-12     7               0.958763                0.971731\
1996    O                            ...  2.311556e-08     7               0.958763                0.971731\
1997    S                     Laura  ...  9.999987e-01     7               0.958763                0.971731\
1998    A                       pai  ...  1.000000e+00     7               0.958763                0.971731\
1999    S                  mensagem  ...  9.999976e-01     7               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     6               0.938144                0.968198\
1       S                   crian\'e7a  ...  1.000000e+00     6               0.938144                0.968198\
2       S                 encomenda  ...  9.999983e-01     6               0.938144                0.968198\
3       S                 encomenda  ...  9.999996e-01     6               0.938144                0.968198\
4       S                 encomenda  ...  9.994630e-01     6               0.938144                0.968198\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.288392e-06     6               0.938144                0.968198\
1996    O                            ...  1.755627e-07     6               0.938144                0.968198\
1997    S                     Laura  ...  1.000000e+00     6               0.938144                0.968198\
1998    A                       pai  ...  1.000000e+00     6               0.938144                0.968198\
1999    S                  mensagem  ...  9.999999e-01     6               0.938144                0.968198\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     5               0.969072                0.943463\
1       S                   crian\'e7a  ...  1.000000e+00     5               0.969072                0.943463\
2       S                 encomenda  ...  9.968244e-01     5               0.969072                0.943463\
3       S                 encomenda  ...  9.997893e-01     5               0.969072                0.943463\
4       S                 encomenda  ...  9.997917e-01     5               0.969072                0.943463\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  4.106539e-11     5               0.969072                0.943463\
1996    O                            ...  5.130847e-05     5               0.969072                0.943463\
1997    S                     Laura  ...  1.000000e+00     5               0.969072                0.943463\
1998    A                       pai  ...  9.998236e-01     5               0.969072                0.943463\
1999    S                  mensagem  ...  9.999995e-01     5               0.969072                0.943463\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  1.000000e+00     4               0.917526                0.946996\
1       S                   crian\'e7a  ...  1.000000e+00     4               0.917526                0.946996\
2       S                 encomenda  ...  7.943341e-01     4               0.917526                0.946996\
3       S                 encomenda  ...  9.680672e-01     4               0.917526                0.946996\
4       S                 encomenda  ...  9.636616e-01     4               0.917526                0.946996\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.370775e-09     4               0.917526                0.946996\
1996    O                            ...  7.952538e-02     4               0.917526                0.946996\
1997    S                     Laura  ...  1.000000e+00     4               0.917526                0.946996\
1998    A                       pai  ...  1.000000e+00     4               0.917526                0.946996\
1999    S                  mensagem  ...  1.000000e+00     4               0.917526                0.946996\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999080e-01     3               0.938144                0.936396\
1       S                   crian\'e7a  ...  9.998645e-01     3               0.938144                0.936396\
2       S                 encomenda  ...  9.915936e-01     3               0.938144                0.936396\
3       S                 encomenda  ...  9.939203e-01     3               0.938144                0.936396\
4       S                 encomenda  ...  9.999720e-01     3               0.938144                0.936396\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.544785e-08     3               0.938144                0.936396\
1996    O                            ...  9.839219e-01     3               0.938144                0.936396\
1997    S                     Laura  ...  9.999995e-01     3               0.938144                0.936396\
1998    A                       pai  ...  9.999977e-01     3               0.938144                0.936396\
1999    S                  mensagem  ...  9.998827e-01     3               0.938144                0.936396\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...  9.999999e-01     2               0.783505                0.795053\
1       S                   crian\'e7a  ...  9.998075e-01     2               0.783505                0.795053\
2       S                 encomenda  ...  9.993451e-01     2               0.783505                0.795053\
3       S                 encomenda  ...  9.994387e-01     2               0.783505                0.795053\
4       S                 encomenda  ...  9.994628e-01     2               0.783505                0.795053\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.566804e-07     2               0.783505                0.795053\
1996    O                            ...  2.176025e-02     2               0.783505                0.795053\
1997    S                     Laura  ...  1.000000e+00     2               0.783505                0.795053\
1998    A                       pai  ...  6.417305e-01     2               0.783505                0.795053\
1999    S                  mensagem  ...  5.000000e-01     2               0.783505                0.795053\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     1               0.793814                0.773852\
1       S                   crian\'e7a  ...      0.999988     1               0.793814                0.773852\
2       S                 encomenda  ...      0.999999     1               0.793814                0.773852\
3       S                 encomenda  ...      0.999999     1               0.793814                0.773852\
4       S                 encomenda  ...      0.999149     1               0.793814                0.773852\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.002383     1               0.793814                0.773852\
1996    O                            ...      0.554169     1               0.793814                0.773852\
1997    S                     Laura  ...      1.000000     1               0.793814                0.773852\
1998    A                       pai  ...      0.989594     1               0.793814                0.773852\
1999    S                  mensagem  ...      1.000000     1               0.793814                0.773852\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     0               0.721649                0.816254\
1       S                   crian\'e7a  ...      1.000000     0               0.721649                0.816254\
2       S                 encomenda  ...      1.000000     0               0.721649                0.816254\
3       S                 encomenda  ...      1.000000     0               0.721649                0.816254\
4       S                 encomenda  ...      1.000000     0               0.721649                0.816254\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.002510     0               0.721649                0.816254\
1996    O                            ...      0.999626     0               0.721649                0.816254\
1997    S                     Laura  ...      1.000000     0               0.721649                0.816254\
1998    A                       pai  ...      0.999751     0               0.721649                0.816254\
1999    S                  mensagem  ...      1.000000     0               0.721649                0.816254\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_pt_cintil-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud-train.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2089 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2089/2089 [00:00<00:00, 4851.82it/s]\
Loaded 2088 sentences from disk.\
length of bert outputs 2089\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.998646    12                0.84556                0.873118\
1       S                   crian\'e7a  ...      0.999919    12                0.84556                0.873118\
2       S                 encomenda  ...      0.013987    12                0.84556                0.873118\
3       S                 encomenda  ...      0.004216    12                0.84556                0.873118\
4       S                 encomenda  ...      0.003834    12                0.84556                0.873118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.017518    12                0.84556                0.873118\
1996    O                            ...      0.392038    12                0.84556                0.873118\
1997    S                     Laura  ...      0.993871    12                0.84556                0.873118\
1998    A                       pai  ...      1.000000    12                0.84556                0.873118\
1999    S                  mensagem  ...      1.000000    12                0.84556                0.873118\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999997    11               0.880309                0.896774\
1       S                   crian\'e7a  ...      0.999981    11               0.880309                0.896774\
2       S                 encomenda  ...      0.991804    11               0.880309                0.896774\
3       S                 encomenda  ...      0.800285    11               0.880309                0.896774\
4       S                 encomenda  ...      0.897079    11               0.880309                0.896774\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.001292    11               0.880309                0.896774\
1996    O                            ...      0.961844    11               0.880309                0.896774\
1997    S                     Laura  ...      0.995992    11               0.880309                0.896774\
1998    A                       pai  ...      1.000000    11               0.880309                0.896774\
1999    S                  mensagem  ...      1.000000    11               0.880309                0.896774\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000    10               0.915058                0.922581\
1       S                   crian\'e7a  ...      1.000000    10               0.915058                0.922581\
2       S                 encomenda  ...      0.989019    10               0.915058                0.922581\
3       S                 encomenda  ...      0.408001    10               0.915058                0.922581\
4       S                 encomenda  ...      0.388182    10               0.915058                0.922581\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000036    10               0.915058                0.922581\
1996    O                            ...      0.386176    10               0.915058                0.922581\
1997    S                     Laura  ...      0.999885    10               0.915058                0.922581\
1998    A                       pai  ...      1.000000    10               0.915058                0.922581\
1999    S                  mensagem  ...      0.999985    10               0.915058                0.922581\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999998     9               0.903475                0.909677\
1       S                   crian\'e7a  ...      1.000000     9               0.903475                0.909677\
2       S                 encomenda  ...      0.999960     9               0.903475                0.909677\
3       S                 encomenda  ...      0.999751     9               0.903475                0.909677\
4       S                 encomenda  ...      0.999050     9               0.903475                0.909677\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000148     9               0.903475                0.909677\
1996    O                            ...      0.232631     9               0.903475                0.909677\
1997    S                     Laura  ...      0.999879     9               0.903475                0.909677\
1998    A                       pai  ...      1.000000     9               0.903475                0.909677\
1999    S                  mensagem  ...      1.000000     9               0.903475                0.909677\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.998622     8               0.891892                0.913978\
1       S                   crian\'e7a  ...      1.000000     8               0.891892                0.913978\
2       S                 encomenda  ...      0.999999     8               0.891892                0.913978\
3       S                 encomenda  ...      1.000000     8               0.891892                0.913978\
4       S                 encomenda  ...      1.000000     8               0.891892                0.913978\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000119     8               0.891892                0.913978\
1996    O                            ...      0.690178     8               0.891892                0.913978\
1997    S                     Laura  ...      0.999873     8               0.891892                0.913978\
1998    A                       pai  ...      1.000000     8               0.891892                0.913978\
1999    S                  mensagem  ...      1.000000     8               0.891892                0.913978\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999953     7               0.911197                0.892473\
1       S                   crian\'e7a  ...      1.000000     7               0.911197                0.892473\
2       S                 encomenda  ...      0.999991     7               0.911197                0.892473\
3       S                 encomenda  ...      1.000000     7               0.911197                0.892473\
4       S                 encomenda  ...      1.000000     7               0.911197                0.892473\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000035     7               0.911197                0.892473\
1996    O                            ...      0.998225     7               0.911197                0.892473\
1997    S                     Laura  ...      0.999959     7               0.911197                0.892473\
1998    A                       pai  ...      1.000000     7               0.911197                0.892473\
1999    S                  mensagem  ...      1.000000     7               0.911197                0.892473\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     6               0.888031                0.890323\
1       S                   crian\'e7a  ...      1.000000     6               0.888031                0.890323\
2       S                 encomenda  ...      1.000000     6               0.888031                0.890323\
3       S                 encomenda  ...      1.000000     6               0.888031                0.890323\
4       S                 encomenda  ...      0.999795     6               0.888031                0.890323\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.010751     6               0.888031                0.890323\
1996    O                            ...      0.999483     6               0.888031                0.890323\
1997    S                     Laura  ...      1.000000     6               0.888031                0.890323\
1998    A                       pai  ...      1.000000     6               0.888031                0.890323\
1999    S                  mensagem  ...      1.000000     6               0.888031                0.890323\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     5               0.803089                 0.84086\
1       S                   crian\'e7a  ...      1.000000     5               0.803089                 0.84086\
2       S                 encomenda  ...      0.995112     5               0.803089                 0.84086\
3       S                 encomenda  ...      0.999373     5               0.803089                 0.84086\
4       S                 encomenda  ...      0.999358     5               0.803089                 0.84086\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.004055     5               0.803089                 0.84086\
1996    O                            ...      0.895043     5               0.803089                 0.84086\
1997    S                     Laura  ...      1.000000     5               0.803089                 0.84086\
1998    A                       pai  ...      0.999917     5               0.803089                 0.84086\
1999    S                  mensagem  ...      1.000000     5               0.803089                 0.84086\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     4               0.826255                0.756989\
1       S                   crian\'e7a  ...      1.000000     4               0.826255                0.756989\
2       S                 encomenda  ...      0.959656     4               0.826255                0.756989\
3       S                 encomenda  ...      0.991569     4               0.826255                0.756989\
4       S                 encomenda  ...      0.989748     4               0.826255                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.082601     4               0.826255                0.756989\
1996    O                            ...      0.680542     4               0.826255                0.756989\
1997    S                     Laura  ...      1.000000     4               0.826255                0.756989\
1998    A                       pai  ...      0.999993     4               0.826255                0.756989\
1999    S                  mensagem  ...      0.999997     4               0.826255                0.756989\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999954     3                0.80695                0.787097\
1       S                   crian\'e7a  ...      0.999995     3                0.80695                0.787097\
2       S                 encomenda  ...      0.744217     3                0.80695                0.787097\
3       S                 encomenda  ...      0.789539     3                0.80695                0.787097\
4       S                 encomenda  ...      0.949290     3                0.80695                0.787097\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.002535     3                0.80695                0.787097\
1996    O                            ...      0.941016     3                0.80695                0.787097\
1997    S                     Laura  ...      0.999851     3                0.80695                0.787097\
1998    A                       pai  ...      1.000000     3                0.80695                0.787097\
1999    S                  mensagem  ...      0.998252     3                0.80695                0.787097\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000     2               0.722008                0.825806\
1       S                   crian\'e7a  ...      0.999946     2               0.722008                0.825806\
2       S                 encomenda  ...      0.999948     2               0.722008                0.825806\
3       S                 encomenda  ...      0.999966     2               0.722008                0.825806\
4       S                 encomenda  ...      0.999964     2               0.722008                0.825806\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.385664     2               0.722008                0.825806\
1996    O                            ...      0.172044     2               0.722008                0.825806\
1997    S                     Laura  ...      1.000000     2               0.722008                0.825806\
1998    A                       pai  ...      0.999998     2               0.722008                0.825806\
1999    S                  mensagem  ...      0.500000     2               0.722008                0.825806\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999755     1               0.675676                0.756989\
1       S                   crian\'e7a  ...      1.000000     1               0.675676                0.756989\
2       S                 encomenda  ...      1.000000     1               0.675676                0.756989\
3       S                 encomenda  ...      1.000000     1               0.675676                0.756989\
4       S                 encomenda  ...      0.999840     1               0.675676                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.561417     1               0.675676                0.756989\
1996    O                            ...      0.986648     1               0.675676                0.756989\
1997    S                     Laura  ...      1.000000     1               0.675676                0.756989\
1998    A                       pai  ...      0.999996     1               0.675676                0.756989\
1999    S                  mensagem  ...      1.000000     1               0.675676                0.756989\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999829     0               0.722008                0.673118\
1       S                   crian\'e7a  ...      1.000000     0               0.722008                0.673118\
2       S                 encomenda  ...      0.999993     0               0.722008                0.673118\
3       S                 encomenda  ...      0.999993     0               0.722008                0.673118\
4       S                 encomenda  ...      0.999993     0               0.722008                0.673118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.331736     0               0.722008                0.673118\
1996    O                            ...      0.999997     0               0.722008                0.673118\
1997    S                     Laura  ...      1.000000     0               0.722008                0.673118\
1998    A                       pai  ...      0.995158     0               0.722008                0.673118\
1999    S                  mensagem  ...      0.999996     0               0.722008                0.673118\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_pt_cintil-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud-train.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 2089 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_pt_cintil-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2089/2089 [00:00<00:00, 4848.47it/s]\
Loaded 2088 sentences from disk.\
length of bert outputs 2089\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999726    12               0.978723                0.872247\
1       S                   crian\'e7a  ...      1.000000    12               0.978723                0.872247\
2       S                 encomenda  ...      0.996388    12               0.978723                0.872247\
3       S                 encomenda  ...      0.972147    12               0.978723                0.872247\
4       S                 encomenda  ...      0.979705    12               0.978723                0.872247\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.186702    12               0.978723                0.872247\
1996    O                            ...      0.000013    12               0.978723                0.872247\
1997    S                     Laura  ...      0.999993    12               0.978723                0.872247\
1998    A                       pai  ...      1.000000    12               0.978723                0.872247\
1999    S                  mensagem  ...      0.999997    12               0.978723                0.872247\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000    11               0.978723                0.898678\
1       S                   crian\'e7a  ...      0.999978    11               0.978723                0.898678\
2       S                 encomenda  ...      0.428135    11               0.978723                0.898678\
3       S                 encomenda  ...      0.429502    11               0.978723                0.898678\
4       S                 encomenda  ...      0.634570    11               0.978723                0.898678\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000455    11               0.978723                0.898678\
1996    O                            ...      0.000671    11               0.978723                0.898678\
1997    S                     Laura  ...      1.000000    11               0.978723                0.898678\
1998    A                       pai  ...      1.000000    11               0.978723                0.898678\
1999    S                  mensagem  ...      0.999999    11               0.978723                0.898678\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      1.000000    10               0.978723                0.929515\
1       S                   crian\'e7a  ...      1.000000    10               0.978723                0.929515\
2       S                 encomenda  ...      0.260524    10               0.978723                0.929515\
3       S                 encomenda  ...      0.466950    10               0.978723                0.929515\
4       S                 encomenda  ...      0.516564    10               0.978723                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000475    10               0.978723                0.929515\
1996    O                            ...      0.001179    10               0.978723                0.929515\
1997    S                     Laura  ...      1.000000    10               0.978723                0.929515\
1998    A                       pai  ...      1.000000    10               0.978723                0.929515\
1999    S                  mensagem  ...      0.987172    10               0.978723                0.929515\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999995     9               0.989362                0.920705\
1       S                   crian\'e7a  ...      1.000000     9               0.989362                0.920705\
2       S                 encomenda  ...      0.915367     9               0.989362                0.920705\
3       S                 encomenda  ...      0.996908     9               0.989362                0.920705\
4       S                 encomenda  ...      0.993700     9               0.989362                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.002541     9               0.989362                0.920705\
1996    O                            ...      0.094308     9               0.989362                0.920705\
1997    S                     Laura  ...      1.000000     9               0.989362                0.920705\
1998    A                       pai  ...      1.000000     9               0.989362                0.920705\
1999    S                  mensagem  ...      0.999857     9               0.989362                0.920705\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.995430     8               0.989362                0.929515\
1       S                   crian\'e7a  ...      1.000000     8               0.989362                0.929515\
2       S                 encomenda  ...      0.856765     8               0.989362                0.929515\
3       S                 encomenda  ...      0.998060     8               0.989362                0.929515\
4       S                 encomenda  ...      0.995078     8               0.989362                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000646     8               0.989362                0.929515\
1996    O                            ...      0.441449     8               0.989362                0.929515\
1997    S                     Laura  ...      1.000000     8               0.989362                0.929515\
1998    A                       pai  ...      1.000000     8               0.989362                0.929515\
1999    S                  mensagem  ...      0.999897     8               0.989362                0.929515\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.998541     7               0.978723                 0.92511\
1       S                   crian\'e7a  ...      1.000000     7               0.978723                 0.92511\
2       S                 encomenda  ...      0.711436     7               0.978723                 0.92511\
3       S                 encomenda  ...      0.956876     7               0.978723                 0.92511\
4       S                 encomenda  ...      0.954724     7               0.978723                 0.92511\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000011     7               0.978723                 0.92511\
1996    O                            ...      0.993650     7               0.978723                 0.92511\
1997    S                     Laura  ...      1.000000     7               0.978723                 0.92511\
1998    A                       pai  ...      1.000000     7               0.978723                 0.92511\
1999    S                  mensagem  ...      0.332237     7               0.978723                 0.92511\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999998     6               0.957447                0.920705\
1       S                   crian\'e7a  ...      1.000000     6               0.957447                0.920705\
2       S                 encomenda  ...      0.999992     6               0.957447                0.920705\
3       S                 encomenda  ...      0.999999     6               0.957447                0.920705\
4       S                 encomenda  ...      0.998553     6               0.957447                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000111     6               0.957447                0.920705\
1996    O                            ...      0.952419     6               0.957447                0.920705\
1997    S                     Laura  ...      0.999999     6               0.957447                0.920705\
1998    A                       pai  ...      0.999978     6               0.957447                0.920705\
1999    S                  mensagem  ...      0.215324     6               0.957447                0.920705\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.999665     5               0.968085                0.863436\
1       S                   crian\'e7a  ...      0.999998     5               0.968085                0.863436\
2       S                 encomenda  ...      0.704507     5               0.968085                0.863436\
3       S                 encomenda  ...      0.986209     5               0.968085                0.863436\
4       S                 encomenda  ...      0.984015     5               0.968085                0.863436\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000164     5               0.968085                0.863436\
1996    O                            ...      0.522980     5               0.968085                0.863436\
1997    S                     Laura  ...      1.000000     5               0.968085                0.863436\
1998    A                       pai  ...      0.999616     5               0.968085                0.863436\
1999    S                  mensagem  ...      0.002019     5               0.968085                0.863436\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.844850     4               0.957447                0.797357\
1       S                   crian\'e7a  ...      1.000000     4               0.957447                0.797357\
2       S                 encomenda  ...      0.888790     4               0.957447                0.797357\
3       S                 encomenda  ...      0.982963     4               0.957447                0.797357\
4       S                 encomenda  ...      0.982040     4               0.957447                0.797357\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.493343     4               0.957447                0.797357\
1996    O                            ...      0.030612     4               0.957447                0.797357\
1997    S                     Laura  ...      1.000000     4               0.957447                0.797357\
1998    A                       pai  ...      1.000000     4               0.957447                0.797357\
1999    S                  mensagem  ...      0.047761     4               0.957447                0.797357\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.156214     3               0.914894                0.810573\
1       S                   crian\'e7a  ...      0.995155     3               0.914894                0.810573\
2       S                 encomenda  ...      0.045349     3               0.914894                0.810573\
3       S                 encomenda  ...      0.083757     3               0.914894                0.810573\
4       S                 encomenda  ...      0.011103     3               0.914894                0.810573\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.001848     3               0.914894                0.810573\
1996    O                            ...      0.023147     3               0.914894                0.810573\
1997    S                     Laura  ...      0.999027     3               0.914894                0.810573\
1998    A                       pai  ...      0.999795     3               0.914894                0.810573\
1999    S                  mensagem  ...      0.100398     3               0.914894                0.810573\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.324785     2               0.787234                0.674009\
1       S                   crian\'e7a  ...      0.995632     2               0.787234                0.674009\
2       S                 encomenda  ...      0.999788     2               0.787234                0.674009\
3       S                 encomenda  ...      0.999918     2               0.787234                0.674009\
4       S                 encomenda  ...      0.999916     2               0.787234                0.674009\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.999564     2               0.787234                0.674009\
1996    O                            ...      0.528033     2               0.787234                0.674009\
1997    S                     Laura  ...      1.000000     2               0.787234                0.674009\
1998    A                       pai  ...      0.999927     2               0.787234                0.674009\
1999    S                  mensagem  ...      0.500000     2               0.787234                0.674009\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.001292     1               0.765957                 0.69163\
1       S                   crian\'e7a  ...      0.998652     1               0.765957                 0.69163\
2       S                 encomenda  ...      0.998121     1               0.765957                 0.69163\
3       S                 encomenda  ...      0.998946     1               0.765957                 0.69163\
4       S                 encomenda  ...      0.975571     1               0.765957                 0.69163\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.947604     1               0.765957                 0.69163\
1996    O                            ...      0.969239     1               0.765957                 0.69163\
1997    S                     Laura  ...      1.000000     1               0.765957                 0.69163\
1998    A                       pai  ...      0.977510     1               0.765957                 0.69163\
1999    S                  mensagem  ...      0.222467     1               0.765957                 0.69163\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                   cliente  ...      0.987944     0               0.712766                0.788546\
1       S                   crian\'e7a  ...      0.999947     0               0.712766                0.788546\
2       S                 encomenda  ...      0.999878     0               0.712766                0.788546\
3       S                 encomenda  ...      0.999878     0               0.712766                0.788546\
4       S                 encomenda  ...      0.999878     0               0.712766                0.788546\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.965104     0               0.712766                0.788546\
1996    O                            ...      0.864870     0               0.712766                0.788546\
1997    S                     Laura  ...      1.000000     0               0.712766                0.788546\
1998    A                       pai  ...      0.994837     0               0.712766                0.788546\
1999    S                  mensagem  ...      0.996953     0               0.712766                0.788546\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/ko_kaist-ud_en_gum-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-train.conllu', train_lang_base_path='language_data/UD_Korean-Kaist-master/ko_kaist-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Counts of each role Counter(\{'O': 1132, 'A': 343, 'S': 270, 'S-passive': 215, 'S-expletive': 36, 'A-passive': 2, 'S-aux': 2\})\
Case counts per role defaultdict(<class 'collections.Counter'>, \{None: Counter(\{None: 33796\}), 'S': Counter(\{None: 270\}), 'A': Counter(\{None: 343\}), 'O': Counter(\{None: 1132\}), 'S-passive': Counter(\{None: 215\}), 'S-expletive': Counter(\{None: 36\}), 'A-passive': Counter(\{None: 2\}), 'S-aux': Counter(\{None: 2\})\})\
lengths of bert ids etc 1922 1922 1922 1922\
Saving all of the tokens and non-bert stuff to cached_datasets/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1922 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.hdf5\
Running 1922 sentences through BERT. This takes a while\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1922/1922 [01:07<00:00, 28.59it/s]\
length of bert outputs 1922\
On layer 12\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9186991869918699, 'O': 0.7310278578290106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.987731    12               0.918699                0.731028\
1       A                    labels  ...      0.933690    12               0.918699                0.731028\
2       O                            ...      0.010236    12               0.918699                0.731028\
3       S                    people  ...      0.081649    12               0.918699                0.731028\
4       O                            ...      0.999936    12               0.918699                0.731028\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000119    12               0.918699                0.731028\
1996    S                     Gomez  ...      0.999502    12               0.918699                0.731028\
1997    O                            ...      0.848072    12               0.918699                0.731028\
1998    A                     Betty  ...      0.994496    12               0.918699                0.731028\
1999    O                            ...      0.000323    12               0.918699                0.731028\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.7905859750240154\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999012    11               0.910569                0.790586\
1       A                    labels  ...      0.997988    11               0.910569                0.790586\
2       O                            ...      0.997364    11               0.910569                0.790586\
3       S                    people  ...      0.101122    11               0.910569                0.790586\
4       O                            ...      0.881417    11               0.910569                0.790586\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000831    11               0.910569                0.790586\
1996    S                     Gomez  ...      0.999985    11               0.910569                0.790586\
1997    O                            ...      0.097387    11               0.910569                0.790586\
1998    A                     Betty  ...      0.202053    11               0.910569                0.790586\
1999    O                            ...      0.000002    11               0.910569                0.790586\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.8213256484149856\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999913    10               0.886179                0.821326\
1       A                    labels  ...      1.000000    10               0.886179                0.821326\
2       O                            ...      0.737037    10               0.886179                0.821326\
3       S                    people  ...      0.003234    10               0.886179                0.821326\
4       O                            ...      0.044877    10               0.886179                0.821326\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000004    10               0.886179                0.821326\
1996    S                     Gomez  ...      0.999970    10               0.886179                0.821326\
1997    O                            ...      0.044109    10               0.886179                0.821326\
1998    A                     Betty  ...      0.980352    10               0.886179                0.821326\
1999    O                            ...      0.000352    10               0.886179                0.821326\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999988e-01     9               0.910569                0.855908\
1       A                    labels  ...  1.000000e+00     9               0.910569                0.855908\
2       O                            ...  1.983081e-02     9               0.910569                0.855908\
3       S                    people  ...  1.627459e-02     9               0.910569                0.855908\
4       O                            ...  6.467728e-02     9               0.910569                0.855908\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.770823e-04     9               0.910569                0.855908\
1996    S                     Gomez  ...  9.978271e-01     9               0.910569                0.855908\
1997    O                            ...  1.648120e-03     9               0.910569                0.855908\
1998    A                     Betty  ...  9.999993e-01     9               0.910569                0.855908\
1999    O                            ...  1.875769e-08     9               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  3.956691e-01     8               0.910569                0.855908\
1       A                    labels  ...  9.999999e-01     8               0.910569                0.855908\
2       O                            ...  5.999217e-04     8               0.910569                0.855908\
3       S                    people  ...  1.075279e-07     8               0.910569                0.855908\
4       O                            ...  4.016217e-04     8               0.910569                0.855908\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.951497e-03     8               0.910569                0.855908\
1996    S                     Gomez  ...  9.980180e-01     8               0.910569                0.855908\
1997    O                            ...  9.295154e-06     8               0.910569                0.855908\
1998    A                     Betty  ...  1.000000e+00     8               0.910569                0.855908\
1999    O                            ...  8.091385e-10     8               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8914505283381364\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  1.566972e-03     7               0.934959                0.891451\
1       A                    labels  ...  1.000000e+00     7               0.934959                0.891451\
2       O                            ...  3.259280e-01     7               0.934959                0.891451\
3       S                    people  ...  1.266446e-07     7               0.934959                0.891451\
4       O                            ...  5.145078e-02     7               0.934959                0.891451\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.034122e-01     7               0.934959                0.891451\
1996    S                     Gomez  ...  9.999999e-01     7               0.934959                0.891451\
1997    O                            ...  1.540502e-04     7               0.934959                0.891451\
1998    A                     Betty  ...  1.000000e+00     7               0.934959                0.891451\
1999    O                            ...  2.926177e-05     7               0.934959                0.891451\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8194044188280499\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.150074     6               0.934959                0.819404\
1       A                    labels  ...      1.000000     6               0.934959                0.819404\
2       O                            ...      0.385000     6               0.934959                0.819404\
3       S                    people  ...      0.000046     6               0.934959                0.819404\
4       O                            ...      0.355769     6               0.934959                0.819404\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000886     6               0.934959                0.819404\
1996    S                     Gomez  ...      0.992006     6               0.934959                0.819404\
1997    O                            ...      0.062978     6               0.934959                0.819404\
1998    A                     Betty  ...      1.000000     6               0.934959                0.819404\
1999    O                            ...      0.000002     6               0.934959                0.819404\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9024390243902439, 'O': 0.7425552353506244\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  7.192626e-01     5               0.902439                0.742555\
1       A                    labels  ...  9.950078e-01     5               0.902439                0.742555\
2       O                            ...  5.874875e-04     5               0.902439                0.742555\
3       S                    people  ...  6.113051e-02     5               0.902439                0.742555\
4       O                            ...  6.564511e-02     5               0.902439                0.742555\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.601763e-08     5               0.902439                0.742555\
1996    S                     Gomez  ...  9.999073e-01     5               0.902439                0.742555\
1997    O                            ...  9.961824e-01     5               0.902439                0.742555\
1998    A                     Betty  ...  9.731359e-01     5               0.902439                0.742555\
1999    O                            ...  1.097326e-06     5               0.902439                0.742555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.7300672430355427\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  7.423218e-01     4               0.886179                0.730067\
1       A                    labels  ...  9.766155e-01     4               0.886179                0.730067\
2       O                            ...  2.357096e-03     4               0.886179                0.730067\
3       S                    people  ...  9.497368e-01     4               0.886179                0.730067\
4       O                            ...  1.910019e-04     4               0.886179                0.730067\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.129505e-06     4               0.886179                0.730067\
1996    S                     Gomez  ...  6.889468e-01     4               0.886179                0.730067\
1997    O                            ...  9.046968e-01     4               0.886179                0.730067\
1998    A                     Betty  ...  4.474515e-01     4               0.886179                0.730067\
1999    O                            ...  1.082585e-10     4               0.886179                0.730067\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8699186991869918, 'O': 0.7598463016330451\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.852805e-01     3               0.869919                0.759846\
1       A                    labels  ...  3.284435e-01     3               0.869919                0.759846\
2       O                            ...  6.468654e-01     3               0.869919                0.759846\
3       S                    people  ...  9.590491e-01     3               0.869919                0.759846\
4       O                            ...  1.504189e-02     3               0.869919                0.759846\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.821189e-06     3               0.869919                0.759846\
1996    S                     Gomez  ...  3.049619e-01     3               0.869919                0.759846\
1997    O                            ...  7.538779e-01     3               0.869919                0.759846\
1998    A                     Betty  ...  5.376491e-03     3               0.869919                0.759846\
1999    O                            ...  9.399685e-07     3               0.869919                0.759846\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8536585365853658, 'O': 0.5524542829643888\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999718     2               0.853659                0.552454\
1       A                    labels  ...      0.001384     2               0.853659                0.552454\
2       O                            ...      0.000021     2               0.853659                0.552454\
3       S                    people  ...      0.994637     2               0.853659                0.552454\
4       O                            ...      0.069891     2               0.853659                0.552454\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000003     2               0.853659                0.552454\
1996    S                     Gomez  ...      0.442635     2               0.853659                0.552454\
1997    O                            ...      0.219806     2               0.853659                0.552454\
1998    A                     Betty  ...      0.529601     2               0.853659                0.552454\
1999    O                            ...      0.500000     2               0.853659                0.552454\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.8373983739837398, 'O': 0.5620789220404235\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.997177e-01     1               0.837398                0.562079\
1       A                    labels  ...  2.545476e-03     1               0.837398                0.562079\
2       O                            ...  1.269330e-01     1               0.837398                0.562079\
3       S                    people  ...  9.999063e-01     1               0.837398                0.562079\
4       O                            ...  6.616559e-02     1               0.837398                0.562079\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.274282e-04     1               0.837398                0.562079\
1996    S                     Gomez  ...  9.830521e-01     1               0.837398                0.562079\
1997    O                            ...  8.581144e-01     1               0.837398                0.562079\
1998    A                     Betty  ...  9.511791e-01     1               0.837398                0.562079\
1999    O                            ...  1.953652e-07     1               0.837398                0.562079\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6422764227642277, 'O': 0.5851780558229066\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.975211e-01     0               0.642276                0.585178\
1       A                    labels  ...  2.602770e-04     0               0.642276                0.585178\
2       O                            ...  5.502262e-06     0               0.642276                0.585178\
3       S                    people  ...  9.590533e-01     0               0.642276                0.585178\
4       O                            ...  7.545123e-02     0               0.642276                0.585178\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.231456e-02     0               0.642276                0.585178\
1996    S                     Gomez  ...  6.448697e-01     0               0.642276                0.585178\
1997    O                            ...  6.669351e-03     0               0.642276                0.585178\
1998    A                     Betty  ...  9.577618e-01     0               0.642276                0.585178\
1999    O                            ...  8.904268e-08     0               0.642276                0.585178\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/pt_cintil-ud_en_gum-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-train.conllu', train_lang_base_path='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1922 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1922/1922 [00:00<00:00, 3123.33it/s]\
Loaded 1921 sentences from disk.\
length of bert outputs 1922\
On layer 12\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9315403422982885, 'O': 0.8970099667774086\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999945e-01    12                0.93154                 0.89701\
1       A                    labels  ...  9.995756e-01    12                0.93154                 0.89701\
2       O                            ...  1.710005e-06    12                0.93154                 0.89701\
3       S                    people  ...  9.918213e-01    12                0.93154                 0.89701\
4       O                            ...  9.006335e-01    12                0.93154                 0.89701\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.865598e-05    12                0.93154                 0.89701\
1996    S                     Gomez  ...  9.999882e-01    12                0.93154                 0.89701\
1997    O                            ...  9.872283e-01    12                0.93154                 0.89701\
1998    A                     Betty  ...  9.407825e-01    12                0.93154                 0.89701\
1999    O                            ...  2.892492e-07    12                0.93154                 0.89701\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9535452322738386, 'O': 0.9346622369878184\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.858705e-01    11               0.953545                0.934662\
1       A                    labels  ...  9.908255e-01    11               0.953545                0.934662\
2       O                            ...  1.142837e-08    11               0.953545                0.934662\
3       S                    people  ...  2.047911e-01    11               0.953545                0.934662\
4       O                            ...  9.717747e-05    11               0.953545                0.934662\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.550878e-07    11               0.953545                0.934662\
1996    S                     Gomez  ...  9.994049e-01    11               0.953545                0.934662\
1997    O                            ...  4.392414e-02    11               0.953545                0.934662\
1998    A                     Betty  ...  9.999999e-01    11               0.953545                0.934662\
1999    O                            ...  1.262802e-09    11               0.953545                0.934662\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9633251833740831, 'O': 0.9446290143964563\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.987858e-01    10               0.963325                0.944629\
1       A                    labels  ...  9.999963e-01    10               0.963325                0.944629\
2       O                            ...  7.923144e-11    10               0.963325                0.944629\
3       S                    people  ...  2.702687e-02    10               0.963325                0.944629\
4       O                            ...  1.043081e-06    10               0.963325                0.944629\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.031701e-08    10               0.963325                0.944629\
1996    S                     Gomez  ...  9.997669e-01    10               0.963325                0.944629\
1997    O                            ...  5.458844e-02    10               0.963325                0.944629\
1998    A                     Betty  ...  1.000000e+00    10               0.963325                0.944629\
1999    O                            ...  9.305132e-06    10               0.963325                0.944629\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.960880195599022, 'O': 0.9501661129568106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999994e-01     9                0.96088                0.950166\
1       A                    labels  ...  9.999999e-01     9                0.96088                0.950166\
2       O                            ...  2.111843e-10     9                0.96088                0.950166\
3       S                    people  ...  3.076130e-02     9                0.96088                0.950166\
4       O                            ...  3.494633e-07     9                0.96088                0.950166\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.625424e-08     9                0.96088                0.950166\
1996    S                     Gomez  ...  9.933990e-01     9                0.96088                0.950166\
1997    O                            ...  1.218547e-04     9                0.96088                0.950166\
1998    A                     Betty  ...  1.000000e+00     9                0.96088                0.950166\
1999    O                            ...  5.174285e-12     9                0.96088                0.950166\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.964562569213732\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.950506e-01     8                0.95599                0.964563\
1       A                    labels  ...  9.999125e-01     8                0.95599                0.964563\
2       O                            ...  3.298354e-09     8                0.95599                0.964563\
3       S                    people  ...  3.359005e-04     8                0.95599                0.964563\
4       O                            ...  4.641129e-08     8                0.95599                0.964563\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.196332e-07     8                0.95599                0.964563\
1996    S                     Gomez  ...  9.856277e-01     8                0.95599                0.964563\
1997    O                            ...  1.187860e-05     8                0.95599                0.964563\
1998    A                     Betty  ...  1.000000e+00     8                0.95599                0.964563\
1999    O                            ...  2.890547e-10     8                0.95599                0.964563\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.9512735326688815\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.948227e-01     7                0.95599                0.951274\
1       A                    labels  ...  9.999918e-01     7                0.95599                0.951274\
2       O                            ...  5.563426e-06     7                0.95599                0.951274\
3       S                    people  ...  1.142268e-05     7                0.95599                0.951274\
4       O                            ...  2.820814e-07     7                0.95599                0.951274\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.380364e-06     7                0.95599                0.951274\
1996    S                     Gomez  ...  9.999974e-01     7                0.95599                0.951274\
1997    O                            ...  1.814676e-04     7                0.95599                0.951274\
1998    A                     Betty  ...  1.000000e+00     7                0.95599                0.951274\
1999    O                            ...  2.977809e-09     7                0.95599                0.951274\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9437652811735942, 'O': 0.9678848283499446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999329e-01     6               0.943765                0.967885\
1       A                    labels  ...  9.999981e-01     6               0.943765                0.967885\
2       O                            ...  8.154586e-09     6               0.943765                0.967885\
3       S                    people  ...  2.354933e-01     6               0.943765                0.967885\
4       O                            ...  1.051462e-02     6               0.943765                0.967885\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.196854e-05     6               0.943765                0.967885\
1996    S                     Gomez  ...  9.760762e-01     6               0.943765                0.967885\
1997    O                            ...  1.453685e-04     6               0.943765                0.967885\
1998    A                     Betty  ...  1.000000e+00     6               0.943765                0.967885\
1999    O                            ...  2.603168e-09     6               0.943765                0.967885\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9388753056234719, 'O': 0.9335548172757475\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.368221e-01     5               0.938875                0.933555\
1       A                    labels  ...  9.999226e-01     5               0.938875                0.933555\
2       O                            ...  1.621686e-09     5               0.938875                0.933555\
3       S                    people  ...  9.663253e-01     5               0.938875                0.933555\
4       O                            ...  6.525410e-05     5               0.938875                0.933555\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.893616e-09     5               0.938875                0.933555\
1996    S                     Gomez  ...  9.782070e-01     5               0.938875                0.933555\
1997    O                            ...  4.271790e-04     5               0.938875                0.933555\
1998    A                     Betty  ...  9.999985e-01     5               0.938875                0.933555\
1999    O                            ...  1.142885e-09     5               0.938875                0.933555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9070904645476773, 'O': 0.9080841638981174\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.977463e-01     4                0.90709                0.908084\
1       A                    labels  ...  9.999897e-01     4                0.90709                0.908084\
2       O                            ...  4.749077e-09     4                0.90709                0.908084\
3       S                    people  ...  9.999464e-01     4                0.90709                0.908084\
4       O                            ...  4.848509e-06     4                0.90709                0.908084\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.960185e-10     4                0.90709                0.908084\
1996    S                     Gomez  ...  9.759856e-01     4                0.90709                0.908084\
1997    O                            ...  7.111678e-03     4                0.90709                0.908084\
1998    A                     Betty  ...  1.000000e+00     4                0.90709                0.908084\
1999    O                            ...  2.348610e-09     4                0.90709                0.908084\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8997555012224939, 'O': 0.9136212624584718\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.184027e-01     3               0.899756                0.913621\
1       A                    labels  ...  9.488549e-01     3               0.899756                0.913621\
2       O                            ...  2.643175e-04     3               0.899756                0.913621\
3       S                    people  ...  9.048558e-01     3               0.899756                0.913621\
4       O                            ...  2.355402e-04     3               0.899756                0.913621\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.949300e-07     3               0.899756                0.913621\
1996    S                     Gomez  ...  9.733323e-01     3               0.899756                0.913621\
1997    O                            ...  2.409533e-01     3               0.899756                0.913621\
1998    A                     Betty  ...  1.000000e+00     3               0.899756                0.913621\
1999    O                            ...  7.984792e-04     3               0.899756                0.913621\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7652811735941321, 'O': 0.858250276854928\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999832     2               0.765281                 0.85825\
1       A                    labels  ...      0.997930     2               0.765281                 0.85825\
2       O                            ...      0.000205     2               0.765281                 0.85825\
3       S                    people  ...      0.999912     2               0.765281                 0.85825\
4       O                            ...      0.001016     2               0.765281                 0.85825\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000017     2               0.765281                 0.85825\
1996    S                     Gomez  ...      0.381143     2               0.765281                 0.85825\
1997    O                            ...      0.985368     2               0.765281                 0.85825\
1998    A                     Betty  ...      1.000000     2               0.765281                 0.85825\
1999    O                            ...      0.500000     2               0.765281                 0.85825\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7555012224938875, 'O': 0.8217054263565892\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  2.253433e-01     1               0.755501                0.821705\
1       A                    labels  ...  9.999942e-01     1               0.755501                0.821705\
2       O                            ...  1.208854e-07     1               0.755501                0.821705\
3       S                    people  ...  6.224571e-01     1               0.755501                0.821705\
4       O                            ...  3.489491e-02     1               0.755501                0.821705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.537759e-03     1               0.755501                0.821705\
1996    S                     Gomez  ...  5.002488e-03     1               0.755501                0.821705\
1997    O                            ...  9.927625e-01     1               0.755501                0.821705\
1998    A                     Betty  ...  1.000000e+00     1               0.755501                0.821705\
1999    O                            ...  7.910914e-05     1               0.755501                0.821705\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6968215158924206, 'O': 0.8073089700996677\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.742507     0               0.696822                0.807309\
1       A                    labels  ...      0.644918     0               0.696822                0.807309\
2       O                            ...      0.006405     0               0.696822                0.807309\
3       S                    people  ...      0.875911     0               0.696822                0.807309\
4       O                            ...      0.001038     0               0.696822                0.807309\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.010180     0               0.696822                0.807309\
1996    S                     Gomez  ...      0.202297     0               0.696822                0.807309\
1997    O                            ...      0.031359     0               0.696822                0.807309\
1998    A                     Betty  ...      0.999847     0               0.696822                0.807309\
1999    O                            ...      0.064044     0               0.696822                0.807309\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_en_gum-ud-test.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-test.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_en_gum-ud-test_aso_unbalanced_2000.pkl\
There are 1242 relevant tokens, and 1096 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-test_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1096/1096 [00:00<00:00, 3218.06it/s]\
Loaded 1095 sentences from disk.\
length of bert outputs 1096\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...      0.999798    12               0.960976                 0.85929\
1       O                              ...      0.000002    12               0.960976                 0.85929\
2       A               psychologists  ...      0.952351    12               0.960976                 0.85929\
3       O                              ...      0.007724    12               0.960976                 0.85929\
4       O                              ...      0.000817    12               0.960976                 0.85929\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...      0.015305    12               0.960976                 0.85929\
1238    O                              ...      0.000496    12               0.960976                 0.85929\
1239    A                      family  ...      1.000000    12               0.960976                 0.85929\
1240    O                              ...      0.077617    12               0.960976                 0.85929\
1241    O                              ...      0.000654    12               0.960976                 0.85929\
\
[1242 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.999896e-01    11               0.980488                0.912568\
1       O                              ...  1.549105e-08    11               0.980488                0.912568\
2       A               psychologists  ...  9.942850e-01    11               0.980488                0.912568\
3       O                              ...  3.965743e-07    11               0.980488                0.912568\
4       O                              ...  1.791579e-06    11               0.980488                0.912568\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.640634e-01    11               0.980488                0.912568\
1238    O                              ...  3.728022e-03    11               0.980488                0.912568\
1239    A                      family  ...  1.000000e+00    11               0.980488                0.912568\
1240    O                              ...  1.232400e-03    11               0.980488                0.912568\
1241    O                              ...  1.385678e-04    11               0.980488                0.912568\
\
[1242 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.999920e-01    10                0.97561                0.904372\
1       O                              ...  4.012357e-09    10                0.97561                0.904372\
2       A               psychologists  ...  9.734513e-01    10                0.97561                0.904372\
3       O                              ...  2.309317e-04    10                0.97561                0.904372\
4       O                              ...  2.156692e-07    10                0.97561                0.904372\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.510689e-01    10                0.97561                0.904372\
1238    O                              ...  2.067840e-04    10                0.97561                0.904372\
1239    A                      family  ...  1.000000e+00    10                0.97561                0.904372\
1240    O                              ...  1.948589e-06    10                0.97561                0.904372\
1241    O                              ...  1.538697e-03    10                0.97561                0.904372\
\
[1242 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.999979e-01     9               0.980488                0.924863\
1       O                              ...  2.526313e-09     9               0.980488                0.924863\
2       A               psychologists  ...  9.955375e-01     9               0.980488                0.924863\
3       O                              ...  4.049162e-07     9               0.980488                0.924863\
4       O                              ...  2.891935e-07     9               0.980488                0.924863\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.159996e-01     9               0.980488                0.924863\
1238    O                              ...  1.871026e-09     9               0.980488                0.924863\
1239    A                      family  ...  9.997404e-01     9               0.980488                0.924863\
1240    O                              ...  7.093301e-07     9               0.980488                0.924863\
1241    O                              ...  2.870390e-04     9               0.980488                0.924863\
\
[1242 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.985330e-01     8               0.985366                0.941257\
1       O                              ...  4.041012e-09     8               0.985366                0.941257\
2       A               psychologists  ...  9.605391e-01     8               0.985366                0.941257\
3       O                              ...  3.901750e-07     8               0.985366                0.941257\
4       O                              ...  5.908498e-04     8               0.985366                0.941257\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.997110e-01     8               0.985366                0.941257\
1238    O                              ...  1.259285e-09     8               0.985366                0.941257\
1239    A                      family  ...  9.999999e-01     8               0.985366                0.941257\
1240    O                              ...  7.903290e-09     8               0.985366                0.941257\
1241    O                              ...  4.749442e-06     8               0.985366                0.941257\
\
[1242 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.969264e-01     7               0.980488                0.939891\
1       O                              ...  2.848293e-05     7               0.980488                0.939891\
2       A               psychologists  ...  9.999790e-01     7               0.980488                0.939891\
3       O                              ...  7.896610e-06     7               0.980488                0.939891\
4       O                              ...  3.666775e-07     7               0.980488                0.939891\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.991508e-01     7               0.980488                0.939891\
1238    O                              ...  8.943203e-05     7               0.980488                0.939891\
1239    A                      family  ...  1.000000e+00     7               0.980488                0.939891\
1240    O                              ...  1.489927e-08     7               0.980488                0.939891\
1241    O                              ...  9.643280e-07     7               0.980488                0.939891\
\
[1242 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  1.000000e+00     6                0.97561                0.927596\
1       O                              ...  1.170576e-11     6                0.97561                0.927596\
2       A               psychologists  ...  9.999989e-01     6                0.97561                0.927596\
3       O                              ...  8.966814e-05     6                0.97561                0.927596\
4       O                              ...  5.524200e-05     6                0.97561                0.927596\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  1.000000e+00     6                0.97561                0.927596\
1238    O                              ...  1.696355e-03     6                0.97561                0.927596\
1239    A                      family  ...  1.000000e+00     6                0.97561                0.927596\
1240    O                              ...  4.720663e-05     6                0.97561                0.927596\
1241    O                              ...  3.824082e-05     6                0.97561                0.927596\
\
[1242 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  1.000000e+00     5               0.970732                0.901639\
1       O                              ...  7.264157e-11     5               0.970732                0.901639\
2       A               psychologists  ...  9.999995e-01     5               0.970732                0.901639\
3       O                              ...  8.281598e-07     5               0.970732                0.901639\
4       O                              ...  2.726252e-06     5               0.970732                0.901639\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.999998e-01     5               0.970732                0.901639\
1238    O                              ...  7.103676e-03     5               0.970732                0.901639\
1239    A                      family  ...  1.000000e+00     5               0.970732                0.901639\
1240    O                              ...  8.396272e-05     5               0.970732                0.901639\
1241    O                              ...  1.215528e-01     5               0.970732                0.901639\
\
[1242 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.999946e-01     4               0.912195                0.826503\
1       O                              ...  1.107189e-07     4               0.912195                0.826503\
2       A               psychologists  ...  1.000000e+00     4               0.912195                0.826503\
3       O                              ...  6.498344e-08     4               0.912195                0.826503\
4       O                              ...  7.630661e-05     4               0.912195                0.826503\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  1.000000e+00     4               0.912195                0.826503\
1238    O                              ...  1.924576e-03     4               0.912195                0.826503\
1239    A                      family  ...  9.995424e-01     4               0.912195                0.826503\
1240    O                              ...  3.902278e-04     4               0.912195                0.826503\
1241    O                              ...  2.636777e-01     4               0.912195                0.826503\
\
[1242 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  9.999759e-01     3               0.936585                0.815574\
1       O                              ...  2.132665e-10     3               0.936585                0.815574\
2       A               psychologists  ...  9.999998e-01     3               0.936585                0.815574\
3       O                              ...  6.046950e-09     3               0.936585                0.815574\
4       O                              ...  2.494881e-05     3               0.936585                0.815574\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.992521e-01     3               0.936585                0.815574\
1238    O                              ...  3.241930e-03     3               0.936585                0.815574\
1239    A                      family  ...  9.998502e-01     3               0.936585                0.815574\
1240    O                              ...  1.094232e-03     3               0.936585                0.815574\
1241    O                              ...  6.366702e-02     3               0.936585                0.815574\
\
[1242 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  1.000000e+00     2               0.858537                0.717213\
1       O                              ...  8.045943e-09     2               0.858537                0.717213\
2       A               psychologists  ...  9.999862e-01     2               0.858537                0.717213\
3       O                              ...  4.710369e-08     2               0.858537                0.717213\
4       O                              ...  1.010030e-02     2               0.858537                0.717213\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.999999e-01     2               0.858537                0.717213\
1238    O                              ...  9.705691e-01     2               0.858537                0.717213\
1239    A                      family  ...  9.999992e-01     2               0.858537                0.717213\
1240    O                              ...  9.997979e-01     2               0.858537                0.717213\
1241    O                              ...  9.896387e-01     2               0.858537                0.717213\
\
[1242 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...  1.000000e+00     1               0.780488                0.709016\
1       O                              ...  1.112423e-08     1               0.780488                0.709016\
2       A               psychologists  ...  9.992658e-01     1               0.780488                0.709016\
3       O                              ...  1.153306e-02     1               0.780488                0.709016\
4       O                              ...  2.556833e-02     1               0.780488                0.709016\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...  9.998978e-01     1               0.780488                0.709016\
1238    O                              ...  9.980964e-01     1               0.780488                0.709016\
1239    A                      family  ...  9.996089e-01     1               0.780488                0.709016\
1240    O                              ...  9.965211e-01     1               0.780488                0.709016\
1241    O                              ...  6.639848e-01     1               0.780488                0.709016\
\
[1242 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 1242\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1242 examples to evaluate on.\
     role case animacy   subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       A                Sociologists  ...      0.999885     0               0.790244                0.665301\
1       O                              ...      0.000225     0               0.790244                0.665301\
2       A               psychologists  ...      0.999967     0               0.790244                0.665301\
3       O                              ...      0.000335     0               0.790244                0.665301\
4       O                              ...      0.000930     0               0.790244                0.665301\
...   ...  ...     ...            ...  ...           ...   ...                    ...                     ...\
1237    O                              ...      0.113220     0               0.790244                0.665301\
1238    O                              ...      0.985880     0               0.790244                0.665301\
1239    A                      family  ...      1.000000     0               0.790244                0.665301\
1240    O                              ...      0.999934     0               0.790244                0.665301\
1241    O                              ...      0.463774     0               0.790244                0.665301\
\
[1242 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_en_gum-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-train.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1922 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1922/1922 [00:00<00:00, 3495.33it/s]\
Loaded 1921 sentences from disk.\
length of bert outputs 1922\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999995e-01    12               0.958763                0.929329\
1       A                    labels  ...  1.000000e+00    12               0.958763                0.929329\
2       O                            ...  1.225931e-07    12               0.958763                0.929329\
3       S                    people  ...  5.428332e-01    12               0.958763                0.929329\
4       O                            ...  6.141482e-04    12               0.958763                0.929329\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.088644e-03    12               0.958763                0.929329\
1996    S                     Gomez  ...  1.000000e+00    12               0.958763                0.929329\
1997    O                            ...  9.822651e-01    12               0.958763                0.929329\
1998    A                     Betty  ...  9.999920e-01    12               0.958763                0.929329\
1999    O                            ...  1.697731e-05    12               0.958763                0.929329\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  1.000000e+00    11               0.958763                0.975265\
1       A                    labels  ...  9.999951e-01    11               0.958763                0.975265\
2       O                            ...  2.784713e-08    11               0.958763                0.975265\
3       S                    people  ...  5.129532e-01    11               0.958763                0.975265\
4       O                            ...  3.068313e-07    11               0.958763                0.975265\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.435200e-08    11               0.958763                0.975265\
1996    S                     Gomez  ...  1.000000e+00    11               0.958763                0.975265\
1997    O                            ...  6.070614e-04    11               0.958763                0.975265\
1998    A                     Betty  ...  1.000000e+00    11               0.958763                0.975265\
1999    O                            ...  3.720443e-07    11               0.958763                0.975265\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999601e-01    10               0.958763                0.961131\
1       A                    labels  ...  1.000000e+00    10               0.958763                0.961131\
2       O                            ...  5.088191e-08    10               0.958763                0.961131\
3       S                    people  ...  4.536966e-04    10               0.958763                0.961131\
4       O                            ...  1.600929e-07    10               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  6.176925e-07    10               0.958763                0.961131\
1996    S                     Gomez  ...  1.000000e+00    10               0.958763                0.961131\
1997    O                            ...  3.077842e-05    10               0.958763                0.961131\
1998    A                     Betty  ...  1.000000e+00    10               0.958763                0.961131\
1999    O                            ...  4.986974e-06    10               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999998e-01     9               0.958763                0.971731\
1       A                    labels  ...  1.000000e+00     9               0.958763                0.971731\
2       O                            ...  2.248652e-08     9               0.958763                0.971731\
3       S                    people  ...  3.304080e-03     9               0.958763                0.971731\
4       O                            ...  4.577057e-06     9               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  6.800924e-07     9               0.958763                0.971731\
1996    S                     Gomez  ...  9.994342e-01     9               0.958763                0.971731\
1997    O                            ...  2.758049e-06     9               0.958763                0.971731\
1998    A                     Betty  ...  1.000000e+00     9               0.958763                0.971731\
1999    O                            ...  9.631836e-11     9               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.941848e-01     8               0.958763                0.961131\
1       A                    labels  ...  9.999999e-01     8               0.958763                0.961131\
2       O                            ...  1.255190e-09     8               0.958763                0.961131\
3       S                    people  ...  1.432951e-03     8               0.958763                0.961131\
4       O                            ...  2.559236e-07     8               0.958763                0.961131\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.179279e-05     8               0.958763                0.961131\
1996    S                     Gomez  ...  9.954536e-01     8               0.958763                0.961131\
1997    O                            ...  1.492021e-04     8               0.958763                0.961131\
1998    A                     Betty  ...  1.000000e+00     8               0.958763                0.961131\
1999    O                            ...  4.466036e-09     8               0.958763                0.961131\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.992830e-01     7               0.958763                0.971731\
1       A                    labels  ...  1.000000e+00     7               0.958763                0.971731\
2       O                            ...  1.705668e-05     7               0.958763                0.971731\
3       S                    people  ...  6.928357e-06     7               0.958763                0.971731\
4       O                            ...  9.426942e-08     7               0.958763                0.971731\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.816095e-05     7               0.958763                0.971731\
1996    S                     Gomez  ...  9.999999e-01     7               0.958763                0.971731\
1997    O                            ...  7.616269e-06     7               0.958763                0.971731\
1998    A                     Betty  ...  1.000000e+00     7               0.958763                0.971731\
1999    O                            ...  3.101978e-07     7               0.958763                0.971731\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999021e-01     6               0.938144                0.968198\
1       A                    labels  ...  1.000000e+00     6               0.938144                0.968198\
2       O                            ...  1.229846e-10     6               0.938144                0.968198\
3       S                    people  ...  5.417122e-01     6               0.938144                0.968198\
4       O                            ...  1.141500e-03     6               0.938144                0.968198\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.773826e-03     6               0.938144                0.968198\
1996    S                     Gomez  ...  9.911612e-01     6               0.938144                0.968198\
1997    O                            ...  9.699601e-05     6               0.938144                0.968198\
1998    A                     Betty  ...  1.000000e+00     6               0.938144                0.968198\
1999    O                            ...  2.031337e-06     6               0.938144                0.968198\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.985343e-01     5               0.969072                0.943463\
1       A                    labels  ...  1.000000e+00     5               0.969072                0.943463\
2       O                            ...  1.563361e-08     5               0.969072                0.943463\
3       S                    people  ...  7.315068e-01     5               0.969072                0.943463\
4       O                            ...  5.483919e-07     5               0.969072                0.943463\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.551416e-06     5               0.969072                0.943463\
1996    S                     Gomez  ...  9.961945e-01     5               0.969072                0.943463\
1997    O                            ...  8.591592e-01     5               0.969072                0.943463\
1998    A                     Betty  ...  9.999921e-01     5               0.969072                0.943463\
1999    O                            ...  5.282227e-09     5               0.969072                0.943463\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  7.009908e-01     4               0.917526                0.946996\
1       A                    labels  ...  1.000000e+00     4               0.917526                0.946996\
2       O                            ...  3.082205e-06     4               0.917526                0.946996\
3       S                    people  ...  2.411780e-02     4               0.917526                0.946996\
4       O                            ...  2.714767e-04     4               0.917526                0.946996\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  9.786730e-10     4               0.917526                0.946996\
1996    S                     Gomez  ...  8.868564e-01     4               0.917526                0.946996\
1997    O                            ...  3.054596e-01     4               0.917526                0.946996\
1998    A                     Betty  ...  1.000000e+00     4               0.917526                0.946996\
1999    O                            ...  6.097519e-08     4               0.917526                0.946996\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.987015e-01     3               0.938144                0.936396\
1       A                    labels  ...  9.998719e-01     3               0.938144                0.936396\
2       O                            ...  5.320999e-04     3               0.938144                0.936396\
3       S                    people  ...  8.313686e-01     3               0.938144                0.936396\
4       O                            ...  1.238599e-02     3               0.938144                0.936396\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.090084e-08     3               0.938144                0.936396\
1996    S                     Gomez  ...  9.997904e-01     3               0.938144                0.936396\
1997    O                            ...  3.075265e-01     3               0.938144                0.936396\
1998    A                     Betty  ...  9.999990e-01     3               0.938144                0.936396\
1999    O                            ...  1.352323e-04     3               0.938144                0.936396\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      1.000000     2               0.783505                0.795053\
1       A                    labels  ...      0.999837     2               0.783505                0.795053\
2       O                            ...      0.025849     2               0.783505                0.795053\
3       S                    people  ...      0.999914     2               0.783505                0.795053\
4       O                            ...      0.216728     2               0.783505                0.795053\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.000086     2               0.783505                0.795053\
1996    S                     Gomez  ...      0.895774     2               0.783505                0.795053\
1997    O                            ...      0.998951     2               0.783505                0.795053\
1998    A                     Betty  ...      1.000000     2               0.783505                0.795053\
1999    O                            ...      0.500000     2               0.783505                0.795053\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999994e-01     1               0.793814                0.773852\
1       A                    labels  ...  9.999999e-01     1               0.793814                0.773852\
2       O                            ...  4.742811e-07     1               0.793814                0.773852\
3       S                    people  ...  9.096724e-01     1               0.793814                0.773852\
4       O                            ...  9.145288e-02     1               0.793814                0.773852\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  4.132206e-04     1               0.793814                0.773852\
1996    S                     Gomez  ...  1.993300e-01     1               0.793814                0.773852\
1997    O                            ...  9.875712e-01     1               0.793814                0.773852\
1998    A                     Betty  ...  9.999996e-01     1               0.793814                0.773852\
1999    O                            ...  1.412466e-03     1               0.793814                0.773852\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999998     0               0.721649                0.816254\
1       A                    labels  ...      1.000000     0               0.721649                0.816254\
2       O                            ...      0.038576     0               0.721649                0.816254\
3       S                    people  ...      0.969569     0               0.721649                0.816254\
4       O                            ...      0.275936     0               0.721649                0.816254\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.009662     0               0.721649                0.816254\
1996    S                     Gomez  ...      0.925534     0               0.721649                0.816254\
1997    O                            ...      0.926163     0               0.721649                0.816254\
1998    A                     Betty  ...      0.999315     0               0.721649                0.816254\
1999    O                            ...      0.687705     0               0.721649                0.816254\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_en_gum-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-train.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1922 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1922/1922 [00:00<00:00, 3833.80it/s]\
Loaded 1921 sentences from disk.\
length of bert outputs 1922\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.987565    12                0.84556                0.873118\
1       A                    labels  ...      0.054481    12                0.84556                0.873118\
2       O                            ...      0.000089    12                0.84556                0.873118\
3       S                    people  ...      0.054767    12                0.84556                0.873118\
4       O                            ...      0.175326    12                0.84556                0.873118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.002625    12                0.84556                0.873118\
1996    S                     Gomez  ...      1.000000    12                0.84556                0.873118\
1997    O                            ...      0.001452    12                0.84556                0.873118\
1998    A                     Betty  ...      0.940736    12                0.84556                0.873118\
1999    O                            ...      0.000026    12                0.84556                0.873118\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.995880e-01    11               0.880309                0.896774\
1       A                    labels  ...  9.920402e-01    11               0.880309                0.896774\
2       O                            ...  2.878798e-08    11               0.880309                0.896774\
3       S                    people  ...  4.692253e-02    11               0.880309                0.896774\
4       O                            ...  8.196651e-06    11               0.880309                0.896774\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.926202e-03    11               0.880309                0.896774\
1996    S                     Gomez  ...  9.999990e-01    11               0.880309                0.896774\
1997    O                            ...  1.427345e-06    11               0.880309                0.896774\
1998    A                     Betty  ...  9.999784e-01    11               0.880309                0.896774\
1999    O                            ...  1.965621e-07    11               0.880309                0.896774\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.996132e-01    10               0.915058                0.922581\
1       A                    labels  ...  9.999994e-01    10               0.915058                0.922581\
2       O                            ...  3.458336e-07    10               0.915058                0.922581\
3       S                    people  ...  9.232943e-05    10               0.915058                0.922581\
4       O                            ...  7.837502e-07    10               0.915058                0.922581\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.336535e-04    10               0.915058                0.922581\
1996    S                     Gomez  ...  9.999440e-01    10               0.915058                0.922581\
1997    O                            ...  4.004846e-06    10               0.915058                0.922581\
1998    A                     Betty  ...  1.000000e+00    10               0.915058                0.922581\
1999    O                            ...  6.966585e-05    10               0.915058                0.922581\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999977e-01     9               0.903475                0.909677\
1       A                    labels  ...  9.999819e-01     9               0.903475                0.909677\
2       O                            ...  3.508514e-07     9               0.903475                0.909677\
3       S                    people  ...  2.230672e-03     9               0.903475                0.909677\
4       O                            ...  9.292872e-08     9               0.903475                0.909677\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.992731e-03     9               0.903475                0.909677\
1996    S                     Gomez  ...  9.982122e-01     9               0.903475                0.909677\
1997    O                            ...  4.349248e-08     9               0.903475                0.909677\
1998    A                     Betty  ...  1.000000e+00     9               0.903475                0.909677\
1999    O                            ...  3.564903e-08     9               0.903475                0.909677\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.994759e-01     8               0.891892                0.913978\
1       A                    labels  ...  9.988708e-01     8               0.891892                0.913978\
2       O                            ...  4.164735e-08     8               0.891892                0.913978\
3       S                    people  ...  1.600946e-03     8               0.891892                0.913978\
4       O                            ...  3.189689e-07     8               0.891892                0.913978\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.569444e-04     8               0.891892                0.913978\
1996    S                     Gomez  ...  9.987487e-01     8               0.891892                0.913978\
1997    O                            ...  1.853293e-04     8               0.891892                0.913978\
1998    A                     Betty  ...  1.000000e+00     8               0.891892                0.913978\
1999    O                            ...  1.745754e-07     8               0.891892                0.913978\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999509e-01     7               0.911197                0.892473\
1       A                    labels  ...  9.999372e-01     7               0.911197                0.892473\
2       O                            ...  1.451858e-04     7               0.911197                0.892473\
3       S                    people  ...  8.998682e-06     7               0.911197                0.892473\
4       O                            ...  5.249625e-09     7               0.911197                0.892473\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.121445e-02     7               0.911197                0.892473\
1996    S                     Gomez  ...  9.999998e-01     7               0.911197                0.892473\
1997    O                            ...  3.570412e-05     7               0.911197                0.892473\
1998    A                     Betty  ...  1.000000e+00     7               0.911197                0.892473\
1999    O                            ...  2.963733e-05     7               0.911197                0.892473\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.937091e-01     6               0.888031                0.890323\
1       A                    labels  ...  9.999589e-01     6               0.888031                0.890323\
2       O                            ...  1.107564e-08     6               0.888031                0.890323\
3       S                    people  ...  8.975982e-03     6               0.888031                0.890323\
4       O                            ...  6.726028e-05     6               0.888031                0.890323\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.294046e-04     6               0.888031                0.890323\
1996    S                     Gomez  ...  9.979482e-01     6               0.888031                0.890323\
1997    O                            ...  4.725549e-03     6               0.888031                0.890323\
1998    A                     Betty  ...  1.000000e+00     6               0.888031                0.890323\
1999    O                            ...  4.314893e-05     6               0.888031                0.890323\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  4.480781e-02     5               0.803089                 0.84086\
1       A                    labels  ...  9.971712e-01     5               0.803089                 0.84086\
2       O                            ...  2.019509e-07     5               0.803089                 0.84086\
3       S                    people  ...  8.268485e-02     5               0.803089                 0.84086\
4       O                            ...  9.752523e-05     5               0.803089                 0.84086\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.448161e-05     5               0.803089                 0.84086\
1996    S                     Gomez  ...  9.997053e-01     5               0.803089                 0.84086\
1997    O                            ...  6.464020e-03     5               0.803089                 0.84086\
1998    A                     Betty  ...  9.999601e-01     5               0.803089                 0.84086\
1999    O                            ...  1.140590e-06     5               0.803089                 0.84086\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  4.941295e-01     4               0.826255                0.756989\
1       A                    labels  ...  9.999899e-01     4               0.826255                0.756989\
2       O                            ...  2.379500e-06     4               0.826255                0.756989\
3       S                    people  ...  8.016739e-01     4               0.826255                0.756989\
4       O                            ...  2.827820e-04     4               0.826255                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.931790e-07     4               0.826255                0.756989\
1996    S                     Gomez  ...  9.972096e-01     4               0.826255                0.756989\
1997    O                            ...  2.515050e-02     4               0.826255                0.756989\
1998    A                     Betty  ...  9.999998e-01     4               0.826255                0.756989\
1999    O                            ...  1.433863e-06     4               0.826255                0.756989\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  4.370082e-01     3                0.80695                0.787097\
1       A                    labels  ...  9.640711e-01     3                0.80695                0.787097\
2       O                            ...  1.934976e-02     3                0.80695                0.787097\
3       S                    people  ...  1.957073e-01     3                0.80695                0.787097\
4       O                            ...  8.402089e-07     3                0.80695                0.787097\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.011782e-04     3                0.80695                0.787097\
1996    S                     Gomez  ...  9.999472e-01     3                0.80695                0.787097\
1997    O                            ...  6.576675e-02     3                0.80695                0.787097\
1998    A                     Betty  ...  9.999993e-01     3                0.80695                0.787097\
1999    O                            ...  3.608532e-03     3                0.80695                0.787097\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999787     2               0.722008                0.825806\
1       A                    labels  ...      0.999980     2               0.722008                0.825806\
2       O                            ...      0.900645     2               0.722008                0.825806\
3       S                    people  ...      0.982116     2               0.722008                0.825806\
4       O                            ...      0.001901     2               0.722008                0.825806\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.810293     2               0.722008                0.825806\
1996    S                     Gomez  ...      0.995198     2               0.722008                0.825806\
1997    O                            ...      0.021144     2               0.722008                0.825806\
1998    A                     Betty  ...      1.000000     2               0.722008                0.825806\
1999    O                            ...      0.500000     2               0.722008                0.825806\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.997247     1               0.675676                0.756989\
1       A                    labels  ...      1.000000     1               0.675676                0.756989\
2       O                            ...      0.837023     1               0.675676                0.756989\
3       S                    people  ...      0.970273     1               0.675676                0.756989\
4       O                            ...      0.145273     1               0.675676                0.756989\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.076809     1               0.675676                0.756989\
1996    S                     Gomez  ...      0.996820     1               0.675676                0.756989\
1997    O                            ...      0.099183     1               0.675676                0.756989\
1998    A                     Betty  ...      1.000000     1               0.675676                0.756989\
1999    O                            ...      0.006233     1               0.675676                0.756989\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999973     0               0.722008                0.673118\
1       A                    labels  ...      0.999986     0               0.722008                0.673118\
2       O                            ...      0.999256     0               0.722008                0.673118\
3       S                    people  ...      0.946006     0               0.722008                0.673118\
4       O                            ...      0.044545     0               0.722008                0.673118\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.374889     0               0.722008                0.673118\
1996    S                     Gomez  ...      0.999997     0               0.722008                0.673118\
1997    O                            ...      0.258469     0               0.722008                0.673118\
1998    A                     Betty  ...      0.999451     0               0.722008                0.673118\
1999    O                            ...      0.820315     0               0.722008                0.673118\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_en_gum-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_English-GUM-master/en_gum-ud-train.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1922 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_en_gum-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1922/1922 [00:00<00:00, 3893.61it/s]\
Loaded 1921 sentences from disk.\
length of bert outputs 1922\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.709580    12               0.978723                0.872247\
1       A                    labels  ...      0.456583    12               0.978723                0.872247\
2       O                            ...      0.000253    12               0.978723                0.872247\
3       S                    people  ...      0.711186    12               0.978723                0.872247\
4       O                            ...      0.005199    12               0.978723                0.872247\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.684386    12               0.978723                0.872247\
1996    S                     Gomez  ...      0.999978    12               0.978723                0.872247\
1997    O                            ...      0.000159    12               0.978723                0.872247\
1998    A                     Betty  ...      0.999917    12               0.978723                0.872247\
1999    O                            ...      0.048965    12               0.978723                0.872247\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.826921e-01    11               0.978723                0.898678\
1       A                    labels  ...  9.971454e-01    11               0.978723                0.898678\
2       O                            ...  1.623919e-06    11               0.978723                0.898678\
3       S                    people  ...  6.889647e-03    11               0.978723                0.898678\
4       O                            ...  1.474527e-03    11               0.978723                0.898678\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.248526e-05    11               0.978723                0.898678\
1996    S                     Gomez  ...  9.999989e-01    11               0.978723                0.898678\
1997    O                            ...  4.020438e-07    11               0.978723                0.898678\
1998    A                     Betty  ...  9.999985e-01    11               0.978723                0.898678\
1999    O                            ...  8.177506e-06    11               0.978723                0.898678\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999996e-01    10               0.978723                0.929515\
1       A                    labels  ...  9.999999e-01    10               0.978723                0.929515\
2       O                            ...  1.349863e-07    10               0.978723                0.929515\
3       S                    people  ...  3.606098e-01    10               0.978723                0.929515\
4       O                            ...  1.018912e-02    10               0.978723                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  3.955977e-06    10               0.978723                0.929515\
1996    S                     Gomez  ...  9.999671e-01    10               0.978723                0.929515\
1997    O                            ...  3.207411e-04    10               0.978723                0.929515\
1998    A                     Betty  ...  1.000000e+00    10               0.978723                0.929515\
1999    O                            ...  1.855739e-03    10               0.978723                0.929515\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.999740e-01     9               0.989362                0.920705\
1       A                    labels  ...  9.999932e-01     9               0.989362                0.920705\
2       O                            ...  2.138433e-10     9               0.989362                0.920705\
3       S                    people  ...  6.717349e-03     9               0.989362                0.920705\
4       O                            ...  2.678716e-05     9               0.989362                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  5.881502e-05     9               0.989362                0.920705\
1996    S                     Gomez  ...  9.972717e-01     9               0.989362                0.920705\
1997    O                            ...  9.407843e-06     9               0.989362                0.920705\
1998    A                     Betty  ...  9.999999e-01     9               0.989362                0.920705\
1999    O                            ...  2.466202e-07     9               0.989362                0.920705\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.847754e-01     8               0.989362                0.929515\
1       A                    labels  ...  9.852225e-01     8               0.989362                0.929515\
2       O                            ...  2.899285e-08     8               0.989362                0.929515\
3       S                    people  ...  1.193269e-06     8               0.989362                0.929515\
4       O                            ...  1.778766e-06     8               0.989362                0.929515\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.935776e-05     8               0.989362                0.929515\
1996    S                     Gomez  ...  9.962180e-01     8               0.989362                0.929515\
1997    O                            ...  8.259524e-05     8               0.989362                0.929515\
1998    A                     Betty  ...  1.000000e+00     8               0.989362                0.929515\
1999    O                            ...  1.540469e-08     8               0.989362                0.929515\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.902209e-01     7               0.978723                 0.92511\
1       A                    labels  ...  9.900259e-01     7               0.978723                 0.92511\
2       O                            ...  1.086229e-04     7               0.978723                 0.92511\
3       S                    people  ...  3.852123e-09     7               0.978723                 0.92511\
4       O                            ...  4.980135e-07     7               0.978723                 0.92511\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  4.974959e-05     7               0.978723                 0.92511\
1996    S                     Gomez  ...  9.999874e-01     7               0.978723                 0.92511\
1997    O                            ...  4.442025e-02     7               0.978723                 0.92511\
1998    A                     Betty  ...  1.000000e+00     7               0.978723                 0.92511\
1999    O                            ...  2.001881e-09     7               0.978723                 0.92511\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.992628e-01     6               0.957447                0.920705\
1       A                    labels  ...  9.998382e-01     6               0.957447                0.920705\
2       O                            ...  1.137152e-11     6               0.957447                0.920705\
3       S                    people  ...  2.688761e-04     6               0.957447                0.920705\
4       O                            ...  1.071110e-03     6               0.957447                0.920705\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  1.491759e-03     6               0.957447                0.920705\
1996    S                     Gomez  ...  9.999995e-01     6               0.957447                0.920705\
1997    O                            ...  9.433016e-01     6               0.957447                0.920705\
1998    A                     Betty  ...  1.000000e+00     6               0.957447                0.920705\
1999    O                            ...  1.944053e-09     6               0.957447                0.920705\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  6.771291e-01     5               0.968085                0.863436\
1       A                    labels  ...  9.643956e-01     5               0.968085                0.863436\
2       O                            ...  2.475953e-12     5               0.968085                0.863436\
3       S                    people  ...  1.241631e-03     5               0.968085                0.863436\
4       O                            ...  5.964923e-05     5               0.968085                0.863436\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.807868e-10     5               0.968085                0.863436\
1996    S                     Gomez  ...  9.999974e-01     5               0.968085                0.863436\
1997    O                            ...  6.903376e-01     5               0.968085                0.863436\
1998    A                     Betty  ...  9.996279e-01     5               0.968085                0.863436\
1999    O                            ...  2.901328e-11     5               0.968085                0.863436\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.978262e-01     4               0.957447                0.797357\
1       A                    labels  ...  9.999942e-01     4               0.957447                0.797357\
2       O                            ...  3.487006e-13     4               0.957447                0.797357\
3       S                    people  ...  2.346584e-01     4               0.957447                0.797357\
4       O                            ...  4.929123e-05     4               0.957447                0.797357\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  6.475393e-07     4               0.957447                0.797357\
1996    S                     Gomez  ...  9.980956e-01     4               0.957447                0.797357\
1997    O                            ...  2.237641e-01     4               0.957447                0.797357\
1998    A                     Betty  ...  9.999998e-01     4               0.957447                0.797357\
1999    O                            ...  8.088405e-07     4               0.957447                0.797357\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...  9.802464e-01     3               0.914894                0.810573\
1       A                    labels  ...  9.081406e-01     3               0.914894                0.810573\
2       O                            ...  3.339491e-06     3               0.914894                0.810573\
3       S                    people  ...  2.277425e-01     3               0.914894                0.810573\
4       O                            ...  8.579708e-09     3               0.914894                0.810573\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...  2.926392e-06     3               0.914894                0.810573\
1996    S                     Gomez  ...  9.923028e-01     3               0.914894                0.810573\
1997    O                            ...  2.474460e-02     3               0.914894                0.810573\
1998    A                     Betty  ...  9.999704e-01     3               0.914894                0.810573\
1999    O                            ...  5.743655e-04     3               0.914894                0.810573\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999997     2               0.787234                0.674009\
1       A                    labels  ...      0.997437     2               0.787234                0.674009\
2       O                            ...      0.000401     2               0.787234                0.674009\
3       S                    people  ...      0.944365     2               0.787234                0.674009\
4       O                            ...      0.000129     2               0.787234                0.674009\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.010229     2               0.787234                0.674009\
1996    S                     Gomez  ...      0.940371     2               0.787234                0.674009\
1997    O                            ...      0.014319     2               0.787234                0.674009\
1998    A                     Betty  ...      0.999999     2               0.787234                0.674009\
1999    O                            ...      0.500000     2               0.787234                0.674009\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999806     1               0.765957                 0.69163\
1       A                    labels  ...      0.999959     1               0.765957                 0.69163\
2       O                            ...      0.019813     1               0.765957                 0.69163\
3       S                    people  ...      0.997574     1               0.765957                 0.69163\
4       O                            ...      0.064677     1               0.765957                 0.69163\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.087200     1               0.765957                 0.69163\
1996    S                     Gomez  ...      0.993686     1               0.765957                 0.69163\
1997    O                            ...      0.353566     1               0.765957                 0.69163\
1998    A                     Betty  ...      0.999946     1               0.765957                 0.69163\
1999    O                            ...      0.021837     1               0.765957                 0.69163\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'S-aux': 5, 'S-expletive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                    people  ...      0.999998     0               0.712766                0.788546\
1       A                    labels  ...      0.999923     0               0.712766                0.788546\
2       O                            ...      0.285059     0               0.712766                0.788546\
3       S                    people  ...      0.998205     0               0.712766                0.788546\
4       O                            ...      0.925949     0               0.712766                0.788546\
...   ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
1995    O                            ...      0.868051     0               0.712766                0.788546\
1996    S                     Gomez  ...      0.962793     0               0.712766                0.788546\
1997    O                            ...      0.841439     0               0.712766                0.788546\
1998    A                     Betty  ...      0.998741     0               0.712766                0.788546\
1999    O                            ...      0.876106     0               0.712766                0.788546\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/ko_kaist-ud_fr_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Korean-Kaist-master/ko_kaist-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Counts of each role Counter(\{'O': 1054, 'A': 376, 'S': 335, 'S-passive': 231, 'A-passive': 4\})\
Case counts per role defaultdict(<class 'collections.Counter'>, \{None: Counter(\{None: 36779\}), 'S': Counter(\{None: 335\}), 'A': Counter(\{None: 376\}), 'O': Counter(\{None: 1054\}), 'S-passive': Counter(\{None: 231\}), 'A-passive': Counter(\{None: 4\})\})\
lengths of bert ids etc 1535 1535 1535 1535\
Saving all of the tokens and non-bert stuff to cached_datasets/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1535 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.hdf5\
Running 1535 sentences through BERT. This takes a while\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1535/1535 [00:56<00:00, 27.30it/s]\
length of bert outputs 1535\
On layer 12\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9186991869918699, 'O': 0.7310278578290106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.314138e-01    12               0.918699                0.731028\
1       S                      \'9cuvre  ...  9.996110e-01    12               0.918699                0.731028\
2       S               comportement  ...  5.967990e-02    12               0.918699                0.731028\
3       A                     filles  ...  9.360323e-01    12               0.918699                0.731028\
4       O                             ...  4.109880e-07    12               0.918699                0.731028\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.364162e-05    12               0.918699                0.731028\
1996    S                       co\'fbt  ...  9.999944e-01    12               0.918699                0.731028\
1997    S                        TPS  ...  1.000000e+00    12               0.918699                0.731028\
1998    O                             ...  1.308762e-03    12               0.918699                0.731028\
1999    O                             ...  8.004318e-01    12               0.918699                0.731028\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.7905859750240154\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.993413e-01    11               0.910569                0.790586\
1       S                      \'9cuvre  ...  9.409711e-01    11               0.910569                0.790586\
2       S               comportement  ...  9.998122e-01    11               0.910569                0.790586\
3       A                     filles  ...  9.220999e-01    11               0.910569                0.790586\
4       O                             ...  4.065034e-11    11               0.910569                0.790586\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  4.707465e-06    11               0.910569                0.790586\
1996    S                       co\'fbt  ...  9.999971e-01    11               0.910569                0.790586\
1997    S                        TPS  ...  9.999990e-01    11               0.910569                0.790586\
1998    O                             ...  3.382378e-05    11               0.910569                0.790586\
1999    O                             ...  9.650102e-01    11               0.910569                0.790586\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.8213256484149856\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999934e-01    10               0.886179                0.821326\
1       S                      \'9cuvre  ...  9.985663e-01    10               0.886179                0.821326\
2       S               comportement  ...  9.999985e-01    10               0.886179                0.821326\
3       A                     filles  ...  9.999994e-01    10               0.886179                0.821326\
4       O                             ...  7.107874e-10    10               0.886179                0.821326\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  6.415405e-04    10               0.886179                0.821326\
1996    S                       co\'fbt  ...  9.999954e-01    10               0.886179                0.821326\
1997    S                        TPS  ...  9.999970e-01    10               0.886179                0.821326\
1998    O                             ...  6.434446e-06    10               0.886179                0.821326\
1999    O                             ...  8.904542e-01    10               0.886179                0.821326\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.997810e-01     9               0.910569                0.855908\
1       S                      \'9cuvre  ...  9.999944e-01     9               0.910569                0.855908\
2       S               comportement  ...  9.999959e-01     9               0.910569                0.855908\
3       A                     filles  ...  1.000000e+00     9               0.910569                0.855908\
4       O                             ...  1.141878e-09     9               0.910569                0.855908\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  9.173242e-07     9               0.910569                0.855908\
1996    S                       co\'fbt  ...  9.986527e-01     9               0.910569                0.855908\
1997    S                        TPS  ...  9.999999e-01     9               0.910569                0.855908\
1998    O                             ...  5.016609e-01     9               0.910569                0.855908\
1999    O                             ...  7.226450e-01     9               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  4.721015e-01     8               0.910569                0.855908\
1       S                      \'9cuvre  ...  9.999886e-01     8               0.910569                0.855908\
2       S               comportement  ...  9.999989e-01     8               0.910569                0.855908\
3       A                     filles  ...  9.997724e-01     8               0.910569                0.855908\
4       O                             ...  1.631776e-09     8               0.910569                0.855908\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.003330e-04     8               0.910569                0.855908\
1996    S                       co\'fbt  ...  8.812001e-01     8               0.910569                0.855908\
1997    S                        TPS  ...  1.000000e+00     8               0.910569                0.855908\
1998    O                             ...  6.236630e-02     8               0.910569                0.855908\
1999    O                             ...  5.626888e-01     8               0.910569                0.855908\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8914505283381364\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  7.501478e-01     7               0.934959                0.891451\
1       S                      \'9cuvre  ...  7.903123e-01     7               0.934959                0.891451\
2       S               comportement  ...  9.996093e-01     7               0.934959                0.891451\
3       A                     filles  ...  9.817647e-01     7               0.934959                0.891451\
4       O                             ...  6.464959e-10     7               0.934959                0.891451\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  5.523189e-07     7               0.934959                0.891451\
1996    S                       co\'fbt  ...  9.796972e-01     7               0.934959                0.891451\
1997    S                        TPS  ...  1.000000e+00     7               0.934959                0.891451\
1998    O                             ...  1.539323e-01     7               0.934959                0.891451\
1999    O                             ...  7.705252e-04     7               0.934959                0.891451\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8194044188280499\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.989031     6               0.934959                0.819404\
1       S                      \'9cuvre  ...      0.770808     6               0.934959                0.819404\
2       S               comportement  ...      0.998689     6               0.934959                0.819404\
3       A                     filles  ...      0.999521     6               0.934959                0.819404\
4       O                             ...      0.000041     6               0.934959                0.819404\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.002627     6               0.934959                0.819404\
1996    S                       co\'fbt  ...      0.999991     6               0.934959                0.819404\
1997    S                        TPS  ...      1.000000     6               0.934959                0.819404\
1998    O                             ...      0.000008     6               0.934959                0.819404\
1999    O                             ...      0.999992     6               0.934959                0.819404\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9024390243902439, 'O': 0.7425552353506244\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.886440e-01     5               0.902439                0.742555\
1       S                      \'9cuvre  ...  9.998543e-01     5               0.902439                0.742555\
2       S               comportement  ...  9.999943e-01     5               0.902439                0.742555\
3       A                     filles  ...  7.362579e-01     5               0.902439                0.742555\
4       O                             ...  8.787544e-09     5               0.902439                0.742555\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.122222e-09     5               0.902439                0.742555\
1996    S                       co\'fbt  ...  9.999865e-01     5               0.902439                0.742555\
1997    S                        TPS  ...  1.000000e+00     5               0.902439                0.742555\
1998    O                             ...  3.450395e-03     5               0.902439                0.742555\
1999    O                             ...  9.999049e-01     5               0.902439                0.742555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.7300672430355427\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.799611e-01     4               0.886179                0.730067\
1       S                      \'9cuvre  ...  9.999895e-01     4               0.886179                0.730067\
2       S               comportement  ...  9.999974e-01     4               0.886179                0.730067\
3       A                     filles  ...  1.794153e-03     4               0.886179                0.730067\
4       O                             ...  1.235302e-07     4               0.886179                0.730067\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.162529e-09     4               0.886179                0.730067\
1996    S                       co\'fbt  ...  7.199070e-01     4               0.886179                0.730067\
1997    S                        TPS  ...  9.999999e-01     4               0.886179                0.730067\
1998    O                             ...  2.994093e-08     4               0.886179                0.730067\
1999    O                             ...  9.941210e-01     4               0.886179                0.730067\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8699186991869918, 'O': 0.7598463016330451\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.450396e-01     3               0.869919                0.759846\
1       S                      \'9cuvre  ...  9.628956e-01     3               0.869919                0.759846\
2       S               comportement  ...  9.692103e-01     3               0.869919                0.759846\
3       A                     filles  ...  3.284076e-02     3               0.869919                0.759846\
4       O                             ...  1.310214e-06     3               0.869919                0.759846\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.553969e-10     3               0.869919                0.759846\
1996    S                       co\'fbt  ...  9.999714e-01     3               0.869919                0.759846\
1997    S                        TPS  ...  9.995822e-01     3               0.869919                0.759846\
1998    O                             ...  4.706628e-10     3               0.869919                0.759846\
1999    O                             ...  9.966307e-01     3               0.869919                0.759846\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8536585365853658, 'O': 0.5524542829643888\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.412590e-01     2               0.853659                0.552454\
1       S                      \'9cuvre  ...  7.147374e-01     2               0.853659                0.552454\
2       S               comportement  ...  5.710881e-01     2               0.853659                0.552454\
3       A                     filles  ...  4.052521e-01     2               0.853659                0.552454\
4       O                             ...  8.874729e-05     2               0.853659                0.552454\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.122439e-05     2               0.853659                0.552454\
1996    S                       co\'fbt  ...  8.306932e-01     2               0.853659                0.552454\
1997    S                        TPS  ...  1.000000e+00     2               0.853659                0.552454\
1998    O                             ...  2.495316e-11     2               0.853659                0.552454\
1999    O                             ...  5.000000e-01     2               0.853659                0.552454\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.8373983739837398, 'O': 0.5620789220404235\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  8.668935e-01     1               0.837398                0.562079\
1       S                      \'9cuvre  ...  9.489544e-01     1               0.837398                0.562079\
2       S               comportement  ...  4.667896e-01     1               0.837398                0.562079\
3       A                     filles  ...  2.603851e-03     1               0.837398                0.562079\
4       O                             ...  2.814941e-02     1               0.837398                0.562079\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.929027e-02     1               0.837398                0.562079\
1996    S                       co\'fbt  ...  1.800182e-01     1               0.837398                0.562079\
1997    S                        TPS  ...  9.999998e-01     1               0.837398                0.562079\
1998    O                             ...  6.073932e-08     1               0.837398                0.562079\
1999    O                             ...  9.999284e-01     1               0.837398                0.562079\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6422764227642277, 'O': 0.5851780558229066\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-passive': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.514065     0               0.642276                0.585178\
1       S                      \'9cuvre  ...      0.998455     0               0.642276                0.585178\
2       S               comportement  ...      0.030146     0               0.642276                0.585178\
3       A                     filles  ...      0.011658     0               0.642276                0.585178\
4       O                             ...      0.992062     0               0.642276                0.585178\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.028641     0               0.642276                0.585178\
1996    S                       co\'fbt  ...      0.068226     0               0.642276                0.585178\
1997    S                        TPS  ...      0.999315     0               0.642276                0.585178\
1998    O                             ...      0.000195     0               0.642276                0.585178\
1999    O                             ...      0.970289     0               0.642276                0.585178\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/pt_cintil-ud_fr_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1535 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1535/1535 [00:00<00:00, 2450.20it/s]\
Loaded 1534 sentences from disk.\
length of bert outputs 1535\
On layer 12\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9315403422982885, 'O': 0.8970099667774086\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  6.303513e-04    12                0.93154                 0.89701\
1       S                      \'9cuvre  ...  1.000000e+00    12                0.93154                 0.89701\
2       S               comportement  ...  9.999989e-01    12                0.93154                 0.89701\
3       A                     filles  ...  9.999999e-01    12                0.93154                 0.89701\
4       O                             ...  8.641750e-02    12                0.93154                 0.89701\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  6.115564e-05    12                0.93154                 0.89701\
1996    S                       co\'fbt  ...  9.996452e-01    12                0.93154                 0.89701\
1997    S                        TPS  ...  1.000000e+00    12                0.93154                 0.89701\
1998    O                             ...  9.132759e-08    12                0.93154                 0.89701\
1999    O                             ...  6.005451e-01    12                0.93154                 0.89701\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9535452322738386, 'O': 0.9346622369878184\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  3.737965e-01    11               0.953545                0.934662\
1       S                      \'9cuvre  ...  9.999994e-01    11               0.953545                0.934662\
2       S               comportement  ...  1.000000e+00    11               0.953545                0.934662\
3       A                     filles  ...  9.999992e-01    11               0.953545                0.934662\
4       O                             ...  9.599654e-04    11               0.953545                0.934662\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.018975e-05    11               0.953545                0.934662\
1996    S                       co\'fbt  ...  9.999985e-01    11               0.953545                0.934662\
1997    S                        TPS  ...  1.000000e+00    11               0.953545                0.934662\
1998    O                             ...  3.385454e-07    11               0.953545                0.934662\
1999    O                             ...  8.387195e-01    11               0.953545                0.934662\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9633251833740831, 'O': 0.9446290143964563\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  1.189504e-01    10               0.963325                0.944629\
1       S                      \'9cuvre  ...  1.000000e+00    10               0.963325                0.944629\
2       S               comportement  ...  1.000000e+00    10               0.963325                0.944629\
3       A                     filles  ...  1.000000e+00    10               0.963325                0.944629\
4       O                             ...  1.462226e-05    10               0.963325                0.944629\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.001343e-05    10               0.963325                0.944629\
1996    S                       co\'fbt  ...  9.997763e-01    10               0.963325                0.944629\
1997    S                        TPS  ...  1.000000e+00    10               0.963325                0.944629\
1998    O                             ...  1.550737e-07    10               0.963325                0.944629\
1999    O                             ...  7.030421e-01    10               0.963325                0.944629\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.960880195599022, 'O': 0.9501661129568106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.363545     9                0.96088                0.950166\
1       S                      \'9cuvre  ...      1.000000     9                0.96088                0.950166\
2       S               comportement  ...      1.000000     9                0.96088                0.950166\
3       A                     filles  ...      1.000000     9                0.96088                0.950166\
4       O                             ...      0.000004     9                0.96088                0.950166\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000620     9                0.96088                0.950166\
1996    S                       co\'fbt  ...      0.987506     9                0.96088                0.950166\
1997    S                        TPS  ...      1.000000     9                0.96088                0.950166\
1998    O                             ...      0.000002     9                0.96088                0.950166\
1999    O                             ...      0.866931     9                0.96088                0.950166\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.964562569213732\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  8.055703e-01     8                0.95599                0.964563\
1       S                      \'9cuvre  ...  1.000000e+00     8                0.95599                0.964563\
2       S               comportement  ...  1.000000e+00     8                0.95599                0.964563\
3       A                     filles  ...  1.000000e+00     8                0.95599                0.964563\
4       O                             ...  4.208687e-07     8                0.95599                0.964563\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.130285e-03     8                0.95599                0.964563\
1996    S                       co\'fbt  ...  9.995586e-01     8                0.95599                0.964563\
1997    S                        TPS  ...  1.000000e+00     8                0.95599                0.964563\
1998    O                             ...  7.711794e-07     8                0.95599                0.964563\
1999    O                             ...  2.316929e-01     8                0.95599                0.964563\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.9512735326688815\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.998702e-01     7                0.95599                0.951274\
1       S                      \'9cuvre  ...  1.000000e+00     7                0.95599                0.951274\
2       S               comportement  ...  9.998959e-01     7                0.95599                0.951274\
3       A                     filles  ...  1.000000e+00     7                0.95599                0.951274\
4       O                             ...  1.729144e-07     7                0.95599                0.951274\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.455460e-05     7                0.95599                0.951274\
1996    S                       co\'fbt  ...  1.000000e+00     7                0.95599                0.951274\
1997    S                        TPS  ...  1.000000e+00     7                0.95599                0.951274\
1998    O                             ...  6.466605e-05     7                0.95599                0.951274\
1999    O                             ...  9.991554e-01     7                0.95599                0.951274\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9437652811735942, 'O': 0.9678848283499446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999995     6               0.943765                0.967885\
1       S                      \'9cuvre  ...      1.000000     6               0.943765                0.967885\
2       S               comportement  ...      1.000000     6               0.943765                0.967885\
3       A                     filles  ...      1.000000     6               0.943765                0.967885\
4       O                             ...      0.000367     6               0.943765                0.967885\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.119898     6               0.943765                0.967885\
1996    S                       co\'fbt  ...      1.000000     6               0.943765                0.967885\
1997    S                        TPS  ...      1.000000     6               0.943765                0.967885\
1998    O                             ...      0.000102     6               0.943765                0.967885\
1999    O                             ...      0.999990     6               0.943765                0.967885\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9388753056234719, 'O': 0.9335548172757475\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.991007e-01     5               0.938875                0.933555\
1       S                      \'9cuvre  ...  1.000000e+00     5               0.938875                0.933555\
2       S               comportement  ...  9.999995e-01     5               0.938875                0.933555\
3       A                     filles  ...  9.999995e-01     5               0.938875                0.933555\
4       O                             ...  4.032960e-07     5               0.938875                0.933555\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.513616e-02     5               0.938875                0.933555\
1996    S                       co\'fbt  ...  1.000000e+00     5               0.938875                0.933555\
1997    S                        TPS  ...  1.000000e+00     5               0.938875                0.933555\
1998    O                             ...  1.725765e-03     5               0.938875                0.933555\
1999    O                             ...  9.999996e-01     5               0.938875                0.933555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9070904645476773, 'O': 0.9080841638981174\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999684     4                0.90709                0.908084\
1       S                      \'9cuvre  ...      1.000000     4                0.90709                0.908084\
2       S               comportement  ...      0.999999     4                0.90709                0.908084\
3       A                     filles  ...      0.999956     4                0.90709                0.908084\
4       O                             ...      0.000001     4                0.90709                0.908084\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.001534     4                0.90709                0.908084\
1996    S                       co\'fbt  ...      0.999831     4                0.90709                0.908084\
1997    S                        TPS  ...      0.999999     4                0.90709                0.908084\
1998    O                             ...      0.001281     4                0.90709                0.908084\
1999    O                             ...      0.999087     4                0.90709                0.908084\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8997555012224939, 'O': 0.9136212624584718\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.765687e-01     3               0.899756                0.913621\
1       S                      \'9cuvre  ...  9.999466e-01     3               0.899756                0.913621\
2       S               comportement  ...  9.996765e-01     3               0.899756                0.913621\
3       A                     filles  ...  9.789836e-01     3               0.899756                0.913621\
4       O                             ...  3.302328e-07     3               0.899756                0.913621\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.185230e-04     3               0.899756                0.913621\
1996    S                       co\'fbt  ...  9.999940e-01     3               0.899756                0.913621\
1997    S                        TPS  ...  8.622014e-01     3               0.899756                0.913621\
1998    O                             ...  2.174476e-04     3               0.899756                0.913621\
1999    O                             ...  9.907337e-01     3               0.899756                0.913621\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7652811735941321, 'O': 0.858250276854928\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999832     2               0.765281                 0.85825\
1       S                      \'9cuvre  ...      0.998749     2               0.765281                 0.85825\
2       S               comportement  ...      1.000000     2               0.765281                 0.85825\
3       A                     filles  ...      0.314126     2               0.765281                 0.85825\
4       O                             ...      0.001846     2               0.765281                 0.85825\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.154835     2               0.765281                 0.85825\
1996    S                       co\'fbt  ...      0.999792     2               0.765281                 0.85825\
1997    S                        TPS  ...      0.801811     2               0.765281                 0.85825\
1998    O                             ...      0.011494     2               0.765281                 0.85825\
1999    O                             ...      0.500000     2               0.765281                 0.85825\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7555012224938875, 'O': 0.8217054263565892\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999992     1               0.755501                0.821705\
1       S                      \'9cuvre  ...      0.991357     1               0.755501                0.821705\
2       S               comportement  ...      0.999997     1               0.755501                0.821705\
3       A                     filles  ...      0.000263     1               0.755501                0.821705\
4       O                             ...      0.000653     1               0.755501                0.821705\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.036786     1               0.755501                0.821705\
1996    S                       co\'fbt  ...      1.000000     1               0.755501                0.821705\
1997    S                        TPS  ...      0.778797     1               0.755501                0.821705\
1998    O                             ...      0.083840     1               0.755501                0.821705\
1999    O                             ...      0.996666     1               0.755501                0.821705\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6968215158924206, 'O': 0.8073089700996677\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-passive': 4, 'S-passive': 5\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999049     0               0.696822                0.807309\
1       S                      \'9cuvre  ...      0.005034     0               0.696822                0.807309\
2       S               comportement  ...      1.000000     0               0.696822                0.807309\
3       A                     filles  ...      0.025243     0               0.696822                0.807309\
4       O                             ...      0.000506     0               0.696822                0.807309\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.355043     0               0.696822                0.807309\
1996    S                       co\'fbt  ...      0.999938     0               0.696822                0.807309\
1997    S                        TPS  ...      0.000018     0               0.696822                0.807309\
1998    O                             ...      0.383597     0               0.696822                0.807309\
1999    O                             ...      0.873809     0               0.696822                0.807309\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_fr_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1535 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1535/1535 [00:00<00:00, 3056.29it/s]\
Loaded 1534 sentences from disk.\
length of bert outputs 1535\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.000168    12               0.960976                 0.85929\
1       S                      \'9cuvre  ...      0.999993    12               0.960976                 0.85929\
2       S               comportement  ...      0.999585    12               0.960976                 0.85929\
3       A                     filles  ...      1.000000    12               0.960976                 0.85929\
4       O                             ...      0.939931    12               0.960976                 0.85929\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000590    12               0.960976                 0.85929\
1996    S                       co\'fbt  ...      0.990805    12               0.960976                 0.85929\
1997    S                        TPS  ...      1.000000    12               0.960976                 0.85929\
1998    O                             ...      0.000014    12               0.960976                 0.85929\
1999    O                             ...      0.444946    12               0.960976                 0.85929\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  2.864431e-02    11               0.980488                0.912568\
1       S                      \'9cuvre  ...  9.971049e-01    11               0.980488                0.912568\
2       S               comportement  ...  9.999981e-01    11               0.980488                0.912568\
3       A                     filles  ...  9.999709e-01    11               0.980488                0.912568\
4       O                             ...  1.183701e-01    11               0.980488                0.912568\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  9.802516e-05    11               0.980488                0.912568\
1996    S                       co\'fbt  ...  9.999999e-01    11               0.980488                0.912568\
1997    S                        TPS  ...  1.000000e+00    11               0.980488                0.912568\
1998    O                             ...  3.078452e-09    11               0.980488                0.912568\
1999    O                             ...  7.755287e-03    11               0.980488                0.912568\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.742018e-01    10                0.97561                0.904372\
1       S                      \'9cuvre  ...  1.000000e+00    10                0.97561                0.904372\
2       S               comportement  ...  9.999990e-01    10                0.97561                0.904372\
3       A                     filles  ...  1.000000e+00    10                0.97561                0.904372\
4       O                             ...  2.274342e-04    10                0.97561                0.904372\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  5.902658e-04    10                0.97561                0.904372\
1996    S                       co\'fbt  ...  9.999998e-01    10                0.97561                0.904372\
1997    S                        TPS  ...  1.000000e+00    10                0.97561                0.904372\
1998    O                             ...  2.531012e-08    10                0.97561                0.904372\
1999    O                             ...  2.890977e-01    10                0.97561                0.904372\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.995924e-01     9               0.980488                0.924863\
1       S                      \'9cuvre  ...  1.000000e+00     9               0.980488                0.924863\
2       S               comportement  ...  9.999996e-01     9               0.980488                0.924863\
3       A                     filles  ...  1.000000e+00     9               0.980488                0.924863\
4       O                             ...  1.875851e-05     9               0.980488                0.924863\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.067676e-04     9               0.980488                0.924863\
1996    S                       co\'fbt  ...  9.996325e-01     9               0.980488                0.924863\
1997    S                        TPS  ...  1.000000e+00     9               0.980488                0.924863\
1998    O                             ...  2.112688e-07     9               0.980488                0.924863\
1999    O                             ...  8.385608e-01     9               0.980488                0.924863\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.917671e-01     8               0.985366                0.941257\
1       S                      \'9cuvre  ...  1.000000e+00     8               0.985366                0.941257\
2       S               comportement  ...  1.000000e+00     8               0.985366                0.941257\
3       A                     filles  ...  9.999999e-01     8               0.985366                0.941257\
4       O                             ...  9.133140e-07     8               0.985366                0.941257\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.794605e-07     8               0.985366                0.941257\
1996    S                       co\'fbt  ...  9.994822e-01     8               0.985366                0.941257\
1997    S                        TPS  ...  1.000000e+00     8               0.985366                0.941257\
1998    O                             ...  9.870687e-08     8               0.985366                0.941257\
1999    O                             ...  8.030005e-01     8               0.985366                0.941257\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999976e-01     7               0.980488                0.939891\
1       S                      \'9cuvre  ...  9.999990e-01     7               0.980488                0.939891\
2       S               comportement  ...  9.996636e-01     7               0.980488                0.939891\
3       A                     filles  ...  1.000000e+00     7               0.980488                0.939891\
4       O                             ...  3.523102e-08     7               0.980488                0.939891\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.874003e-06     7               0.980488                0.939891\
1996    S                       co\'fbt  ...  9.999999e-01     7               0.980488                0.939891\
1997    S                        TPS  ...  1.000000e+00     7               0.980488                0.939891\
1998    O                             ...  6.017037e-09     7               0.980488                0.939891\
1999    O                             ...  4.709371e-01     7               0.980488                0.939891\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999981e-01     6                0.97561                0.927596\
1       S                      \'9cuvre  ...  9.999995e-01     6                0.97561                0.927596\
2       S               comportement  ...  1.000000e+00     6                0.97561                0.927596\
3       A                     filles  ...  1.000000e+00     6                0.97561                0.927596\
4       O                             ...  1.577829e-06     6                0.97561                0.927596\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.771737e-03     6                0.97561                0.927596\
1996    S                       co\'fbt  ...  1.000000e+00     6                0.97561                0.927596\
1997    S                        TPS  ...  9.999998e-01     6                0.97561                0.927596\
1998    O                             ...  2.107729e-07     6                0.97561                0.927596\
1999    O                             ...  9.972413e-01     6                0.97561                0.927596\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999588e-01     5               0.970732                0.901639\
1       S                      \'9cuvre  ...  9.999357e-01     5               0.970732                0.901639\
2       S               comportement  ...  9.999996e-01     5               0.970732                0.901639\
3       A                     filles  ...  9.999985e-01     5               0.970732                0.901639\
4       O                             ...  8.978621e-09     5               0.970732                0.901639\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.963994e-05     5               0.970732                0.901639\
1996    S                       co\'fbt  ...  1.000000e+00     5               0.970732                0.901639\
1997    S                        TPS  ...  9.999821e-01     5               0.970732                0.901639\
1998    O                             ...  2.610509e-05     5               0.970732                0.901639\
1999    O                             ...  9.530075e-01     5               0.970732                0.901639\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999992e-01     4               0.912195                0.826503\
1       S                      \'9cuvre  ...  9.999913e-01     4               0.912195                0.826503\
2       S               comportement  ...  9.999996e-01     4               0.912195                0.826503\
3       A                     filles  ...  1.000000e+00     4               0.912195                0.826503\
4       O                             ...  1.197544e-07     4               0.912195                0.826503\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  9.305234e-08     4               0.912195                0.826503\
1996    S                       co\'fbt  ...  9.999905e-01     4               0.912195                0.826503\
1997    S                        TPS  ...  9.997910e-01     4               0.912195                0.826503\
1998    O                             ...  4.042536e-06     4               0.912195                0.826503\
1999    O                             ...  3.608705e-03     4               0.912195                0.826503\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.898879e-01     3               0.936585                0.815574\
1       S                      \'9cuvre  ...  9.990583e-01     3               0.936585                0.815574\
2       S               comportement  ...  9.994854e-01     3               0.936585                0.815574\
3       A                     filles  ...  9.994753e-01     3               0.936585                0.815574\
4       O                             ...  2.946656e-06     3               0.936585                0.815574\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.327190e-08     3               0.936585                0.815574\
1996    S                       co\'fbt  ...  9.999999e-01     3               0.936585                0.815574\
1997    S                        TPS  ...  8.338588e-01     3               0.936585                0.815574\
1998    O                             ...  1.040278e-07     3               0.936585                0.815574\
1999    O                             ...  4.383351e-01     3               0.936585                0.815574\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.961038e-01     2               0.858537                0.717213\
1       S                      \'9cuvre  ...  9.997875e-01     2               0.858537                0.717213\
2       S               comportement  ...  9.999998e-01     2               0.858537                0.717213\
3       A                     filles  ...  7.656161e-01     2               0.858537                0.717213\
4       O                             ...  5.117015e-03     2               0.858537                0.717213\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.205956e-04     2               0.858537                0.717213\
1996    S                       co\'fbt  ...  9.999433e-01     2               0.858537                0.717213\
1997    S                        TPS  ...  9.999812e-01     2               0.858537                0.717213\
1998    O                             ...  3.516285e-10     2               0.858537                0.717213\
1999    O                             ...  5.000000e-01     2               0.858537                0.717213\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999657e-01     1               0.780488                0.709016\
1       S                      \'9cuvre  ...  9.979209e-01     1               0.780488                0.709016\
2       S               comportement  ...  9.936014e-01     1               0.780488                0.709016\
3       A                     filles  ...  2.280247e-01     1               0.780488                0.709016\
4       O                             ...  1.531758e-01     1               0.780488                0.709016\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  3.128624e-04     1               0.780488                0.709016\
1996    S                       co\'fbt  ...  9.999998e-01     1               0.780488                0.709016\
1997    S                        TPS  ...  9.998159e-01     1               0.780488                0.709016\
1998    O                             ...  3.657017e-08     1               0.780488                0.709016\
1999    O                             ...  1.543251e-01     1               0.780488                0.709016\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999939     0               0.790244                0.665301\
1       S                      \'9cuvre  ...      0.999944     0               0.790244                0.665301\
2       S               comportement  ...      0.999894     0               0.790244                0.665301\
3       A                     filles  ...      0.827904     0               0.790244                0.665301\
4       O                             ...      0.997333     0               0.790244                0.665301\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.011365     0               0.790244                0.665301\
1996    S                       co\'fbt  ...      1.000000     0               0.790244                0.665301\
1997    S                        TPS  ...      0.999941     0               0.790244                0.665301\
1998    O                             ...      0.007643     0               0.790244                0.665301\
1999    O                             ...      0.831220     0               0.790244                0.665301\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_fr_gsd-ud-test.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-test.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_fr_gsd-ud-test_aso_unbalanced_2000.pkl\
There are 501 relevant tokens, and 416 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-test_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 416/416 [00:00<00:00, 2480.51it/s]\
Loaded 415 sentences from disk.\
length of bert outputs 416\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  3.277833e-09    12               0.958763                0.929329\
1            S                       ONG  ...  9.999971e-01    12               0.958763                0.929329\
2            O                            ...  3.179692e-04    12               0.958763                0.929329\
3            O                            ...  5.834075e-04    12               0.958763                0.929329\
4            O                            ...  8.638679e-08    12               0.958763                0.929329\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  5.109519e-07    12               0.958763                0.929329\
497  S-passive                 pr\'e9sident  ...  7.610182e-02    12               0.958763                0.929329\
498  S-passive                   r\'e9union  ...  9.999958e-01    12               0.958763                0.929329\
499          O                            ...  1.404156e-06    12               0.958763                0.929329\
500          O                            ...  6.418768e-05    12               0.958763                0.929329\
\
[501 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  1.838114e-11    11               0.958763                0.975265\
1            S                       ONG  ...  9.999970e-01    11               0.958763                0.975265\
2            O                            ...  1.159615e-04    11               0.958763                0.975265\
3            O                            ...  2.698721e-07    11               0.958763                0.975265\
4            O                            ...  5.056340e-05    11               0.958763                0.975265\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  1.643961e-11    11               0.958763                0.975265\
497  S-passive                 pr\'e9sident  ...  8.202395e-01    11               0.958763                0.975265\
498  S-passive                   r\'e9union  ...  9.999769e-01    11               0.958763                0.975265\
499          O                            ...  7.281412e-15    11               0.958763                0.975265\
500          O                            ...  2.968313e-07    11               0.958763                0.975265\
\
[501 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  8.664421e-12    10               0.958763                0.961131\
1            S                       ONG  ...  9.999996e-01    10               0.958763                0.961131\
2            O                            ...  3.656449e-03    10               0.958763                0.961131\
3            O                            ...  1.281832e-09    10               0.958763                0.961131\
4            O                            ...  2.881544e-04    10               0.958763                0.961131\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  2.430329e-06    10               0.958763                0.961131\
497  S-passive                 pr\'e9sident  ...  1.918166e-01    10               0.958763                0.961131\
498  S-passive                   r\'e9union  ...  1.000000e+00    10               0.958763                0.961131\
499          O                            ...  1.122565e-14    10               0.958763                0.961131\
500          O                            ...  1.591705e-02    10               0.958763                0.961131\
\
[501 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  3.932029e-12     9               0.958763                0.971731\
1            S                       ONG  ...  9.997162e-01     9               0.958763                0.971731\
2            O                            ...  2.359157e-06     9               0.958763                0.971731\
3            O                            ...  1.546411e-10     9               0.958763                0.971731\
4            O                            ...  1.128194e-09     9               0.958763                0.971731\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  4.172912e-14     9               0.958763                0.971731\
497  S-passive                 pr\'e9sident  ...  8.866132e-01     9               0.958763                0.971731\
498  S-passive                   r\'e9union  ...  1.000000e+00     9               0.958763                0.971731\
499          O                            ...  8.598683e-08     9               0.958763                0.971731\
500          O                            ...  3.427655e-07     9               0.958763                0.971731\
\
[501 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  1.527960e-11     8               0.958763                0.961131\
1            S                       ONG  ...  9.999994e-01     8               0.958763                0.961131\
2            O                            ...  1.822592e-07     8               0.958763                0.961131\
3            O                            ...  2.148051e-03     8               0.958763                0.961131\
4            O                            ...  3.190437e-08     8               0.958763                0.961131\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  8.891454e-12     8               0.958763                0.961131\
497  S-passive                 pr\'e9sident  ...  9.999889e-01     8               0.958763                0.961131\
498  S-passive                   r\'e9union  ...  1.000000e+00     8               0.958763                0.961131\
499          O                            ...  1.058687e-11     8               0.958763                0.961131\
500          O                            ...  4.123496e-03     8               0.958763                0.961131\
\
[501 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  1.417824e-10     7               0.958763                0.971731\
1            S                       ONG  ...  9.999551e-01     7               0.958763                0.971731\
2            O                            ...  2.597040e-08     7               0.958763                0.971731\
3            O                            ...  1.225592e-05     7               0.958763                0.971731\
4            O                            ...  8.461575e-09     7               0.958763                0.971731\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  8.740000e-10     7               0.958763                0.971731\
497  S-passive                 pr\'e9sident  ...  9.999988e-01     7               0.958763                0.971731\
498  S-passive                   r\'e9union  ...  1.000000e+00     7               0.958763                0.971731\
499          O                            ...  1.088109e-05     7               0.958763                0.971731\
500          O                            ...  4.922087e-05     7               0.958763                0.971731\
\
[501 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  5.874338e-07     6               0.938144                0.968198\
1            S                       ONG  ...  9.996560e-01     6               0.938144                0.968198\
2            O                            ...  5.888049e-01     6               0.938144                0.968198\
3            O                            ...  2.483383e-04     6               0.938144                0.968198\
4            O                            ...  5.091589e-08     6               0.938144                0.968198\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  1.788618e-09     6               0.938144                0.968198\
497  S-passive                 pr\'e9sident  ...  9.999987e-01     6               0.938144                0.968198\
498  S-passive                   r\'e9union  ...  1.000000e+00     6               0.938144                0.968198\
499          O                            ...  8.362120e-07     6               0.938144                0.968198\
500          O                            ...  2.562697e-06     6               0.938144                0.968198\
\
[501 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  3.694948e-08     5               0.969072                0.943463\
1            S                       ONG  ...  9.969013e-01     5               0.969072                0.943463\
2            O                            ...  5.499300e-02     5               0.969072                0.943463\
3            O                            ...  2.787647e-05     5               0.969072                0.943463\
4            O                            ...  6.229949e-08     5               0.969072                0.943463\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  3.899945e-10     5               0.969072                0.943463\
497  S-passive                 pr\'e9sident  ...  9.999990e-01     5               0.969072                0.943463\
498  S-passive                   r\'e9union  ...  9.997863e-01     5               0.969072                0.943463\
499          O                            ...  9.945524e-08     5               0.969072                0.943463\
500          O                            ...  8.982985e-10     5               0.969072                0.943463\
\
[501 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  6.352001e-08     4               0.917526                0.946996\
1            S                       ONG  ...  9.990157e-01     4               0.917526                0.946996\
2            O                            ...  1.107602e-05     4               0.917526                0.946996\
3            O                            ...  2.484610e-05     4               0.917526                0.946996\
4            O                            ...  2.701094e-04     4               0.917526                0.946996\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  3.293842e-07     4               0.917526                0.946996\
497  S-passive                 pr\'e9sident  ...  9.956808e-01     4               0.917526                0.946996\
498  S-passive                   r\'e9union  ...  9.999999e-01     4               0.917526                0.946996\
499          O                            ...  4.199260e-03     4               0.917526                0.946996\
500          O                            ...  5.536531e-07     4               0.917526                0.946996\
\
[501 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  2.597451e-08     3               0.938144                0.936396\
1            S                       ONG  ...  5.541534e-01     3               0.938144                0.936396\
2            O                            ...  2.198626e-04     3               0.938144                0.936396\
3            O                            ...  1.707406e-05     3               0.938144                0.936396\
4            O                            ...  2.835184e-03     3               0.938144                0.936396\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  3.989134e-10     3               0.938144                0.936396\
497  S-passive                 pr\'e9sident  ...  9.989888e-01     3               0.938144                0.936396\
498  S-passive                   r\'e9union  ...  1.000000e+00     3               0.938144                0.936396\
499          O                            ...  1.317034e-05     3               0.938144                0.936396\
500          O                            ...  6.425159e-08     3               0.938144                0.936396\
\
[501 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  1.598952e-09     2               0.783505                0.795053\
1            S                       ONG  ...  7.800296e-02     2               0.783505                0.795053\
2            O                            ...  6.075559e-06     2               0.783505                0.795053\
3            O                            ...  2.074392e-01     2               0.783505                0.795053\
4            O                            ...  4.592405e-03     2               0.783505                0.795053\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  2.562087e-08     2               0.783505                0.795053\
497  S-passive                 pr\'e9sident  ...  6.259246e-01     2               0.783505                0.795053\
498  S-passive                   r\'e9union  ...  1.000000e+00     2               0.783505                0.795053\
499          O                            ...  1.300820e-02     2               0.783505                0.795053\
500          O                            ...  1.783628e-07     2               0.783505                0.795053\
\
[501 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...      0.000013     1               0.793814                0.773852\
1            S                       ONG  ...      0.000061     1               0.793814                0.773852\
2            O                            ...      0.002737     1               0.793814                0.773852\
3            O                            ...      0.042948     1               0.793814                0.773852\
4            O                            ...      0.011423     1               0.793814                0.773852\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...      0.000219     1               0.793814                0.773852\
497  S-passive                 pr\'e9sident  ...      0.352125     1               0.793814                0.773852\
498  S-passive                   r\'e9union  ...      1.000000     1               0.793814                0.773852\
499          O                            ...      0.170072     1               0.793814                0.773852\
500          O                            ...      0.208965     1               0.793814                0.773852\
\
[501 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 501\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 501 examples to evaluate on.\
          role case animacy subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0            O                            ...  3.886690e-06     0               0.721649                0.816254\
1            S                       ONG  ...  4.672147e-04     0               0.721649                0.816254\
2            O                            ...  7.693897e-09     0               0.721649                0.816254\
3            O                            ...  3.099236e-01     0               0.721649                0.816254\
4            O                            ...  3.234588e-03     0               0.721649                0.816254\
..         ...  ...     ...          ...  ...           ...   ...                    ...                     ...\
496          O                            ...  9.214582e-06     0               0.721649                0.816254\
497  S-passive                 pr\'e9sident  ...  3.868331e-01     0               0.721649                0.816254\
498  S-passive                   r\'e9union  ...  9.999988e-01     0               0.721649                0.816254\
499          O                            ...  5.369232e-02     0               0.721649                0.816254\
500          O                            ...  5.000000e-01     0               0.721649                0.816254\
\
[501 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_fr_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1535 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1535/1535 [00:00<00:00, 2754.24it/s]\
Loaded 1534 sentences from disk.\
length of bert outputs 1535\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.002313    12                0.84556                0.873118\
1       S                      \'9cuvre  ...      1.000000    12                0.84556                0.873118\
2       S               comportement  ...      0.999995    12                0.84556                0.873118\
3       A                     filles  ...      0.999816    12                0.84556                0.873118\
4       O                             ...      0.000078    12                0.84556                0.873118\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.999885    12                0.84556                0.873118\
1996    S                       co\'fbt  ...      1.000000    12                0.84556                0.873118\
1997    S                        TPS  ...      0.999999    12                0.84556                0.873118\
1998    O                             ...      0.000004    12                0.84556                0.873118\
1999    O                             ...      0.451170    12                0.84556                0.873118\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  8.709804e-01    11               0.880309                0.896774\
1       S                      \'9cuvre  ...  9.999956e-01    11               0.880309                0.896774\
2       S               comportement  ...  9.999994e-01    11               0.880309                0.896774\
3       A                     filles  ...  9.999052e-01    11               0.880309                0.896774\
4       O                             ...  9.314367e-07    11               0.880309                0.896774\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  7.838690e-01    11               0.880309                0.896774\
1996    S                       co\'fbt  ...  9.999863e-01    11               0.880309                0.896774\
1997    S                        TPS  ...  1.000000e+00    11               0.880309                0.896774\
1998    O                             ...  1.136668e-05    11               0.880309                0.896774\
1999    O                             ...  7.407660e-01    11               0.880309                0.896774\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.983906e-01    10               0.915058                0.922581\
1       S                      \'9cuvre  ...  1.000000e+00    10               0.915058                0.922581\
2       S               comportement  ...  9.999990e-01    10               0.915058                0.922581\
3       A                     filles  ...  1.000000e+00    10               0.915058                0.922581\
4       O                             ...  1.193770e-07    10               0.915058                0.922581\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.385028e-01    10               0.915058                0.922581\
1996    S                       co\'fbt  ...  9.998640e-01    10               0.915058                0.922581\
1997    S                        TPS  ...  1.000000e+00    10               0.915058                0.922581\
1998    O                             ...  7.550120e-06    10               0.915058                0.922581\
1999    O                             ...  8.937221e-01    10               0.915058                0.922581\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.999913e-01     9               0.903475                0.909677\
1       S                      \'9cuvre  ...  1.000000e+00     9               0.903475                0.909677\
2       S               comportement  ...  1.000000e+00     9               0.903475                0.909677\
3       A                     filles  ...  1.000000e+00     9               0.903475                0.909677\
4       O                             ...  5.542512e-07     9               0.903475                0.909677\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.000964e-03     9               0.903475                0.909677\
1996    S                       co\'fbt  ...  9.999070e-01     9               0.903475                0.909677\
1997    S                        TPS  ...  1.000000e+00     9               0.903475                0.909677\
1998    O                             ...  5.156835e-06     9               0.903475                0.909677\
1999    O                             ...  1.673908e-01     9               0.903475                0.909677\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.998279     8               0.891892                0.913978\
1       S                      \'9cuvre  ...      1.000000     8               0.891892                0.913978\
2       S               comportement  ...      1.000000     8               0.891892                0.913978\
3       A                     filles  ...      1.000000     8               0.891892                0.913978\
4       O                             ...      0.000006     8               0.891892                0.913978\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000243     8               0.891892                0.913978\
1996    S                       co\'fbt  ...      0.999913     8               0.891892                0.913978\
1997    S                        TPS  ...      1.000000     8               0.891892                0.913978\
1998    O                             ...      0.000197     8               0.891892                0.913978\
1999    O                             ...      0.216882     8               0.891892                0.913978\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.987468e-01     7               0.911197                0.892473\
1       S                      \'9cuvre  ...  1.000000e+00     7               0.911197                0.892473\
2       S               comportement  ...  9.989246e-01     7               0.911197                0.892473\
3       A                     filles  ...  1.000000e+00     7               0.911197                0.892473\
4       O                             ...  5.250747e-05     7               0.911197                0.892473\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  9.429403e-07     7               0.911197                0.892473\
1996    S                       co\'fbt  ...  9.999995e-01     7               0.911197                0.892473\
1997    S                        TPS  ...  1.000000e+00     7               0.911197                0.892473\
1998    O                             ...  1.006663e-04     7               0.911197                0.892473\
1999    O                             ...  5.103543e-05     7               0.911197                0.892473\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.593214     6               0.888031                0.890323\
1       S                      \'9cuvre  ...      1.000000     6               0.888031                0.890323\
2       S               comportement  ...      0.999992     6               0.888031                0.890323\
3       A                     filles  ...      1.000000     6               0.888031                0.890323\
4       O                             ...      0.000325     6               0.888031                0.890323\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000050     6               0.888031                0.890323\
1996    S                       co\'fbt  ...      1.000000     6               0.888031                0.890323\
1997    S                        TPS  ...      1.000000     6               0.888031                0.890323\
1998    O                             ...      0.000661     6               0.888031                0.890323\
1999    O                             ...      0.003490     6               0.888031                0.890323\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.343684     5               0.803089                 0.84086\
1       S                      \'9cuvre  ...      1.000000     5               0.803089                 0.84086\
2       S               comportement  ...      1.000000     5               0.803089                 0.84086\
3       A                     filles  ...      1.000000     5               0.803089                 0.84086\
4       O                             ...      0.000023     5               0.803089                 0.84086\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000020     5               0.803089                 0.84086\
1996    S                       co\'fbt  ...      1.000000     5               0.803089                 0.84086\
1997    S                        TPS  ...      0.999987     5               0.803089                 0.84086\
1998    O                             ...      0.046512     5               0.803089                 0.84086\
1999    O                             ...      0.996366     5               0.803089                 0.84086\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.292292     4               0.826255                0.756989\
1       S                      \'9cuvre  ...      1.000000     4               0.826255                0.756989\
2       S               comportement  ...      0.999989     4               0.826255                0.756989\
3       A                     filles  ...      0.999991     4               0.826255                0.756989\
4       O                             ...      0.000002     4               0.826255                0.756989\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000002     4               0.826255                0.756989\
1996    S                       co\'fbt  ...      0.999328     4               0.826255                0.756989\
1997    S                        TPS  ...      0.998989     4               0.826255                0.756989\
1998    O                             ...      0.007111     4               0.826255                0.756989\
1999    O                             ...      0.856011     4               0.826255                0.756989\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.805859     3                0.80695                0.787097\
1       S                      \'9cuvre  ...      0.999998     3                0.80695                0.787097\
2       S               comportement  ...      0.994172     3                0.80695                0.787097\
3       A                     filles  ...      0.982287     3                0.80695                0.787097\
4       O                             ...      0.000075     3                0.80695                0.787097\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000007     3                0.80695                0.787097\
1996    S                       co\'fbt  ...      1.000000     3                0.80695                0.787097\
1997    S                        TPS  ...      0.763024     3                0.80695                0.787097\
1998    O                             ...      0.000007     3                0.80695                0.787097\
1999    O                             ...      0.792480     3                0.80695                0.787097\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.663854e-01     2               0.722008                0.825806\
1       S                      \'9cuvre  ...  9.999981e-01     2               0.722008                0.825806\
2       S               comportement  ...  1.000000e+00     2               0.722008                0.825806\
3       A                     filles  ...  9.999977e-01     2               0.722008                0.825806\
4       O                             ...  6.878950e-05     2               0.722008                0.825806\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.113351e-02     2               0.722008                0.825806\
1996    S                       co\'fbt  ...  9.999975e-01     2               0.722008                0.825806\
1997    S                        TPS  ...  9.921469e-01     2               0.722008                0.825806\
1998    O                             ...  2.323199e-07     2               0.722008                0.825806\
1999    O                             ...  5.000000e-01     2               0.722008                0.825806\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.997601     1               0.675676                0.756989\
1       S                      \'9cuvre  ...      1.000000     1               0.675676                0.756989\
2       S               comportement  ...      1.000000     1               0.675676                0.756989\
3       A                     filles  ...      0.999896     1               0.675676                0.756989\
4       O                             ...      0.030214     1               0.675676                0.756989\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.741580     1               0.675676                0.756989\
1996    S                       co\'fbt  ...      1.000000     1               0.675676                0.756989\
1997    S                        TPS  ...      0.988228     1               0.675676                0.756989\
1998    O                             ...      0.000035     1               0.675676                0.756989\
1999    O                             ...      0.998393     1               0.675676                0.756989\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.641614     0               0.722008                0.673118\
1       S                      \'9cuvre  ...      1.000000     0               0.722008                0.673118\
2       S               comportement  ...      0.999995     0               0.722008                0.673118\
3       A                     filles  ...      0.999070     0               0.722008                0.673118\
4       O                             ...      0.671057     0               0.722008                0.673118\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.022159     0               0.722008                0.673118\
1996    S                       co\'fbt  ...      0.999900     0               0.722008                0.673118\
1997    S                        TPS  ...      0.272069     0               0.722008                0.673118\
1998    O                             ...      0.177514     0               0.722008                0.673118\
1999    O                             ...      0.994680     0               0.722008                0.673118\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_fr_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_French-GSD-master/fr_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1535 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_fr_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1535/1535 [00:00<00:00, 3043.85it/s]\
Loaded 1534 sentences from disk.\
length of bert outputs 1535\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.000041    12               0.978723                0.872247\
1       S                      \'9cuvre  ...      0.999651    12               0.978723                0.872247\
2       S               comportement  ...      0.999993    12               0.978723                0.872247\
3       A                     filles  ...      1.000000    12               0.978723                0.872247\
4       O                             ...      0.801925    12               0.978723                0.872247\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.087154    12               0.978723                0.872247\
1996    S                       co\'fbt  ...      0.998729    12               0.978723                0.872247\
1997    S                        TPS  ...      0.999898    12               0.978723                0.872247\
1998    O                             ...      0.000018    12               0.978723                0.872247\
1999    O                             ...      0.999658    12               0.978723                0.872247\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  6.563231e-06    11               0.978723                0.898678\
1       S                      \'9cuvre  ...  9.972737e-01    11               0.978723                0.898678\
2       S               comportement  ...  1.000000e+00    11               0.978723                0.898678\
3       A                     filles  ...  9.992937e-01    11               0.978723                0.898678\
4       O                             ...  9.245838e-04    11               0.978723                0.898678\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.462249e-08    11               0.978723                0.898678\
1996    S                       co\'fbt  ...  9.999956e-01    11               0.978723                0.898678\
1997    S                        TPS  ...  9.999957e-01    11               0.978723                0.898678\
1998    O                             ...  1.174104e-06    11               0.978723                0.898678\
1999    O                             ...  9.952075e-01    11               0.978723                0.898678\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  2.043519e-04    10               0.978723                0.929515\
1       S                      \'9cuvre  ...  9.999971e-01    10               0.978723                0.929515\
2       S               comportement  ...  9.999996e-01    10               0.978723                0.929515\
3       A                     filles  ...  1.000000e+00    10               0.978723                0.929515\
4       O                             ...  4.512818e-06    10               0.978723                0.929515\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.414841e-08    10               0.978723                0.929515\
1996    S                       co\'fbt  ...  9.931434e-01    10               0.978723                0.929515\
1997    S                        TPS  ...  9.999996e-01    10               0.978723                0.929515\
1998    O                             ...  1.107820e-08    10               0.978723                0.929515\
1999    O                             ...  2.665305e-01    10               0.978723                0.929515\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  6.681403e-01     9               0.989362                0.920705\
1       S                      \'9cuvre  ...  9.999950e-01     9               0.989362                0.920705\
2       S               comportement  ...  9.999998e-01     9               0.989362                0.920705\
3       A                     filles  ...  1.000000e+00     9               0.989362                0.920705\
4       O                             ...  1.963885e-07     9               0.989362                0.920705\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  4.261974e-10     9               0.989362                0.920705\
1996    S                       co\'fbt  ...  7.901425e-01     9               0.989362                0.920705\
1997    S                        TPS  ...  9.999989e-01     9               0.989362                0.920705\
1998    O                             ...  2.004959e-07     9               0.989362                0.920705\
1999    O                             ...  5.502945e-03     9               0.989362                0.920705\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  4.537149e-01     8               0.989362                0.929515\
1       S                      \'9cuvre  ...  9.997699e-01     8               0.989362                0.929515\
2       S               comportement  ...  9.999999e-01     8               0.989362                0.929515\
3       A                     filles  ...  1.000000e+00     8               0.989362                0.929515\
4       O                             ...  8.051426e-07     8               0.989362                0.929515\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.055391e-09     8               0.989362                0.929515\
1996    S                       co\'fbt  ...  9.882824e-01     8               0.989362                0.929515\
1997    S                        TPS  ...  1.000000e+00     8               0.989362                0.929515\
1998    O                             ...  2.001265e-06     8               0.989362                0.929515\
1999    O                             ...  1.860513e-04     8               0.989362                0.929515\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  1.209828e-01     7               0.978723                 0.92511\
1       S                      \'9cuvre  ...  9.692047e-01     7               0.978723                 0.92511\
2       S               comportement  ...  9.967554e-01     7               0.978723                 0.92511\
3       A                     filles  ...  9.999987e-01     7               0.978723                 0.92511\
4       O                             ...  3.670861e-07     7               0.978723                 0.92511\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  6.674769e-11     7               0.978723                 0.92511\
1996    S                       co\'fbt  ...  9.999560e-01     7               0.978723                 0.92511\
1997    S                        TPS  ...  1.000000e+00     7               0.978723                 0.92511\
1998    O                             ...  1.237823e-07     7               0.978723                 0.92511\
1999    O                             ...  9.772896e-07     7               0.978723                 0.92511\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  5.149223e-01     6               0.957447                0.920705\
1       S                      \'9cuvre  ...  9.961745e-01     6               0.957447                0.920705\
2       S               comportement  ...  9.996181e-01     6               0.957447                0.920705\
3       A                     filles  ...  9.999999e-01     6               0.957447                0.920705\
4       O                             ...  1.637847e-05     6               0.957447                0.920705\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  1.921996e-07     6               0.957447                0.920705\
1996    S                       co\'fbt  ...  6.473959e-01     6               0.957447                0.920705\
1997    S                        TPS  ...  1.000000e+00     6               0.957447                0.920705\
1998    O                             ...  1.607293e-09     6               0.957447                0.920705\
1999    O                             ...  1.864519e-05     6               0.957447                0.920705\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  2.630249e-01     5               0.968085                0.863436\
1       S                      \'9cuvre  ...  1.138484e-01     5               0.968085                0.863436\
2       S               comportement  ...  9.998426e-01     5               0.968085                0.863436\
3       A                     filles  ...  9.999418e-01     5               0.968085                0.863436\
4       O                             ...  4.715922e-09     5               0.968085                0.863436\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  2.181673e-12     5               0.968085                0.863436\
1996    S                       co\'fbt  ...  9.999920e-01     5               0.968085                0.863436\
1997    S                        TPS  ...  9.999962e-01     5               0.968085                0.863436\
1998    O                             ...  4.386607e-04     5               0.968085                0.863436\
1999    O                             ...  9.329842e-02     5               0.968085                0.863436\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  9.952919e-01     4               0.957447                0.797357\
1       S                      \'9cuvre  ...  8.764130e-05     4               0.957447                0.797357\
2       S               comportement  ...  9.999127e-01     4               0.957447                0.797357\
3       A                     filles  ...  9.998251e-01     4               0.957447                0.797357\
4       O                             ...  3.050645e-06     4               0.957447                0.797357\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.676907e-12     4               0.957447                0.797357\
1996    S                       co\'fbt  ...  8.736361e-01     4               0.957447                0.797357\
1997    S                        TPS  ...  2.122147e-01     4               0.957447                0.797357\
1998    O                             ...  3.143409e-05     4               0.957447                0.797357\
1999    O                             ...  5.975545e-02     4               0.957447                0.797357\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...  5.864542e-01     3               0.914894                0.810573\
1       S                      \'9cuvre  ...  2.423088e-02     3               0.914894                0.810573\
2       S               comportement  ...  5.175954e-01     3               0.914894                0.810573\
3       A                     filles  ...  9.654169e-01     3               0.914894                0.810573\
4       O                             ...  5.860360e-07     3               0.914894                0.810573\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...  8.948305e-10     3               0.914894                0.810573\
1996    S                       co\'fbt  ...  9.088016e-01     3               0.914894                0.810573\
1997    S                        TPS  ...  4.401265e-02     3               0.914894                0.810573\
1998    O                             ...  5.682145e-09     3               0.914894                0.810573\
1999    O                             ...  1.054520e-01     3               0.914894                0.810573\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.985051     2               0.787234                0.674009\
1       S                      \'9cuvre  ...      0.460404     2               0.787234                0.674009\
2       S               comportement  ...      0.934522     2               0.787234                0.674009\
3       A                     filles  ...      0.552888     2               0.787234                0.674009\
4       O                             ...      0.629445     2               0.787234                0.674009\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.000761     2               0.787234                0.674009\
1996    S                       co\'fbt  ...      0.986301     2               0.787234                0.674009\
1997    S                        TPS  ...      0.329020     2               0.787234                0.674009\
1998    O                             ...      0.000111     2               0.787234                0.674009\
1999    O                             ...      0.500000     2               0.787234                0.674009\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.961931     1               0.765957                 0.69163\
1       S                      \'9cuvre  ...      0.148065     1               0.765957                 0.69163\
2       S               comportement  ...      0.687924     1               0.765957                 0.69163\
3       A                     filles  ...      0.009735     1               0.765957                 0.69163\
4       O                             ...      0.160810     1               0.765957                 0.69163\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.020799     1               0.765957                 0.69163\
1996    S                       co\'fbt  ...      0.875887     1               0.765957                 0.69163\
1997    S                        TPS  ...      0.669103     1               0.765957                 0.69163\
1998    O                             ...      0.000027     1               0.765957                 0.69163\
1999    O                             ...      1.000000     1               0.765957                 0.69163\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
     role case animacy  subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       S                 commotions  ...      0.999213     0               0.712766                0.788546\
1       S                      \'9cuvre  ...      0.994358     0               0.712766                0.788546\
2       S               comportement  ...      0.975773     0               0.712766                0.788546\
3       A                     filles  ...      0.980901     0               0.712766                0.788546\
4       O                             ...      0.986964     0               0.712766                0.788546\
...   ...  ...     ...           ...  ...           ...   ...                    ...                     ...\
1995    S                 faiblesses  ...      0.012865     0               0.712766                0.788546\
1996    S                       co\'fbt  ...      0.857219     0               0.712766                0.788546\
1997    S                        TPS  ...      0.012699     0               0.712766                0.788546\
1998    O                             ...      0.054566     0               0.712766                0.788546\
1999    O                             ...      0.999607     0               0.712766                0.788546\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/ko_kaist-ud_de_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Korean-Kaist-master/ko_kaist-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2001 relevant tokens, and 2183 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.hdf5\
Running 2183 sentences through BERT. This takes a while\
100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2183/2183 [01:14<00:00, 29.29it/s]\
length of bert outputs 2183\
On layer 12\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9186991869918699, 'O': 0.7310278578290106\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.983477    12               0.918699                0.731028\
1     S-passive  Nom                    Kosten  ...      0.999126    12               0.918699                0.731028\
2             O  Acc                            ...      0.000375    12               0.918699                0.731028\
3             O  Nom                            ...      0.742423    12               0.918699                0.731028\
4             O  Acc                            ...      0.001273    12               0.918699                0.731028\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.972011    12               0.918699                0.731028\
1997          O  Acc                            ...      0.116366    12               0.918699                0.731028\
1998          O  Acc                            ...      0.008802    12               0.918699                0.731028\
1999          A  Nom                   Ibrahim  ...      1.000000    12               0.918699                0.731028\
2000          O  Acc                            ...      0.999998    12               0.918699                0.731028\
\
[2001 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.7905859750240154\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.139153    11               0.910569                0.790586\
1     S-passive  Nom                    Kosten  ...      0.999960    11               0.910569                0.790586\
2             O  Acc                            ...      0.000280    11               0.910569                0.790586\
3             O  Nom                            ...      0.129853    11               0.910569                0.790586\
4             O  Acc                            ...      0.000630    11               0.910569                0.790586\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.997503    11               0.910569                0.790586\
1997          O  Acc                            ...      0.242921    11               0.910569                0.790586\
1998          O  Acc                            ...      0.011893    11               0.910569                0.790586\
1999          A  Nom                   Ibrahim  ...      1.000000    11               0.910569                0.790586\
2000          O  Acc                            ...      0.999999    11               0.910569                0.790586\
\
[2001 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.8213256484149856\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  6.895957e-03    10               0.886179                0.821326\
1     S-passive  Nom                    Kosten  ...  9.999996e-01    10               0.886179                0.821326\
2             O  Acc                            ...  4.038279e-07    10               0.886179                0.821326\
3             O  Nom                            ...  2.771800e-02    10               0.886179                0.821326\
4             O  Acc                            ...  8.466431e-04    10               0.886179                0.821326\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  7.402203e-01    10               0.886179                0.821326\
1997          O  Acc                            ...  3.364749e-01    10               0.886179                0.821326\
1998          O  Acc                            ...  8.750052e-04    10               0.886179                0.821326\
1999          A  Nom                   Ibrahim  ...  1.000000e+00    10               0.886179                0.821326\
2000          O  Acc                            ...  9.999961e-01    10               0.886179                0.821326\
\
[2001 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  6.225874e-01     9               0.910569                0.855908\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     9               0.910569                0.855908\
2             O  Acc                            ...  3.503801e-09     9               0.910569                0.855908\
3             O  Nom                            ...  9.093991e-02     9               0.910569                0.855908\
4             O  Acc                            ...  3.169614e-04     9               0.910569                0.855908\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.974365e-01     9               0.910569                0.855908\
1997          O  Acc                            ...  1.293752e-03     9               0.910569                0.855908\
1998          O  Acc                            ...  2.120587e-03     9               0.910569                0.855908\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     9               0.910569                0.855908\
2000          O  Acc                            ...  9.982532e-01     9               0.910569                0.855908\
\
[2001 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  1.463347e-03     8               0.910569                0.855908\
1     S-passive  Nom                    Kosten  ...  9.999776e-01     8               0.910569                0.855908\
2             O  Acc                            ...  4.143546e-09     8               0.910569                0.855908\
3             O  Nom                            ...  3.054455e-03     8               0.910569                0.855908\
4             O  Acc                            ...  7.226016e-02     8               0.910569                0.855908\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999125e-01     8               0.910569                0.855908\
1997          O  Acc                            ...  1.792006e-02     8               0.910569                0.855908\
1998          O  Acc                            ...  3.666096e-07     8               0.910569                0.855908\
1999          A  Nom                   Ibrahim  ...  9.992738e-01     8               0.910569                0.855908\
2000          O  Acc                            ...  9.565209e-01     8               0.910569                0.855908\
\
[2001 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8914505283381364\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  8.872956e-01     7               0.934959                0.891451\
1     S-passive  Nom                    Kosten  ...  9.305241e-01     7               0.934959                0.891451\
2             O  Acc                            ...  3.821746e-08     7               0.934959                0.891451\
3             O  Nom                            ...  9.629628e-02     7               0.934959                0.891451\
4             O  Acc                            ...  2.571248e-05     7               0.934959                0.891451\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     7               0.934959                0.891451\
1997          O  Acc                            ...  2.412462e-01     7               0.934959                0.891451\
1998          O  Acc                            ...  4.433591e-04     7               0.934959                0.891451\
1999          A  Nom                   Ibrahim  ...  9.995123e-01     7               0.934959                0.891451\
2000          O  Acc                            ...  1.824446e-01     7               0.934959                0.891451\
\
[2001 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8194044188280499\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  3.452665e-02     6               0.934959                0.819404\
1     S-passive  Nom                    Kosten  ...  6.204569e-01     6               0.934959                0.819404\
2             O  Acc                            ...  2.067013e-05     6               0.934959                0.819404\
3             O  Nom                            ...  7.071214e-01     6               0.934959                0.819404\
4             O  Acc                            ...  2.072243e-03     6               0.934959                0.819404\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  6.781965e-01     6               0.934959                0.819404\
1997          O  Acc                            ...  2.164568e-03     6               0.934959                0.819404\
1998          O  Acc                            ...  1.094057e-08     6               0.934959                0.819404\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     6               0.934959                0.819404\
2000          O  Acc                            ...  6.229627e-01     6               0.934959                0.819404\
\
[2001 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9024390243902439, 'O': 0.7425552353506244\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  7.489645e-01     5               0.902439                0.742555\
1     S-passive  Nom                    Kosten  ...  5.403197e-01     5               0.902439                0.742555\
2             O  Acc                            ...  1.200146e-02     5               0.902439                0.742555\
3             O  Nom                            ...  8.742399e-01     5               0.902439                0.742555\
4             O  Acc                            ...  1.221218e-02     5               0.902439                0.742555\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.992206e-01     5               0.902439                0.742555\
1997          O  Acc                            ...  1.235439e-05     5               0.902439                0.742555\
1998          O  Acc                            ...  3.270407e-07     5               0.902439                0.742555\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     5               0.902439                0.742555\
2000          O  Acc                            ...  4.264420e-03     5               0.902439                0.742555\
\
[2001 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.7300672430355427\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.001935     4               0.886179                0.730067\
1     S-passive  Nom                    Kosten  ...      0.000229     4               0.886179                0.730067\
2             O  Acc                            ...      0.000011     4               0.886179                0.730067\
3             O  Nom                            ...      0.192240     4               0.886179                0.730067\
4             O  Acc                            ...      0.008487     4               0.886179                0.730067\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999956     4               0.886179                0.730067\
1997          O  Acc                            ...      0.000234     4               0.886179                0.730067\
1998          O  Acc                            ...      0.000096     4               0.886179                0.730067\
1999          A  Nom                   Ibrahim  ...      1.000000     4               0.886179                0.730067\
2000          O  Acc                            ...      0.500000     4               0.886179                0.730067\
\
[2001 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8699186991869918, 'O': 0.7598463016330451\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.146923     3               0.869919                0.759846\
1     S-passive  Nom                    Kosten  ...      0.125754     3               0.869919                0.759846\
2             O  Acc                            ...      0.000253     3               0.869919                0.759846\
3             O  Nom                            ...      0.091370     3               0.869919                0.759846\
4             O  Acc                            ...      0.076978     3               0.869919                0.759846\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999854     3               0.869919                0.759846\
1997          O  Acc                            ...      0.116951     3               0.869919                0.759846\
1998          O  Acc                            ...      0.207028     3               0.869919                0.759846\
1999          A  Nom                   Ibrahim  ...      1.000000     3               0.869919                0.759846\
2000          O  Acc                            ...      0.265697     3               0.869919                0.759846\
\
[2001 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8536585365853658, 'O': 0.5524542829643888\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.806534     2               0.853659                0.552454\
1     S-passive  Nom                    Kosten  ...      0.175906     2               0.853659                0.552454\
2             O  Acc                            ...      0.007504     2               0.853659                0.552454\
3             O  Nom                            ...      0.009141     2               0.853659                0.552454\
4             O  Acc                            ...      0.996826     2               0.853659                0.552454\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999944     2               0.853659                0.552454\
1997          O  Acc                            ...      0.000077     2               0.853659                0.552454\
1998          O  Acc                            ...      0.994732     2               0.853659                0.552454\
1999          A  Nom                   Ibrahim  ...      1.000000     2               0.853659                0.552454\
2000          O  Acc                            ...      0.580504     2               0.853659                0.552454\
\
[2001 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.8373983739837398, 'O': 0.5620789220404235\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.859743     1               0.837398                0.562079\
1     S-passive  Nom                    Kosten  ...      0.887071     1               0.837398                0.562079\
2             O  Acc                            ...      0.198059     1               0.837398                0.562079\
3             O  Nom                            ...      0.208350     1               0.837398                0.562079\
4             O  Acc                            ...      0.894286     1               0.837398                0.562079\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.986558     1               0.837398                0.562079\
1997          O  Acc                            ...      0.000064     1               0.837398                0.562079\
1998          O  Acc                            ...      0.995880     1               0.837398                0.562079\
1999          A  Nom                   Ibrahim  ...      0.999964     1               0.837398                0.562079\
2000          O  Acc                            ...      0.298218     1               0.837398                0.562079\
\
[2001 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6422764227642277, 'O': 0.5851780558229066\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'A-aux': 3, 'A-passive': 4, 'O-aux': 5, 'S-expletive': 6, 'S-expletive-passive': 7, 'S-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.720999     0               0.642276                0.585178\
1     S-passive  Nom                    Kosten  ...      0.990932     0               0.642276                0.585178\
2             O  Acc                            ...      0.021134     0               0.642276                0.585178\
3             O  Nom                            ...      0.858929     0               0.642276                0.585178\
4             O  Acc                            ...      0.142459     0               0.642276                0.585178\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.998654     0               0.642276                0.585178\
1997          O  Acc                            ...      0.556712     0               0.642276                0.585178\
1998          O  Acc                            ...      0.124265     0               0.642276                0.585178\
1999          A  Nom                   Ibrahim  ...      0.999934     0               0.642276                0.585178\
2000          O  Acc                            ...      0.321394     0               0.642276                0.585178\
\
[2001 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/pt_cintil-ud_de_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2001 relevant tokens, and 2183 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2183/2183 [00:00<00:00, 3300.28it/s]\
Loaded 2182 sentences from disk.\
length of bert outputs 2183\
On layer 12\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9315403422982885, 'O': 0.8970099667774086\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.177055    12                0.93154                 0.89701\
1     S-passive  Nom                    Kosten  ...      1.000000    12                0.93154                 0.89701\
2             O  Acc                            ...      0.008062    12                0.93154                 0.89701\
3             O  Nom                            ...      0.541816    12                0.93154                 0.89701\
4             O  Acc                            ...      0.000006    12                0.93154                 0.89701\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000    12                0.93154                 0.89701\
1997          O  Acc                            ...      0.422242    12                0.93154                 0.89701\
1998          O  Acc                            ...      0.000218    12                0.93154                 0.89701\
1999          A  Nom                   Ibrahim  ...      1.000000    12                0.93154                 0.89701\
2000          O  Acc                            ...      0.999963    12                0.93154                 0.89701\
\
[2001 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9535452322738386, 'O': 0.9346622369878184\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.880510e-02    11               0.953545                0.934662\
1     S-passive  Nom                    Kosten  ...  9.999996e-01    11               0.953545                0.934662\
2             O  Acc                            ...  5.555964e-04    11               0.953545                0.934662\
3             O  Nom                            ...  3.746061e-03    11               0.953545                0.934662\
4             O  Acc                            ...  8.327518e-07    11               0.953545                0.934662\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999999e-01    11               0.953545                0.934662\
1997          O  Acc                            ...  1.742378e-06    11               0.953545                0.934662\
1998          O  Acc                            ...  1.090753e-07    11               0.953545                0.934662\
1999          A  Nom                   Ibrahim  ...  1.000000e+00    11               0.953545                0.934662\
2000          O  Acc                            ...  9.915979e-01    11               0.953545                0.934662\
\
[2001 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9633251833740831, 'O': 0.9446290143964563\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  1.405602e-04    10               0.963325                0.944629\
1     S-passive  Nom                    Kosten  ...  9.999998e-01    10               0.963325                0.944629\
2             O  Acc                            ...  5.584720e-10    10               0.963325                0.944629\
3             O  Nom                            ...  2.927048e-02    10               0.963325                0.944629\
4             O  Acc                            ...  1.523066e-05    10               0.963325                0.944629\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00    10               0.963325                0.944629\
1997          O  Acc                            ...  8.301843e-04    10               0.963325                0.944629\
1998          O  Acc                            ...  1.550745e-08    10               0.963325                0.944629\
1999          A  Nom                   Ibrahim  ...  1.000000e+00    10               0.963325                0.944629\
2000          O  Acc                            ...  1.951664e-02    10               0.963325                0.944629\
\
[2001 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.960880195599022, 'O': 0.9501661129568106\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.840843e-04     9                0.96088                0.950166\
1     S-passive  Nom                    Kosten  ...  9.999999e-01     9                0.96088                0.950166\
2             O  Acc                            ...  4.264625e-10     9                0.96088                0.950166\
3             O  Nom                            ...  9.620329e-01     9                0.96088                0.950166\
4             O  Acc                            ...  1.202832e-06     9                0.96088                0.950166\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     9                0.96088                0.950166\
1997          O  Acc                            ...  2.729046e-07     9                0.96088                0.950166\
1998          O  Acc                            ...  1.567929e-05     9                0.96088                0.950166\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     9                0.96088                0.950166\
2000          O  Acc                            ...  2.251175e-03     9                0.96088                0.950166\
\
[2001 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.964562569213732\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  7.483966e-06     8                0.95599                0.964563\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     8                0.95599                0.964563\
2             O  Acc                            ...  3.418344e-08     8                0.95599                0.964563\
3             O  Nom                            ...  9.997124e-01     8                0.95599                0.964563\
4             O  Acc                            ...  2.776472e-06     8                0.95599                0.964563\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     8                0.95599                0.964563\
1997          O  Acc                            ...  8.456852e-08     8                0.95599                0.964563\
1998          O  Acc                            ...  2.507023e-11     8                0.95599                0.964563\
1999          A  Nom                   Ibrahim  ...  9.999881e-01     8                0.95599                0.964563\
2000          O  Acc                            ...  3.453804e-05     8                0.95599                0.964563\
\
[2001 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.9512735326688815\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  6.455003e-02     7                0.95599                0.951274\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     7                0.95599                0.951274\
2             O  Acc                            ...  3.448626e-08     7                0.95599                0.951274\
3             O  Nom                            ...  9.999807e-01     7                0.95599                0.951274\
4             O  Acc                            ...  2.202273e-06     7                0.95599                0.951274\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     7                0.95599                0.951274\
1997          O  Acc                            ...  3.001592e-06     7                0.95599                0.951274\
1998          O  Acc                            ...  1.783487e-09     7                0.95599                0.951274\
1999          A  Nom                   Ibrahim  ...  9.999956e-01     7                0.95599                0.951274\
2000          O  Acc                            ...  2.926724e-06     7                0.95599                0.951274\
\
[2001 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9437652811735942, 'O': 0.9678848283499446\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  8.234619e-02     6               0.943765                0.967885\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     6               0.943765                0.967885\
2             O  Acc                            ...  8.008419e-04     6               0.943765                0.967885\
3             O  Nom                            ...  9.976120e-01     6               0.943765                0.967885\
4             O  Acc                            ...  2.059770e-04     6               0.943765                0.967885\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     6               0.943765                0.967885\
1997          O  Acc                            ...  2.829414e-07     6               0.943765                0.967885\
1998          O  Acc                            ...  1.898046e-08     6               0.943765                0.967885\
1999          A  Nom                   Ibrahim  ...  9.999864e-01     6               0.943765                0.967885\
2000          O  Acc                            ...  4.677054e-03     6               0.943765                0.967885\
\
[2001 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9388753056234719, 'O': 0.9335548172757475\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  8.806723e-01     5               0.938875                0.933555\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     5               0.938875                0.933555\
2             O  Acc                            ...  6.877056e-07     5               0.938875                0.933555\
3             O  Nom                            ...  9.999636e-01     5               0.938875                0.933555\
4             O  Acc                            ...  2.280432e-01     5               0.938875                0.933555\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999985e-01     5               0.938875                0.933555\
1997          O  Acc                            ...  1.862750e-06     5               0.938875                0.933555\
1998          O  Acc                            ...  4.464227e-05     5               0.938875                0.933555\
1999          A  Nom                   Ibrahim  ...  9.999754e-01     5               0.938875                0.933555\
2000          O  Acc                            ...  1.788610e-01     5               0.938875                0.933555\
\
[2001 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9070904645476773, 'O': 0.9080841638981174\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  5.649261e-02     4                0.90709                0.908084\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     4                0.90709                0.908084\
2             O  Acc                            ...  7.693248e-05     4                0.90709                0.908084\
3             O  Nom                            ...  9.606426e-01     4                0.90709                0.908084\
4             O  Acc                            ...  3.118018e-04     4                0.90709                0.908084\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999943e-01     4                0.90709                0.908084\
1997          O  Acc                            ...  1.322367e-07     4                0.90709                0.908084\
1998          O  Acc                            ...  5.039179e-05     4                0.90709                0.908084\
1999          A  Nom                   Ibrahim  ...  9.999970e-01     4                0.90709                0.908084\
2000          O  Acc                            ...  5.000000e-01     4                0.90709                0.908084\
\
[2001 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8997555012224939, 'O': 0.9136212624584718\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.000086     3               0.899756                0.913621\
1     S-passive  Nom                    Kosten  ...      1.000000     3               0.899756                0.913621\
2             O  Acc                            ...      0.001818     3               0.899756                0.913621\
3             O  Nom                            ...      0.999924     3               0.899756                0.913621\
4             O  Acc                            ...      0.000056     3               0.899756                0.913621\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999999     3               0.899756                0.913621\
1997          O  Acc                            ...      0.001882     3               0.899756                0.913621\
1998          O  Acc                            ...      0.011350     3               0.899756                0.913621\
1999          A  Nom                   Ibrahim  ...      0.999987     3               0.899756                0.913621\
2000          O  Acc                            ...      0.968626     3               0.899756                0.913621\
\
[2001 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7652811735941321, 'O': 0.858250276854928\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.519006     2               0.765281                 0.85825\
1     S-passive  Nom                    Kosten  ...      0.999997     2               0.765281                 0.85825\
2             O  Acc                            ...      0.018680     2               0.765281                 0.85825\
3             O  Nom                            ...      1.000000     2               0.765281                 0.85825\
4             O  Acc                            ...      0.000321     2               0.765281                 0.85825\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999998     2               0.765281                 0.85825\
1997          O  Acc                            ...      0.000041     2               0.765281                 0.85825\
1998          O  Acc                            ...      0.825364     2               0.765281                 0.85825\
1999          A  Nom                   Ibrahim  ...      1.000000     2               0.765281                 0.85825\
2000          O  Acc                            ...      0.996706     2               0.765281                 0.85825\
\
[2001 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7555012224938875, 'O': 0.8217054263565892\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.783222     1               0.755501                0.821705\
1     S-passive  Nom                    Kosten  ...      1.000000     1               0.755501                0.821705\
2             O  Acc                            ...      0.417571     1               0.755501                0.821705\
3             O  Nom                            ...      0.999957     1               0.755501                0.821705\
4             O  Acc                            ...      0.169696     1               0.755501                0.821705\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999901     1               0.755501                0.821705\
1997          O  Acc                            ...      0.000024     1               0.755501                0.821705\
1998          O  Acc                            ...      0.901408     1               0.755501                0.821705\
1999          A  Nom                   Ibrahim  ...      0.999874     1               0.755501                0.821705\
2000          O  Acc                            ...      0.735079     1               0.755501                0.821705\
\
[2001 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6968215158924206, 'O': 0.8073089700996677\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'A-aux': 4, 'A-passive': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.998853     0               0.696822                0.807309\
1     S-passive  Nom                    Kosten  ...      1.000000     0               0.696822                0.807309\
2             O  Acc                            ...      0.140312     0               0.696822                0.807309\
3             O  Nom                            ...      0.999999     0               0.696822                0.807309\
4             O  Acc                            ...      0.081413     0               0.696822                0.807309\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     0               0.696822                0.807309\
1997          O  Acc                            ...      0.225025     0               0.696822                0.807309\
1998          O  Acc                            ...      0.990408     0               0.696822                0.807309\
1999          A  Nom                   Ibrahim  ...      0.999999     0               0.696822                0.807309\
2000          O  Acc                            ...      0.925192     0               0.696822                0.807309\
\
[2001 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_de_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2001 relevant tokens, and 2183 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2183/2183 [00:00<00:00, 3923.82it/s]\
Loaded 2182 sentences from disk.\
length of bert outputs 2183\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.990676    12               0.960976                 0.85929\
1     S-passive  Nom                    Kosten  ...      0.999877    12               0.960976                 0.85929\
2             O  Acc                            ...      0.000144    12               0.960976                 0.85929\
3             O  Nom                            ...      0.994134    12               0.960976                 0.85929\
4             O  Acc                            ...      0.014695    12               0.960976                 0.85929\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999997    12               0.960976                 0.85929\
1997          O  Acc                            ...      0.001769    12               0.960976                 0.85929\
1998          O  Acc                            ...      0.703850    12               0.960976                 0.85929\
1999          A  Nom                   Ibrahim  ...      1.000000    12               0.960976                 0.85929\
2000          O  Acc                            ...      0.999736    12               0.960976                 0.85929\
\
[2001 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  7.251579e-02    11               0.980488                0.912568\
1     S-passive  Nom                    Kosten  ...  9.999588e-01    11               0.980488                0.912568\
2             O  Acc                            ...  2.282880e-03    11               0.980488                0.912568\
3             O  Nom                            ...  7.169740e-01    11               0.980488                0.912568\
4             O  Acc                            ...  2.136447e-03    11               0.980488                0.912568\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.993081e-01    11               0.980488                0.912568\
1997          O  Acc                            ...  4.902392e-08    11               0.980488                0.912568\
1998          O  Acc                            ...  6.936772e-03    11               0.980488                0.912568\
1999          A  Nom                   Ibrahim  ...  1.000000e+00    11               0.980488                0.912568\
2000          O  Acc                            ...  9.659882e-01    11               0.980488                0.912568\
\
[2001 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.763736e-04    10                0.97561                0.904372\
1     S-passive  Nom                    Kosten  ...  9.999917e-01    10                0.97561                0.904372\
2             O  Acc                            ...  1.404878e-07    10                0.97561                0.904372\
3             O  Nom                            ...  9.648247e-01    10                0.97561                0.904372\
4             O  Acc                            ...  1.427099e-03    10                0.97561                0.904372\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999995e-01    10                0.97561                0.904372\
1997          O  Acc                            ...  2.848999e-04    10                0.97561                0.904372\
1998          O  Acc                            ...  2.806872e-04    10                0.97561                0.904372\
1999          A  Nom                   Ibrahim  ...  1.000000e+00    10                0.97561                0.904372\
2000          O  Acc                            ...  1.067211e-02    10                0.97561                0.904372\
\
[2001 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.692277e-04     9               0.980488                0.924863\
1     S-passive  Nom                    Kosten  ...  9.999915e-01     9               0.980488                0.924863\
2             O  Acc                            ...  1.260809e-09     9               0.980488                0.924863\
3             O  Nom                            ...  9.840372e-01     9               0.980488                0.924863\
4             O  Acc                            ...  1.116834e-04     9               0.980488                0.924863\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999999e-01     9               0.980488                0.924863\
1997          O  Acc                            ...  1.175710e-08     9               0.980488                0.924863\
1998          O  Acc                            ...  7.267863e-02     9               0.980488                0.924863\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     9               0.980488                0.924863\
2000          O  Acc                            ...  1.937613e-03     9               0.980488                0.924863\
\
[2001 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  6.002041e-06     8               0.985366                0.941257\
1     S-passive  Nom                    Kosten  ...  9.999975e-01     8               0.985366                0.941257\
2             O  Acc                            ...  1.559565e-10     8               0.985366                0.941257\
3             O  Nom                            ...  9.999975e-01     8               0.985366                0.941257\
4             O  Acc                            ...  2.905500e-05     8               0.985366                0.941257\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999977e-01     8               0.985366                0.941257\
1997          O  Acc                            ...  1.104189e-08     8               0.985366                0.941257\
1998          O  Acc                            ...  5.135760e-04     8               0.985366                0.941257\
1999          A  Nom                   Ibrahim  ...  9.999841e-01     8               0.985366                0.941257\
2000          O  Acc                            ...  9.819832e-07     8               0.985366                0.941257\
\
[2001 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  3.198840e-02     7               0.980488                0.939891\
1     S-passive  Nom                    Kosten  ...  9.999989e-01     7               0.980488                0.939891\
2             O  Acc                            ...  6.558083e-09     7               0.980488                0.939891\
3             O  Nom                            ...  9.999990e-01     7               0.980488                0.939891\
4             O  Acc                            ...  1.195305e-06     7               0.980488                0.939891\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999969e-01     7               0.980488                0.939891\
1997          O  Acc                            ...  2.021998e-08     7               0.980488                0.939891\
1998          O  Acc                            ...  8.277693e-02     7               0.980488                0.939891\
1999          A  Nom                   Ibrahim  ...  9.998196e-01     7               0.980488                0.939891\
2000          O  Acc                            ...  2.829926e-08     7               0.980488                0.939891\
\
[2001 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.404471e-01     6                0.97561                0.927596\
1     S-passive  Nom                    Kosten  ...  9.997003e-01     6                0.97561                0.927596\
2             O  Acc                            ...  2.637891e-04     6                0.97561                0.927596\
3             O  Nom                            ...  9.987893e-01     6                0.97561                0.927596\
4             O  Acc                            ...  3.283534e-06     6                0.97561                0.927596\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999918e-01     6                0.97561                0.927596\
1997          O  Acc                            ...  1.933629e-08     6                0.97561                0.927596\
1998          O  Acc                            ...  3.302683e-03     6                0.97561                0.927596\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     6                0.97561                0.927596\
2000          O  Acc                            ...  8.634429e-03     6                0.97561                0.927596\
\
[2001 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.738838e-01     5               0.970732                0.901639\
1     S-passive  Nom                    Kosten  ...  9.942271e-01     5               0.970732                0.901639\
2             O  Acc                            ...  2.849268e-02     5               0.970732                0.901639\
3             O  Nom                            ...  9.996161e-01     5               0.970732                0.901639\
4             O  Acc                            ...  9.647119e-03     5               0.970732                0.901639\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.996376e-01     5               0.970732                0.901639\
1997          O  Acc                            ...  1.850612e-08     5               0.970732                0.901639\
1998          O  Acc                            ...  1.911740e-01     5               0.970732                0.901639\
1999          A  Nom                   Ibrahim  ...  9.999989e-01     5               0.970732                0.901639\
2000          O  Acc                            ...  2.181701e-04     5               0.970732                0.901639\
\
[2001 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  3.106561e-04     4               0.912195                0.826503\
1     S-passive  Nom                    Kosten  ...  9.951273e-01     4               0.912195                0.826503\
2             O  Acc                            ...  9.672907e-05     4               0.912195                0.826503\
3             O  Nom                            ...  9.813997e-01     4               0.912195                0.826503\
4             O  Acc                            ...  5.354226e-09     4               0.912195                0.826503\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.994147e-01     4               0.912195                0.826503\
1997          O  Acc                            ...  1.046245e-09     4               0.912195                0.826503\
1998          O  Acc                            ...  1.539564e-01     4               0.912195                0.826503\
1999          A  Nom                   Ibrahim  ...  9.999963e-01     4               0.912195                0.826503\
2000          O  Acc                            ...  5.000000e-01     4               0.912195                0.826503\
\
[2001 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.254129e-04     3               0.936585                0.815574\
1     S-passive  Nom                    Kosten  ...  9.513825e-01     3               0.936585                0.815574\
2             O  Acc                            ...  2.418166e-04     3               0.936585                0.815574\
3             O  Nom                            ...  9.999588e-01     3               0.936585                0.815574\
4             O  Acc                            ...  1.248093e-07     3               0.936585                0.815574\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999973e-01     3               0.936585                0.815574\
1997          O  Acc                            ...  3.779658e-04     3               0.936585                0.815574\
1998          O  Acc                            ...  3.234249e-02     3               0.936585                0.815574\
1999          A  Nom                   Ibrahim  ...  9.999948e-01     3               0.936585                0.815574\
2000          O  Acc                            ...  1.441329e-03     3               0.936585                0.815574\
\
[2001 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.941324     2               0.858537                0.717213\
1     S-passive  Nom                    Kosten  ...      0.961717     2               0.858537                0.717213\
2             O  Acc                            ...      0.149731     2               0.858537                0.717213\
3             O  Nom                            ...      1.000000     2               0.858537                0.717213\
4             O  Acc                            ...      0.000552     2               0.858537                0.717213\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     2               0.858537                0.717213\
1997          O  Acc                            ...      0.009709     2               0.858537                0.717213\
1998          O  Acc                            ...      0.979193     2               0.858537                0.717213\
1999          A  Nom                   Ibrahim  ...      0.999996     2               0.858537                0.717213\
2000          O  Acc                            ...      0.992542     2               0.858537                0.717213\
\
[2001 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.376105     1               0.780488                0.709016\
1     S-passive  Nom                    Kosten  ...      0.995363     1               0.780488                0.709016\
2             O  Acc                            ...      0.955168     1               0.780488                0.709016\
3             O  Nom                            ...      0.999581     1               0.780488                0.709016\
4             O  Acc                            ...      0.016308     1               0.780488                0.709016\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999400     1               0.780488                0.709016\
1997          O  Acc                            ...      0.008167     1               0.780488                0.709016\
1998          O  Acc                            ...      0.938468     1               0.780488                0.709016\
1999          A  Nom                   Ibrahim  ...      0.999671     1               0.780488                0.709016\
2000          O  Acc                            ...      0.081580     1               0.780488                0.709016\
\
[2001 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6, 'A-aux': 7, 'O-aux': 8, 'S-expletive-passive': 9, 'S-passive-aux': 10\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999884     0               0.790244                0.665301\
1     S-passive  Nom                    Kosten  ...      1.000000     0               0.790244                0.665301\
2             O  Acc                            ...      0.990767     0               0.790244                0.665301\
3             O  Nom                            ...      1.000000     0               0.790244                0.665301\
4             O  Acc                            ...      0.194975     0               0.790244                0.665301\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     0               0.790244                0.665301\
1997          O  Acc                            ...      0.855886     0               0.790244                0.665301\
1998          O  Acc                            ...      0.820404     0               0.790244                0.665301\
1999          A  Nom                   Ibrahim  ...      1.000000     0               0.790244                0.665301\
2000          O  Acc                            ...      0.205513     0               0.790244                0.665301\
\
[2001 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_de_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2001 relevant tokens, and 2183 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2183/2183 [00:00<00:00, 3991.72it/s]\
Loaded 2182 sentences from disk.\
length of bert outputs 2183\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.099055    12               0.958763                0.929329\
1     S-passive  Nom                    Kosten  ...      1.000000    12               0.958763                0.929329\
2             O  Acc                            ...      0.002609    12               0.958763                0.929329\
3             O  Nom                            ...      0.377374    12               0.958763                0.929329\
4             O  Acc                            ...      0.000031    12               0.958763                0.929329\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000    12               0.958763                0.929329\
1997          O  Acc                            ...      0.722065    12               0.958763                0.929329\
1998          O  Acc                            ...      0.005313    12               0.958763                0.929329\
1999          A  Nom                   Ibrahim  ...      1.000000    12               0.958763                0.929329\
2000          O  Acc                            ...      0.011716    12               0.958763                0.929329\
\
[2001 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  9.603763e-03    11               0.958763                0.975265\
1     S-passive  Nom                    Kosten  ...  1.000000e+00    11               0.958763                0.975265\
2             O  Acc                            ...  6.762233e-03    11               0.958763                0.975265\
3             O  Nom                            ...  1.164048e-01    11               0.958763                0.975265\
4             O  Acc                            ...  4.976599e-07    11               0.958763                0.975265\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999998e-01    11               0.958763                0.975265\
1997          O  Acc                            ...  5.122926e-08    11               0.958763                0.975265\
1998          O  Acc                            ...  7.005760e-09    11               0.958763                0.975265\
1999          A  Nom                   Ibrahim  ...  9.999996e-01    11               0.958763                0.975265\
2000          O  Acc                            ...  5.383401e-03    11               0.958763                0.975265\
\
[2001 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  1.598875e-06    10               0.958763                0.961131\
1     S-passive  Nom                    Kosten  ...  9.999900e-01    10               0.958763                0.961131\
2             O  Acc                            ...  1.640140e-06    10               0.958763                0.961131\
3             O  Nom                            ...  5.564588e-01    10               0.958763                0.961131\
4             O  Acc                            ...  1.774295e-06    10               0.958763                0.961131\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999995e-01    10               0.958763                0.961131\
1997          O  Acc                            ...  5.407682e-04    10               0.958763                0.961131\
1998          O  Acc                            ...  1.304038e-10    10               0.958763                0.961131\
1999          A  Nom                   Ibrahim  ...  9.999994e-01    10               0.958763                0.961131\
2000          O  Acc                            ...  2.653521e-06    10               0.958763                0.961131\
\
[2001 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  1.622851e-06     9               0.958763                0.971731\
1     S-passive  Nom                    Kosten  ...  9.999940e-01     9               0.958763                0.971731\
2             O  Acc                            ...  6.893687e-09     9               0.958763                0.971731\
3             O  Nom                            ...  3.144995e-01     9               0.958763                0.971731\
4             O  Acc                            ...  1.592348e-08     9               0.958763                0.971731\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999483e-01     9               0.958763                0.971731\
1997          O  Acc                            ...  3.022054e-10     9               0.958763                0.971731\
1998          O  Acc                            ...  1.185476e-05     9               0.958763                0.971731\
1999          A  Nom                   Ibrahim  ...  9.999998e-01     9               0.958763                0.971731\
2000          O  Acc                            ...  1.229273e-07     9               0.958763                0.971731\
\
[2001 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.264405e-05     8               0.958763                0.961131\
1     S-passive  Nom                    Kosten  ...  9.999926e-01     8               0.958763                0.961131\
2             O  Acc                            ...  1.087208e-07     8               0.958763                0.961131\
3             O  Nom                            ...  9.992234e-01     8               0.958763                0.961131\
4             O  Acc                            ...  3.966398e-09     8               0.958763                0.961131\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999884e-01     8               0.958763                0.961131\
1997          O  Acc                            ...  7.631810e-09     8               0.958763                0.961131\
1998          O  Acc                            ...  6.962400e-09     8               0.958763                0.961131\
1999          A  Nom                   Ibrahim  ...  9.994423e-01     8               0.958763                0.961131\
2000          O  Acc                            ...  1.012688e-07     8               0.958763                0.961131\
\
[2001 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.351504e-02     7               0.958763                0.971731\
1     S-passive  Nom                    Kosten  ...  9.999998e-01     7               0.958763                0.971731\
2             O  Acc                            ...  6.844649e-05     7               0.958763                0.971731\
3             O  Nom                            ...  9.999480e-01     7               0.958763                0.971731\
4             O  Acc                            ...  1.424574e-10     7               0.958763                0.971731\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     7               0.958763                0.971731\
1997          O  Acc                            ...  1.177429e-06     7               0.958763                0.971731\
1998          O  Acc                            ...  2.094028e-08     7               0.958763                0.971731\
1999          A  Nom                   Ibrahim  ...  9.994366e-01     7               0.958763                0.971731\
2000          O  Acc                            ...  2.867814e-09     7               0.958763                0.971731\
\
[2001 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.272620e-01     6               0.938144                0.968198\
1     S-passive  Nom                    Kosten  ...  9.999993e-01     6               0.938144                0.968198\
2             O  Acc                            ...  9.086462e-01     6               0.938144                0.968198\
3             O  Nom                            ...  9.921241e-01     6               0.938144                0.968198\
4             O  Acc                            ...  3.443105e-07     6               0.938144                0.968198\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     6               0.938144                0.968198\
1997          O  Acc                            ...  1.587565e-03     6               0.938144                0.968198\
1998          O  Acc                            ...  2.314182e-06     6               0.938144                0.968198\
1999          A  Nom                   Ibrahim  ...  9.999747e-01     6               0.938144                0.968198\
2000          O  Acc                            ...  2.889737e-04     6               0.938144                0.968198\
\
[2001 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.996626     5               0.969072                0.943463\
1     S-passive  Nom                    Kosten  ...      1.000000     5               0.969072                0.943463\
2             O  Acc                            ...      0.013294     5               0.969072                0.943463\
3             O  Nom                            ...      0.999607     5               0.969072                0.943463\
4             O  Acc                            ...      0.016703     5               0.969072                0.943463\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     5               0.969072                0.943463\
1997          O  Acc                            ...      0.000099     5               0.969072                0.943463\
1998          O  Acc                            ...      0.003506     5               0.969072                0.943463\
1999          A  Nom                   Ibrahim  ...      0.932528     5               0.969072                0.943463\
2000          O  Acc                            ...      0.000002     5               0.969072                0.943463\
\
[2001 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  9.307866e-01     4               0.917526                0.946996\
1     S-passive  Nom                    Kosten  ...  1.000000e+00     4               0.917526                0.946996\
2             O  Acc                            ...  1.617955e-02     4               0.917526                0.946996\
3             O  Nom                            ...  9.080077e-01     4               0.917526                0.946996\
4             O  Acc                            ...  3.594197e-07     4               0.917526                0.946996\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  1.000000e+00     4               0.917526                0.946996\
1997          O  Acc                            ...  2.436480e-05     4               0.917526                0.946996\
1998          O  Acc                            ...  1.334293e-03     4               0.917526                0.946996\
1999          A  Nom                   Ibrahim  ...  9.978347e-01     4               0.917526                0.946996\
2000          O  Acc                            ...  5.000000e-01     4               0.917526                0.946996\
\
[2001 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999149     3               0.938144                0.936396\
1     S-passive  Nom                    Kosten  ...      1.000000     3               0.938144                0.936396\
2             O  Acc                            ...      0.065288     3               0.938144                0.936396\
3             O  Nom                            ...      0.878514     3               0.938144                0.936396\
4             O  Acc                            ...      0.000033     3               0.938144                0.936396\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     3               0.938144                0.936396\
1997          O  Acc                            ...      0.048421     3               0.938144                0.936396\
1998          O  Acc                            ...      0.090808     3               0.938144                0.936396\
1999          A  Nom                   Ibrahim  ...      0.999991     3               0.938144                0.936396\
2000          O  Acc                            ...      0.009804     3               0.938144                0.936396\
\
[2001 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999684     2               0.783505                0.795053\
1     S-passive  Nom                    Kosten  ...      0.999950     2               0.783505                0.795053\
2             O  Acc                            ...      0.181351     2               0.783505                0.795053\
3             O  Nom                            ...      1.000000     2               0.783505                0.795053\
4             O  Acc                            ...      0.552308     2               0.783505                0.795053\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     2               0.783505                0.795053\
1997          O  Acc                            ...      0.219959     2               0.783505                0.795053\
1998          O  Acc                            ...      0.965441     2               0.783505                0.795053\
1999          A  Nom                   Ibrahim  ...      0.999999     2               0.783505                0.795053\
2000          O  Acc                            ...      0.998853     2               0.783505                0.795053\
\
[2001 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999966     1               0.793814                0.773852\
1     S-passive  Nom                    Kosten  ...      0.999983     1               0.793814                0.773852\
2             O  Acc                            ...      0.350789     1               0.793814                0.773852\
3             O  Nom                            ...      0.999504     1               0.793814                0.773852\
4             O  Acc                            ...      0.579194     1               0.793814                0.773852\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999998     1               0.793814                0.773852\
1997          O  Acc                            ...      0.708507     1               0.793814                0.773852\
1998          O  Acc                            ...      0.981598     1               0.793814                0.773852\
1999          A  Nom                   Ibrahim  ...      0.997106     1               0.793814                0.773852\
2000          O  Acc                            ...      0.047572     1               0.793814                0.773852\
\
[2001 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999924     0               0.721649                0.816254\
1     S-passive  Nom                    Kosten  ...      1.000000     0               0.721649                0.816254\
2             O  Acc                            ...      0.990750     0               0.721649                0.816254\
3             O  Nom                            ...      0.999999     0               0.721649                0.816254\
4             O  Acc                            ...      0.483516     0               0.721649                0.816254\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     0               0.721649                0.816254\
1997          O  Acc                            ...      0.828500     0               0.721649                0.816254\
1998          O  Acc                            ...      0.985086     0               0.721649                0.816254\
1999          A  Nom                   Ibrahim  ...      1.000000     0               0.721649                0.816254\
2000          O  Acc                            ...      0.965475     0               0.721649                0.816254\
\
[2001 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_de_gsd-ud-test.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-test.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-test_aso_unbalanced_2000.pkl\
There are 1092 relevant tokens, and 977 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-test_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 977/977 [00:00<00:00, 3036.40it/s]\
Loaded 976 sentences from disk.\
length of bert outputs 977\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...      0.000010    12                0.84556                0.873118\
1       O  Acc                              ...      0.293457    12                0.84556                0.873118\
2       O  Acc                              ...      0.002850    12                0.84556                0.873118\
3       O  Nom                              ...      0.000015    12                0.84556                0.873118\
4       A  Nom                     Kollege  ...      0.999703    12                0.84556                0.873118\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...      0.292313    12                0.84556                0.873118\
1088    A  Nom          Sicherheitsagenten  ...      0.470315    12                0.84556                0.873118\
1089    O  Acc                              ...      0.000241    12                0.84556                0.873118\
1090    S  Nom                   Pr\'e4sident  ...      0.999999    12                0.84556                0.873118\
1091    O  Acc                              ...      0.000010    12                0.84556                0.873118\
\
[1092 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  1.185149e-03    11               0.880309                0.896774\
1       O  Acc                              ...  5.090745e-05    11               0.880309                0.896774\
2       O  Acc                              ...  6.983908e-06    11               0.880309                0.896774\
3       O  Nom                              ...  3.774154e-03    11               0.880309                0.896774\
4       A  Nom                     Kollege  ...  9.999862e-01    11               0.880309                0.896774\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  1.452903e-01    11               0.880309                0.896774\
1088    A  Nom          Sicherheitsagenten  ...  5.713497e-01    11               0.880309                0.896774\
1089    O  Acc                              ...  6.850004e-07    11               0.880309                0.896774\
1090    S  Nom                   Pr\'e4sident  ...  9.988870e-01    11               0.880309                0.896774\
1091    O  Acc                              ...  1.755453e-04    11               0.880309                0.896774\
\
[1092 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  3.089168e-10    10               0.915058                0.922581\
1       O  Acc                              ...  5.897126e-03    10               0.915058                0.922581\
2       O  Acc                              ...  1.705952e-06    10               0.915058                0.922581\
3       O  Nom                              ...  5.564024e-04    10               0.915058                0.922581\
4       A  Nom                     Kollege  ...  9.972097e-01    10               0.915058                0.922581\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  8.043598e-02    10               0.915058                0.922581\
1088    A  Nom          Sicherheitsagenten  ...  9.968359e-01    10               0.915058                0.922581\
1089    O  Acc                              ...  1.086712e-06    10               0.915058                0.922581\
1090    S  Nom                   Pr\'e4sident  ...  9.999999e-01    10               0.915058                0.922581\
1091    O  Acc                              ...  3.917277e-05    10               0.915058                0.922581\
\
[1092 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  6.656147e-10     9               0.903475                0.909677\
1       O  Acc                              ...  7.600514e-07     9               0.903475                0.909677\
2       O  Acc                              ...  3.713612e-02     9               0.903475                0.909677\
3       O  Nom                              ...  9.555896e-11     9               0.903475                0.909677\
4       A  Nom                     Kollege  ...  9.999999e-01     9               0.903475                0.909677\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  7.958976e-04     9               0.903475                0.909677\
1088    A  Nom          Sicherheitsagenten  ...  9.972786e-01     9               0.903475                0.909677\
1089    O  Acc                              ...  1.047199e-09     9               0.903475                0.909677\
1090    S  Nom                   Pr\'e4sident  ...  1.000000e+00     9               0.903475                0.909677\
1091    O  Acc                              ...  2.535480e-02     9               0.903475                0.909677\
\
[1092 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  3.564120e-09     8               0.891892                0.913978\
1       O  Acc                              ...  5.536668e-07     8               0.891892                0.913978\
2       O  Acc                              ...  3.478799e-03     8               0.891892                0.913978\
3       O  Nom                              ...  2.691403e-06     8               0.891892                0.913978\
4       A  Nom                     Kollege  ...  9.999292e-01     8               0.891892                0.913978\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  2.446383e-03     8               0.891892                0.913978\
1088    A  Nom          Sicherheitsagenten  ...  9.999002e-01     8               0.891892                0.913978\
1089    O  Acc                              ...  9.426907e-08     8               0.891892                0.913978\
1090    S  Nom                   Pr\'e4sident  ...  1.000000e+00     8               0.891892                0.913978\
1091    O  Acc                              ...  3.845231e-03     8               0.891892                0.913978\
\
[1092 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  1.988313e-07     7               0.911197                0.892473\
1       O  Acc                              ...  6.996368e-06     7               0.911197                0.892473\
2       O  Acc                              ...  1.617901e-06     7               0.911197                0.892473\
3       O  Nom                              ...  1.356628e-05     7               0.911197                0.892473\
4       A  Nom                     Kollege  ...  9.971855e-01     7               0.911197                0.892473\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  2.164128e-04     7               0.911197                0.892473\
1088    A  Nom          Sicherheitsagenten  ...  9.035406e-01     7               0.911197                0.892473\
1089    O  Acc                              ...  5.218952e-04     7               0.911197                0.892473\
1090    S  Nom                   Pr\'e4sident  ...  1.000000e+00     7               0.911197                0.892473\
1091    O  Acc                              ...  8.571657e-04     7               0.911197                0.892473\
\
[1092 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  3.328637e-05     6               0.888031                0.890323\
1       O  Acc                              ...  4.528225e-05     6               0.888031                0.890323\
2       O  Acc                              ...  3.024588e-04     6               0.888031                0.890323\
3       O  Nom                              ...  2.141725e-06     6               0.888031                0.890323\
4       A  Nom                     Kollege  ...  9.881869e-01     6               0.888031                0.890323\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  1.440440e-05     6               0.888031                0.890323\
1088    A  Nom          Sicherheitsagenten  ...  3.764434e-01     6               0.888031                0.890323\
1089    O  Acc                              ...  7.389011e-07     6               0.888031                0.890323\
1090    S  Nom                   Pr\'e4sident  ...  1.000000e+00     6               0.888031                0.890323\
1091    O  Acc                              ...  1.317431e-05     6               0.888031                0.890323\
\
[1092 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  1.043272e-02     5               0.803089                 0.84086\
1       O  Acc                              ...  6.931847e-08     5               0.803089                 0.84086\
2       O  Acc                              ...  1.635637e-01     5               0.803089                 0.84086\
3       O  Nom                              ...  4.336518e-04     5               0.803089                 0.84086\
4       A  Nom                     Kollege  ...  9.822299e-01     5               0.803089                 0.84086\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  1.271870e-04     5               0.803089                 0.84086\
1088    A  Nom          Sicherheitsagenten  ...  1.245307e-01     5               0.803089                 0.84086\
1089    O  Acc                              ...  7.781892e-08     5               0.803089                 0.84086\
1090    S  Nom                   Pr\'e4sident  ...  1.000000e+00     5               0.803089                 0.84086\
1091    O  Acc                              ...  4.066312e-05     5               0.803089                 0.84086\
\
[1092 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...      0.060235     4               0.826255                0.756989\
1       O  Acc                              ...      0.000481     4               0.826255                0.756989\
2       O  Acc                              ...      0.007630     4               0.826255                0.756989\
3       O  Nom                              ...      0.000005     4               0.826255                0.756989\
4       A  Nom                     Kollege  ...      0.697107     4               0.826255                0.756989\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...      0.297550     4               0.826255                0.756989\
1088    A  Nom          Sicherheitsagenten  ...      0.621499     4               0.826255                0.756989\
1089    O  Acc                              ...      0.000980     4               0.826255                0.756989\
1090    S  Nom                   Pr\'e4sident  ...      1.000000     4               0.826255                0.756989\
1091    O  Acc                              ...      0.164549     4               0.826255                0.756989\
\
[1092 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...  1.058782e-01     3                0.80695                0.787097\
1       O  Acc                              ...  2.447560e-08     3                0.80695                0.787097\
2       O  Acc                              ...  1.635174e-01     3                0.80695                0.787097\
3       O  Nom                              ...  4.762182e-04     3                0.80695                0.787097\
4       A  Nom                     Kollege  ...  9.853453e-01     3                0.80695                0.787097\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...  8.307370e-02     3                0.80695                0.787097\
1088    A  Nom          Sicherheitsagenten  ...  1.065840e-01     3                0.80695                0.787097\
1089    O  Acc                              ...  2.233411e-06     3                0.80695                0.787097\
1090    S  Nom                   Pr\'e4sident  ...  9.999970e-01     3                0.80695                0.787097\
1091    O  Acc                              ...  1.419672e-02     3                0.80695                0.787097\
\
[1092 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...      0.101054     2               0.722008                0.825806\
1       O  Acc                              ...      0.002085     2               0.722008                0.825806\
2       O  Acc                              ...      0.001811     2               0.722008                0.825806\
3       O  Nom                              ...      0.031914     2               0.722008                0.825806\
4       A  Nom                     Kollege  ...      0.862838     2               0.722008                0.825806\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...      0.169556     2               0.722008                0.825806\
1088    A  Nom          Sicherheitsagenten  ...      0.006644     2               0.722008                0.825806\
1089    O  Acc                              ...      0.000086     2               0.722008                0.825806\
1090    S  Nom                   Pr\'e4sident  ...      0.995638     2               0.722008                0.825806\
1091    O  Acc                              ...      0.083564     2               0.722008                0.825806\
\
[1092 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...      0.366521     1               0.675676                0.756989\
1       O  Acc                              ...      0.000047     1               0.675676                0.756989\
2       O  Acc                              ...      0.010016     1               0.675676                0.756989\
3       O  Nom                              ...      0.982669     1               0.675676                0.756989\
4       A  Nom                     Kollege  ...      0.770832     1               0.675676                0.756989\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...      0.151089     1               0.675676                0.756989\
1088    A  Nom          Sicherheitsagenten  ...      0.030246     1               0.675676                0.756989\
1089    O  Acc                              ...      0.001558     1               0.675676                0.756989\
1090    S  Nom                   Pr\'e4sident  ...      1.000000     1               0.675676                0.756989\
1091    O  Acc                              ...      0.001728     1               0.675676                0.756989\
\
[1092 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 1092\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 1092 examples to evaluate on.\
     role case animacy        subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0       O  Acc                              ...      0.867700     0               0.722008                0.673118\
1       O  Acc                              ...      0.024404     0               0.722008                0.673118\
2       O  Acc                              ...      0.107195     0               0.722008                0.673118\
3       O  Nom                              ...      0.661772     0               0.722008                0.673118\
4       A  Nom                     Kollege  ...      0.948038     0               0.722008                0.673118\
...   ...  ...     ...                 ...  ...           ...   ...                    ...                     ...\
1087    O  Acc                              ...      0.841254     0               0.722008                0.673118\
1088    A  Nom          Sicherheitsagenten  ...      0.204222     0               0.722008                0.673118\
1089    O  Acc                              ...      0.285660     0               0.722008                0.673118\
1090    S  Nom                   Pr\'e4sident  ...      0.999648     0               0.722008                0.673118\
1091    O  Acc                              ...      0.002152     0               0.722008                0.673118\
\
[1092 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_de_gsd-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_German-GSD-master/de_gsd-ud-train.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.pkl\
There are 2001 relevant tokens, and 2183 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_de_gsd-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 2183/2183 [00:00<00:00, 3342.26it/s]\
Loaded 2182 sentences from disk.\
length of bert outputs 2183\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.997125    12               0.978723                0.872247\
1     S-passive  Nom                    Kosten  ...      0.927176    12               0.978723                0.872247\
2             O  Acc                            ...      0.003781    12               0.978723                0.872247\
3             O  Nom                            ...      0.835795    12               0.978723                0.872247\
4             O  Acc                            ...      0.000004    12               0.978723                0.872247\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999999    12               0.978723                0.872247\
1997          O  Acc                            ...      0.997726    12               0.978723                0.872247\
1998          O  Acc                            ...      0.862798    12               0.978723                0.872247\
1999          A  Nom                   Ibrahim  ...      0.999669    12               0.978723                0.872247\
2000          O  Acc                            ...      0.000002    12               0.978723                0.872247\
\
[2001 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  3.654844e-01    11               0.978723                0.898678\
1     S-passive  Nom                    Kosten  ...  9.987046e-01    11               0.978723                0.898678\
2             O  Acc                            ...  1.612791e-04    11               0.978723                0.898678\
3             O  Nom                            ...  7.589327e-01    11               0.978723                0.898678\
4             O  Acc                            ...  5.454033e-07    11               0.978723                0.898678\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999979e-01    11               0.978723                0.898678\
1997          O  Acc                            ...  3.718614e-05    11               0.978723                0.898678\
1998          O  Acc                            ...  6.581382e-02    11               0.978723                0.898678\
1999          A  Nom                   Ibrahim  ...  9.999849e-01    11               0.978723                0.898678\
2000          O  Acc                            ...  2.664554e-06    11               0.978723                0.898678\
\
[2001 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  6.799214e-02    10               0.978723                0.929515\
1     S-passive  Nom                    Kosten  ...  9.998280e-01    10               0.978723                0.929515\
2             O  Acc                            ...  9.447292e-10    10               0.978723                0.929515\
3             O  Nom                            ...  9.861912e-01    10               0.978723                0.929515\
4             O  Acc                            ...  1.155797e-08    10               0.978723                0.929515\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999952e-01    10               0.978723                0.929515\
1997          O  Acc                            ...  1.656619e-04    10               0.978723                0.929515\
1998          O  Acc                            ...  9.052788e-06    10               0.978723                0.929515\
1999          A  Nom                   Ibrahim  ...  9.999995e-01    10               0.978723                0.929515\
2000          O  Acc                            ...  2.821798e-08    10               0.978723                0.929515\
\
[2001 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.429855e-04     9               0.989362                0.920705\
1     S-passive  Nom                    Kosten  ...  9.961531e-01     9               0.989362                0.920705\
2             O  Acc                            ...  1.043074e-10     9               0.989362                0.920705\
3             O  Nom                            ...  9.997231e-01     9               0.989362                0.920705\
4             O  Acc                            ...  1.398790e-07     9               0.989362                0.920705\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999962e-01     9               0.989362                0.920705\
1997          O  Acc                            ...  2.015564e-08     9               0.989362                0.920705\
1998          O  Acc                            ...  1.402788e-02     9               0.989362                0.920705\
1999          A  Nom                   Ibrahim  ...  9.999999e-01     9               0.989362                0.920705\
2000          O  Acc                            ...  4.988619e-06     9               0.989362                0.920705\
\
[2001 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.941089e-06     8               0.989362                0.929515\
1     S-passive  Nom                    Kosten  ...  9.995456e-01     8               0.989362                0.929515\
2             O  Acc                            ...  9.856596e-08     8               0.989362                0.929515\
3             O  Nom                            ...  1.000000e+00     8               0.989362                0.929515\
4             O  Acc                            ...  1.806743e-08     8               0.989362                0.929515\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999989e-01     8               0.989362                0.929515\
1997          O  Acc                            ...  5.197796e-09     8               0.989362                0.929515\
1998          O  Acc                            ...  8.120721e-07     8               0.989362                0.929515\
1999          A  Nom                   Ibrahim  ...  9.999982e-01     8               0.989362                0.929515\
2000          O  Acc                            ...  2.067894e-06     8               0.989362                0.929515\
\
[2001 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  1.745871e-03     7               0.978723                 0.92511\
1     S-passive  Nom                    Kosten  ...  9.923424e-01     7               0.978723                 0.92511\
2             O  Acc                            ...  3.811907e-10     7               0.978723                 0.92511\
3             O  Nom                            ...  9.999990e-01     7               0.978723                 0.92511\
4             O  Acc                            ...  2.667754e-12     7               0.978723                 0.92511\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999998e-01     7               0.978723                 0.92511\
1997          O  Acc                            ...  3.270762e-10     7               0.978723                 0.92511\
1998          O  Acc                            ...  1.974395e-03     7               0.978723                 0.92511\
1999          A  Nom                   Ibrahim  ...  9.999899e-01     7               0.978723                 0.92511\
2000          O  Acc                            ...  1.385972e-05     7               0.978723                 0.92511\
\
[2001 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  7.379812e-04     6               0.957447                0.920705\
1     S-passive  Nom                    Kosten  ...  3.419719e-01     6               0.957447                0.920705\
2             O  Acc                            ...  2.834426e-08     6               0.957447                0.920705\
3             O  Nom                            ...  9.812577e-01     6               0.957447                0.920705\
4             O  Acc                            ...  8.513046e-11     6               0.957447                0.920705\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999999e-01     6               0.957447                0.920705\
1997          O  Acc                            ...  2.992608e-08     6               0.957447                0.920705\
1998          O  Acc                            ...  3.999666e-02     6               0.957447                0.920705\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     6               0.957447                0.920705\
2000          O  Acc                            ...  5.348786e-03     6               0.957447                0.920705\
\
[2001 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.843674e-03     5               0.968085                0.863436\
1     S-passive  Nom                    Kosten  ...  1.342426e-02     5               0.968085                0.863436\
2             O  Acc                            ...  1.853789e-11     5               0.968085                0.863436\
3             O  Nom                            ...  9.999963e-01     5               0.968085                0.863436\
4             O  Acc                            ...  2.985291e-04     5               0.968085                0.863436\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999849e-01     5               0.968085                0.863436\
1997          O  Acc                            ...  1.016574e-05     5               0.968085                0.863436\
1998          O  Acc                            ...  4.656549e-01     5               0.968085                0.863436\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     5               0.968085                0.863436\
2000          O  Acc                            ...  1.601878e-05     5               0.968085                0.863436\
\
[2001 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...  2.587643e-03     4               0.957447                0.797357\
1     S-passive  Nom                    Kosten  ...  4.256735e-04     4               0.957447                0.797357\
2             O  Acc                            ...  3.535542e-08     4               0.957447                0.797357\
3             O  Nom                            ...  9.991332e-01     4               0.957447                0.797357\
4             O  Acc                            ...  2.703739e-09     4               0.957447                0.797357\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...  9.999999e-01     4               0.957447                0.797357\
1997          O  Acc                            ...  7.109068e-04     4               0.957447                0.797357\
1998          O  Acc                            ...  5.107538e-02     4               0.957447                0.797357\
1999          A  Nom                   Ibrahim  ...  1.000000e+00     4               0.957447                0.797357\
2000          O  Acc                            ...  5.000000e-01     4               0.957447                0.797357\
\
[2001 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.132459     3               0.914894                0.810573\
1     S-passive  Nom                    Kosten  ...      0.000021     3               0.914894                0.810573\
2             O  Acc                            ...      0.000002     3               0.914894                0.810573\
3             O  Nom                            ...      0.999927     3               0.914894                0.810573\
4             O  Acc                            ...      0.000001     3               0.914894                0.810573\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      1.000000     3               0.914894                0.810573\
1997          O  Acc                            ...      0.000525     3               0.914894                0.810573\
1998          O  Acc                            ...      0.118586     3               0.914894                0.810573\
1999          A  Nom                   Ibrahim  ...      1.000000     3               0.914894                0.810573\
2000          O  Acc                            ...      0.000956     3               0.914894                0.810573\
\
[2001 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.999420     2               0.787234                0.674009\
1     S-passive  Nom                    Kosten  ...      0.003399     2               0.787234                0.674009\
2             O  Acc                            ...      0.000135     2               0.787234                0.674009\
3             O  Nom                            ...      0.993799     2               0.787234                0.674009\
4             O  Acc                            ...      0.000488     2               0.787234                0.674009\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999988     2               0.787234                0.674009\
1997          O  Acc                            ...      0.261025     2               0.787234                0.674009\
1998          O  Acc                            ...      0.933865     2               0.787234                0.674009\
1999          A  Nom                   Ibrahim  ...      1.000000     2               0.787234                0.674009\
2000          O  Acc                            ...      0.019372     2               0.787234                0.674009\
\
[2001 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.501076     1               0.765957                 0.69163\
1     S-passive  Nom                    Kosten  ...      0.247555     1               0.765957                 0.69163\
2             O  Acc                            ...      0.050642     1               0.765957                 0.69163\
3             O  Nom                            ...      0.977501     1               0.765957                 0.69163\
4             O  Acc                            ...      0.440687     1               0.765957                 0.69163\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999281     1               0.765957                 0.69163\
1997          O  Acc                            ...      0.884094     1               0.765957                 0.69163\
1998          O  Acc                            ...      0.968248     1               0.765957                 0.69163\
1999          A  Nom                   Ibrahim  ...      0.998553     1               0.765957                 0.69163\
2000          O  Acc                            ...      0.851757     1               0.765957                 0.69163\
\
[2001 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 2001\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4, 'A-aux': 5, 'O-aux': 6, 'S-expletive': 7, 'S-expletive-passive': 8, 'S-passive-aux': 9\}\
There are 2001 examples to evaluate on.\
           role case animacy      subject_word  ... probability_A layer source_test_accuracy_A  source_test_accuracy_O\
0             O  Acc                            ...      0.481857     0               0.712766                0.788546\
1     S-passive  Nom                    Kosten  ...      0.213983     0               0.712766                0.788546\
2             O  Acc                            ...      0.002666     0               0.712766                0.788546\
3             O  Nom                            ...      0.999373     0               0.712766                0.788546\
4             O  Acc                            ...      0.509069     0               0.712766                0.788546\
...         ...  ...     ...               ...  ...           ...   ...                    ...                     ...\
1996          A  Nom          Abgeordnetenhaus  ...      0.999998     0               0.712766                0.788546\
1997          O  Acc                            ...      0.911922     0               0.712766                0.788546\
1998          O  Acc                            ...      0.067823     0               0.712766                0.788546\
1999          A  Nom                   Ibrahim  ...      0.999937     0               0.712766                0.788546\
2000          O  Acc                            ...      0.359644     0               0.712766                0.788546\
\
[2001 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/ko_kaist-ud_he_iahltwiki-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-train.conllu', train_lang_base_path='language_data/UD_Korean-Kaist-master/ko_kaist-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Counts of each role Counter(\{'S': 821, 'O': 678, 'A': 285, 'S-passive': 216\})\
Case counts per role defaultdict(<class 'collections.Counter'>, \{None: Counter(\{None: 47041\}), 'S-passive': Counter(\{None: 216\}), 'A': Counter(\{None: 285\}), 'O': Counter(\{None: 678\}), 'S': Counter(\{None: 821\})\})\
lengths of bert ids etc 1473 1473 1473 1473\
Saving all of the tokens and non-bert stuff to cached_datasets/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1473 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.hdf5\
Running 1473 sentences through BERT. This takes a while\
 35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                                       | 515/1473 [00 35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                       | 518/1473 [00 35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                       | 521/1473 [00 36%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                       | 524/1473 [00 36%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                       | 527/1473 [00 36%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                      | 530/1473 [00 36%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                      | 533/1473 [00 36%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                      | 536/1473 [00 37%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                      | 538/1473 [00 37%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                                      | 541/1473 [00 37%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                      | 544/1473 [00 37%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                     | 547/1473 [00 37%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                                     | 550/1473 [00 38%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                     | 553/1473 [00 38%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                     | 556/1473 [00 38%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                     | 559/1473 [00 38%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                     | 562/1473 [00 38%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                    | 565/1473 [00 39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                    | 568/1473 [00 39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                    | 571/1473 [00 39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                    | 574/1473 [00 39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                    | 577/1473 [00 39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                    | 580/1473 [00 40%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                   | 583/1473 [00 40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                   | 586/1473 [00 40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                   | 589/1473 [00 40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                                   | 592/1473 [00 40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                   | 595/1473 [00 41%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                   | 598/1473 [00 41%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                                  | 601/1473 [00 41%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                  | 604/1473 [00 41%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                                  | 607/1473 [00 41%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                                  | 610/1473 [00 42%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                  | 613/1473 [00 42%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                 | 616/1473 [00 42%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                                 | 619/1473 [00 42%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                 | 622/1473 [00 42%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                 | 625/1473 [00 43%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                                 | 628/1473 [00 43%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                                 | 631/1473 [00 43%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                                | 634/1473 [00 43%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                                | 637/1473 [00 43%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                                | 640/1473 [00 44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                                | 643/1473 [00 44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                                | 646/1473 [00 44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                                | 649/1473 [00 44%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                               | 652/1473 [00 44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                               | 655/1473 [00 45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                               | 658/1473 [00 45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                               | 661/1473 [00 45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                               | 664/1473 [00 45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                               | 667/1473 [00 45%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                              | 670/1473 [00 46%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                              | 673/1473 [00 46%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                              | 676/1473 [00 46%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                              | 679/1473 [00 46%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                              | 682/1473 [00 47%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                              | 685/1473 [00 47%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                             | 688/1473 [00 47%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                             | 691/1473 [00 47%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                             | 693/1473 [00 47%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                             | 696/1473 [00 47%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                             | 699/1473 [00 48%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                             | 702/1473 [00 48%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                            | 705/1473 [00 48%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                            | 708/1473 [00 48%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                            | 711/1473 [00 48%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                            | 714/1473 [00 49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                            | 717/1473 [00 49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                            | 720/1473 [00 49%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                           | 723/1473 [00 49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                           | 726/1473 [00 49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                           | 729/1473 [00 50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                           | 732/1473 [00 50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                           | 735/1473 [00 50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                           | 738/1473 [00 50%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                          | 741/1473 [00 51%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                          | 744/1473 [00 51%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                          | 747/1473 [00 51%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                          | 750/1473 [00 51%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                          | 753/1473 [00 51%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                          | 756/1473 [00 52%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                         | 759/1473 [00 52%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                         | 762/1473 [00 52%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                         | 765/1473 [00 52%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                         | 768/1473 [00 52%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                         | 771/1473 [00 53%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                        | 774/1473 [00 53%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                        | 777/1473 [00 53%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                        | 780/1473 [00 53%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                        | 783/1473 [00 53%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                        | 786/1473 [00 54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                        | 789/1473 [00 54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                       | 792/1473 [00 54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                       | 795/1473 [00 54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                       | 798/1473 [00 54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                       | 801/1473 [00 55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                       | 804/1473 [00 55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                       | 807/1473 [00 55%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                      | 810/1473 [00 55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                      | 813/1473 [00 55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                      | 816/1473 [00 56%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                      | 819/1473 [00 56%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                      | 822/1473 [00 56%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                      | 825/1473 [00 56%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                     | 828/1473 [00 56%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                     | 831/1473 [00 57%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                     | 834/1473 [00 57%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                     | 837/1473 [00 57%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                     | 839/1473 [00 57%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                     | 841/1473 [00 57%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                    | 844/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                    | 847/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                    | 850/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                    | 853/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                    | 856/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                    | 858/1473 [00 58%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                    | 860/1473 [00 59%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                   | 862/1473 [00 59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                   | 865/1473 [00 59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                   | 867/1473 [00 59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                   | 869/1473 [00 59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                   | 872/1473 [00 59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                   | 875/1473 [00 60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                   | 878/1473 [00 60%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                                  | 881/1473 [00 60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                  | 884/1473 [00 60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                  | 887/1473 [00 60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                  | 890/1473 [00 61%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                  | 893/1473 [00 61%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                  | 896/1473 [00 61%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                 | 899/1473 [00 61%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                 | 902/1473 [00 61%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                                 | 905/1473 [00 62%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                 | 908/1473 [00 62%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                 | 911/1473 [00 62%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                                 | 914/1473 [00 62%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                                | 917/1473 [00 62%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                                | 920/1473 [00 63%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                                | 923/1473 [00 63%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                                | 926/1473 [00 63%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                                | 929/1473 [00 63%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                               | 932/1473 [00 63%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                               | 935/1473 [00 64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                               | 938/1473 [00 64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                               | 941/1473 [00 64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                               | 944/1473 [00 64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                               | 947/1473 [00 64%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                              | 950/1473 [00 65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                              | 953/1473 [00 65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                              | 956/1473 [00 65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                              | 958/1473 [00 65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                              | 961/1473 [00 65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                              | 964/1473 [00 66%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                             | 967/1473 [00 66%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                             | 970/1473 [00 66%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                             | 973/1473 [00 66%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                             | 976/1473 [00 66%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                             | 979/1473 [00 67%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                             | 983/1473 [00 67%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                            | 987/1473 [00 67%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                            | 990/1473 [00 67%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                            | 993/1473 [00 68%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                            | 996/1473 [00 68%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                            | 999/1473 [00 68%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                           | 1002/1473 [00 68%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                           | 1005/1473 [00 68%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                           | 1008/1473 [00 69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                           | 1011/1473 [00 69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                          | 1014/1473 [00 69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                          | 1017/1473 [00 69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                          | 1020/1473 [00 69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                          | 1023/1473 [00 70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                          | 1026/1473 [00 70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                          | 1029/1473 [00 70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                         | 1032/1473 [00 70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                         | 1035/1473 [00 70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                         | 1038/1473 [00 71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                         | 1041/1473 [00 71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                         | 1044/1473 [00 71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                         | 1047/1473 [00 71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                        | 1050/1473 [00 71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                        | 1053/1473 [00 72%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                        | 1056/1473 [00 72%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                        | 1059/1473 [00 72%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                        | 1062/1473 [00 72%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                        | 1065/1473 [00 73%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                       | 1068/1473 [00 73%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                       | 1071/1473 [00 73%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                       | 1074/1473 [00 73%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                       | 1077/1473 [00 73%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                       | 1080/1473 [00 74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                       | 1083/1473 [00 74%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                      | 1086/1473 [00 74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                      | 1089/1473 [00 74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                      | 1092/1473 [00 74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                      | 1095/1473 [00 75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                      | 1098/1473 [00 75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                      | 1101/1473 [00 75%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                     | 1104/1473 [00 75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                     | 1107/1473 [00 75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                     | 1110/1473 [00 76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                     | 1113/1473 [00 76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                     | 1116/1473 [00 76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                     | 1119/1473 [00 76%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                    | 1122/1473 [00 76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                    | 1125/1473 [00 77%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                    | 1128/1473 [00 77%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                    | 1131/1473 [00 77%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                    | 1134/1473 [00 77%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                    | 1137/1473 [00 77%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                   | 1140/1473 [00 78%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                   | 1143/1473 [00 78%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                   | 1147/1473 [00 78%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                   | 1150/1473 [00 78%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                   | 1153/1473 [00 78%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                  | 1156/1473 [00 79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                  | 1159/1473 [00 79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                  | 1162/1473 [00 79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                  | 1165/1473 [00 79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                  | 1168/1473 [00 79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                  | 1171/1473 [00 80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                 | 1174/1473 [00 80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                 | 1177/1473 [00 80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0                 | 1180/1473 [00 80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                 | 1183/1473 [00 81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                 | 1186/1473 [00 81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0                 | 1189/1473 [00 81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0                | 1192/1473 [00 81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0                | 1195/1473 [00 81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0                | 1198/1473 [00 82%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0                | 1201/1473 [00 82%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0                | 1204/1473 [00 82%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                | 1207/1473 [00 82%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0               | 1210/1473 [00 82%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0               | 1213/1473 [00 83%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0               | 1216/1473 [00 83%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0               | 1219/1473 [00 83%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0               | 1222/1473 [00 83%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608               | 1225/1473 [00 83%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0              | 1228/1473 [00 84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0              | 1231/1473 [00 84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0              | 1234/1473 [00 84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0              | 1237/1473 [00 84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0              | 1240/1473 [00 84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608              | 1243/1473 [00 85%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0             | 1246/1473 [00 85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0             | 1249/1473 [00 85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0             | 1252/1473 [00 85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0             | 1255/1473 [00 85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0             | 1258/1473 [00 86%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 1261/1473 [00 86%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0            | 1264/1473 [00 86%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0            | 1267/1473 [00 86%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0            | 1270/1473 [00 86%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0            | 1273/1473 [00 87%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0            | 1276/1473 [00 87%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608            | 1279/1473 [00 87%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0           | 1282/1473 [00 87%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0           | 1285/1473 [00 87%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0           | 1288/1473 [00 88%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0           | 1291/1473 [00 88%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0           | 1294/1473 [00 88%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608           | 1297/1473 [00 88%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0          | 1300/1473 [00 88%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0          | 1303/1473 [00 89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0          | 1306/1473 [00 89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0          | 1309/1473 [00 89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0          | 1312/1473 [00 89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608          | 1315/1473 [00 89%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0         | 1318/1473 [00 90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0         | 1321/1473 [00 90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0         | 1324/1473 [01 90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0         | 1327/1473 [01 90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0         | 1330/1473 [01 90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608         | 1333/1473 [01 91%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0        | 1336/1473 [01 91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0        | 1339/1473 [01 91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0        | 1342/1473 [01 91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0        | 1345/1473 [01 92%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0        | 1348/1473 [01 92%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0       | 1351/1473 [01 92%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0       | 1354/1473 [01 92%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0       | 1357/1473 [01 92%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0       | 1360/1473 [01 93%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0       | 1363/1473 [01 93%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0       | 1366/1473 [01 93%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0      | 1369/1473 [01 93%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0      | 1372/1473 [01 93%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0      | 1375/1473 [01 94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0      | 1378/1473 [01 94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0      | 1381/1473 [01 94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0      | 1384/1473 [01 94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0     | 1387/1473 [01 94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0     | 1390/1473 [01 95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0     | 1393/1473 [01 95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0     | 1396/1473 [01 95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0     | 1399/1473 [01 95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0     | 1402/1473 [01 95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0    | 1405/1473 [01 96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0    | 1408/1473 [01 96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0    | 1411/1473 [01 96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0    | 1414/1473 [01 96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0    | 1417/1473 [01 96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608    | 1420/1473 [01 97%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0   | 1423/1473 [01 97%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0   | 1426/1473 [01 97%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0   | 1429/1473 [01 97%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0   | 1432/1473 [01 97%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0   | 1435/1473 [01 98%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608   | 1438/1473 [01 98%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0  | 1441/1473 [01 98%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'86
\f0  | 1444/1473 [01 98%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0  | 1447/1473 [01 98%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0  | 1450/1473 [01 99%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'82
\f0  | 1453/1473 [01 99%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608  | 1456/1473 [01 99%|\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'87
\f0 | 1459/1473 [01 99%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'85
\f0 | 1462/1473 [01 99%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'84
\f0 | 1465/1473 [01100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'83
\f0 | 1468/1473 [01100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 
\f2 \'a8\'81
\f0 | 1471/1473 [01100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1473/1473 [01:06<00:00, 22.15it/s]\
length of bert outputs 1473\
On layer 12\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9186991869918699, 'O': 0.7310278578290106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    12               0.918699               0.731028\
1             A               ...    12               0.918699               0.731028\
2             O               ...    12               0.918699               0.731028\
3             S               ...    12               0.918699               0.731028\
4     S-passive               ...    12               0.918699               0.731028\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    12               0.918699               0.731028\
1996          O               ...    12               0.918699               0.731028\
1997          A               ...    12               0.918699               0.731028\
1998          O               ...    12               0.918699               0.731028\
1999          S               ...    12               0.918699               0.731028\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.7905859750240154\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    11               0.910569               0.790586\
1             A               ...    11               0.910569               0.790586\
2             O               ...    11               0.910569               0.790586\
3             S               ...    11               0.910569               0.790586\
4     S-passive               ...    11               0.910569               0.790586\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    11               0.910569               0.790586\
1996          O               ...    11               0.910569               0.790586\
1997          A               ...    11               0.910569               0.790586\
1998          O               ...    11               0.910569               0.790586\
1999          S               ...    11               0.910569               0.790586\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.8213256484149856\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    10               0.886179               0.821326\
1             A               ...    10               0.886179               0.821326\
2             O               ...    10               0.886179               0.821326\
3             S               ...    10               0.886179               0.821326\
4     S-passive               ...    10               0.886179               0.821326\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    10               0.886179               0.821326\
1996          O               ...    10               0.886179               0.821326\
1997          A               ...    10               0.886179               0.821326\
1998          O               ...    10               0.886179               0.821326\
1999          S               ...    10               0.886179               0.821326\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     9               0.910569               0.855908\
1             A               ...     9               0.910569               0.855908\
2             O               ...     9               0.910569               0.855908\
3             S               ...     9               0.910569               0.855908\
4     S-passive               ...     9               0.910569               0.855908\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     9               0.910569               0.855908\
1996          O               ...     9               0.910569               0.855908\
1997          A               ...     9               0.910569               0.855908\
1998          O               ...     9               0.910569               0.855908\
1999          S               ...     9               0.910569               0.855908\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9105691056910569, 'O': 0.8559077809798271\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     8               0.910569               0.855908\
1             A               ...     8               0.910569               0.855908\
2             O               ...     8               0.910569               0.855908\
3             S               ...     8               0.910569               0.855908\
4     S-passive               ...     8               0.910569               0.855908\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     8               0.910569               0.855908\
1996          O               ...     8               0.910569               0.855908\
1997          A               ...     8               0.910569               0.855908\
1998          O               ...     8               0.910569               0.855908\
1999          S               ...     8               0.910569               0.855908\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8914505283381364\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     7               0.934959               0.891451\
1             A               ...     7               0.934959               0.891451\
2             O               ...     7               0.934959               0.891451\
3             S               ...     7               0.934959               0.891451\
4     S-passive               ...     7               0.934959               0.891451\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     7               0.934959               0.891451\
1996          O               ...     7               0.934959               0.891451\
1997          A               ...     7               0.934959               0.891451\
1998          O               ...     7               0.934959               0.891451\
1999          S               ...     7               0.934959               0.891451\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9349593495934959, 'O': 0.8194044188280499\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     6               0.934959               0.819404\
1             A               ...     6               0.934959               0.819404\
2             O               ...     6               0.934959               0.819404\
3             S               ...     6               0.934959               0.819404\
4     S-passive               ...     6               0.934959               0.819404\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     6               0.934959               0.819404\
1996          O               ...     6               0.934959               0.819404\
1997          A               ...     6               0.934959               0.819404\
1998          O               ...     6               0.934959               0.819404\
1999          S               ...     6               0.934959               0.819404\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9024390243902439, 'O': 0.7425552353506244\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     5               0.902439               0.742555\
1             A               ...     5               0.902439               0.742555\
2             O               ...     5               0.902439               0.742555\
3             S               ...     5               0.902439               0.742555\
4     S-passive               ...     5               0.902439               0.742555\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     5               0.902439               0.742555\
1996          O               ...     5               0.902439               0.742555\
1997          A               ...     5               0.902439               0.742555\
1998          O               ...     5               0.902439               0.742555\
1999          S               ...     5               0.902439               0.742555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8861788617886179, 'O': 0.7300672430355427\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     4               0.886179               0.730067\
1             A               ...     4               0.886179               0.730067\
2             O               ...     4               0.886179               0.730067\
3             S               ...     4               0.886179               0.730067\
4     S-passive               ...     4               0.886179               0.730067\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     4               0.886179               0.730067\
1996          O               ...     4               0.886179               0.730067\
1997          A               ...     4               0.886179               0.730067\
1998          O               ...     4               0.886179               0.730067\
1999          S               ...     4               0.886179               0.730067\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8699186991869918, 'O': 0.7598463016330451\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     3               0.869919               0.759846\
1             A               ...     3               0.869919               0.759846\
2             O               ...     3               0.869919               0.759846\
3             S               ...     3               0.869919               0.759846\
4     S-passive               ...     3               0.869919               0.759846\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     3               0.869919               0.759846\
1996          O               ...     3               0.869919               0.759846\
1997          A               ...     3               0.869919               0.759846\
1998          O               ...     3               0.869919               0.759846\
1999          S               ...     3               0.869919               0.759846\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8536585365853658, 'O': 0.5524542829643888\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     2               0.853659               0.552454\
1             A               ...     2               0.853659               0.552454\
2             O               ...     2               0.853659               0.552454\
3             S               ...     2               0.853659               0.552454\
4     S-passive               ...     2               0.853659               0.552454\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     2               0.853659               0.552454\
1996          O               ...     2               0.853659               0.552454\
1997          A               ...     2               0.853659               0.552454\
1998          O               ...     2               0.853659               0.552454\
1999          S               ...     2               0.853659               0.552454\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.8373983739837398, 'O': 0.5620789220404235\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     1               0.837398               0.562079\
1             A               ...     1               0.837398               0.562079\
2             O               ...     1               0.837398               0.562079\
3             S               ...     1               0.837398               0.562079\
4     S-passive               ...     1               0.837398               0.562079\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     1               0.837398               0.562079\
1996          O               ...     1               0.837398               0.562079\
1997          A               ...     1               0.837398               0.562079\
1998          O               ...     1               0.837398               0.562079\
1999          S               ...     1               0.837398               0.562079\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_ko_kaist-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6422764227642277, 'O': 0.5851780558229066\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-passive': 3\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     0               0.642276               0.585178\
1             A               ...     0               0.642276               0.585178\
2             O               ...     0               0.642276               0.585178\
3             S               ...     0               0.642276               0.585178\
4     S-passive               ...     0               0.642276               0.585178\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     0               0.642276               0.585178\
1996          O               ...     0               0.642276               0.585178\
1997          A               ...     0               0.642276               0.585178\
1998          O               ...     0               0.642276               0.585178\
1999          S               ...     0               0.642276               0.585178\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/pt_cintil-ud_he_iahltwiki-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-train.conllu', train_lang_base_path='language_data/UD_Portuguese-CINTIL-master/pt_cintil-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1473 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1473/1473 [00:01<00:00, 1203.68it/s]\
Loaded 1472 sentences from disk.\
length of bert outputs 1473\
On layer 12\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9315403422982885, 'O': 0.8970099667774086\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    12                0.93154                0.89701\
1             A               ...    12                0.93154                0.89701\
2             O               ...    12                0.93154                0.89701\
3             S               ...    12                0.93154                0.89701\
4     S-passive               ...    12                0.93154                0.89701\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    12                0.93154                0.89701\
1996          O               ...    12                0.93154                0.89701\
1997          A               ...    12                0.93154                0.89701\
1998          O               ...    12                0.93154                0.89701\
1999          S               ...    12                0.93154                0.89701\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9535452322738386, 'O': 0.9346622369878184\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    11               0.953545               0.934662\
1             A               ...    11               0.953545               0.934662\
2             O               ...    11               0.953545               0.934662\
3             S               ...    11               0.953545               0.934662\
4     S-passive               ...    11               0.953545               0.934662\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    11               0.953545               0.934662\
1996          O               ...    11               0.953545               0.934662\
1997          A               ...    11               0.953545               0.934662\
1998          O               ...    11               0.953545               0.934662\
1999          S               ...    11               0.953545               0.934662\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9633251833740831, 'O': 0.9446290143964563\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    10               0.963325               0.944629\
1             A               ...    10               0.963325               0.944629\
2             O               ...    10               0.963325               0.944629\
3             S               ...    10               0.963325               0.944629\
4     S-passive               ...    10               0.963325               0.944629\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    10               0.963325               0.944629\
1996          O               ...    10               0.963325               0.944629\
1997          A               ...    10               0.963325               0.944629\
1998          O               ...    10               0.963325               0.944629\
1999          S               ...    10               0.963325               0.944629\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.960880195599022, 'O': 0.9501661129568106\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     9                0.96088               0.950166\
1             A               ...     9                0.96088               0.950166\
2             O               ...     9                0.96088               0.950166\
3             S               ...     9                0.96088               0.950166\
4     S-passive               ...     9                0.96088               0.950166\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     9                0.96088               0.950166\
1996          O               ...     9                0.96088               0.950166\
1997          A               ...     9                0.96088               0.950166\
1998          O               ...     9                0.96088               0.950166\
1999          S               ...     9                0.96088               0.950166\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.964562569213732\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     8                0.95599               0.964563\
1             A               ...     8                0.95599               0.964563\
2             O               ...     8                0.95599               0.964563\
3             S               ...     8                0.95599               0.964563\
4     S-passive               ...     8                0.95599               0.964563\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     8                0.95599               0.964563\
1996          O               ...     8                0.95599               0.964563\
1997          A               ...     8                0.95599               0.964563\
1998          O               ...     8                0.95599               0.964563\
1999          S               ...     8                0.95599               0.964563\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9559902200488998, 'O': 0.9512735326688815\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     7                0.95599               0.951274\
1             A               ...     7                0.95599               0.951274\
2             O               ...     7                0.95599               0.951274\
3             S               ...     7                0.95599               0.951274\
4     S-passive               ...     7                0.95599               0.951274\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     7                0.95599               0.951274\
1996          O               ...     7                0.95599               0.951274\
1997          A               ...     7                0.95599               0.951274\
1998          O               ...     7                0.95599               0.951274\
1999          S               ...     7                0.95599               0.951274\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9437652811735942, 'O': 0.9678848283499446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     6               0.943765               0.967885\
1             A               ...     6               0.943765               0.967885\
2             O               ...     6               0.943765               0.967885\
3             S               ...     6               0.943765               0.967885\
4     S-passive               ...     6               0.943765               0.967885\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     6               0.943765               0.967885\
1996          O               ...     6               0.943765               0.967885\
1997          A               ...     6               0.943765               0.967885\
1998          O               ...     6               0.943765               0.967885\
1999          S               ...     6               0.943765               0.967885\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9388753056234719, 'O': 0.9335548172757475\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     5               0.938875               0.933555\
1             A               ...     5               0.938875               0.933555\
2             O               ...     5               0.938875               0.933555\
3             S               ...     5               0.938875               0.933555\
4     S-passive               ...     5               0.938875               0.933555\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     5               0.938875               0.933555\
1996          O               ...     5               0.938875               0.933555\
1997          A               ...     5               0.938875               0.933555\
1998          O               ...     5               0.938875               0.933555\
1999          S               ...     5               0.938875               0.933555\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9070904645476773, 'O': 0.9080841638981174\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     4                0.90709               0.908084\
1             A               ...     4                0.90709               0.908084\
2             O               ...     4                0.90709               0.908084\
3             S               ...     4                0.90709               0.908084\
4     S-passive               ...     4                0.90709               0.908084\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     4                0.90709               0.908084\
1996          O               ...     4                0.90709               0.908084\
1997          A               ...     4                0.90709               0.908084\
1998          O               ...     4                0.90709               0.908084\
1999          S               ...     4                0.90709               0.908084\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.8997555012224939, 'O': 0.9136212624584718\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     3               0.899756               0.913621\
1             A               ...     3               0.899756               0.913621\
2             O               ...     3               0.899756               0.913621\
3             S               ...     3               0.899756               0.913621\
4     S-passive               ...     3               0.899756               0.913621\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     3               0.899756               0.913621\
1996          O               ...     3               0.899756               0.913621\
1997          A               ...     3               0.899756               0.913621\
1998          O               ...     3               0.899756               0.913621\
1999          S               ...     3               0.899756               0.913621\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7652811735941321, 'O': 0.858250276854928\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     2               0.765281                0.85825\
1             A               ...     2               0.765281                0.85825\
2             O               ...     2               0.765281                0.85825\
3             S               ...     2               0.765281                0.85825\
4     S-passive               ...     2               0.765281                0.85825\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     2               0.765281                0.85825\
1996          O               ...     2               0.765281                0.85825\
1997          A               ...     2               0.765281                0.85825\
1998          O               ...     2               0.765281                0.85825\
1999          S               ...     2               0.765281                0.85825\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7555012224938875, 'O': 0.8217054263565892\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     1               0.755501               0.821705\
1             A               ...     1               0.755501               0.821705\
2             O               ...     1               0.755501               0.821705\
3             S               ...     1               0.755501               0.821705\
4     S-passive               ...     1               0.755501               0.821705\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     1               0.755501               0.821705\
1996          O               ...     1               0.755501               0.821705\
1997          A               ...     1               0.755501               0.821705\
1998          O               ...     1               0.755501               0.821705\
1999          S               ...     1               0.755501               0.821705\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_pt_cintil-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.6968215158924206, 'O': 0.8073089700996677\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'S': 2, 'S-aux': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     0               0.696822               0.807309\
1             A               ...     0               0.696822               0.807309\
2             O               ...     0               0.696822               0.807309\
3             S               ...     0               0.696822               0.807309\
4     S-passive               ...     0               0.696822               0.807309\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     0               0.696822               0.807309\
1996          O               ...     0               0.696822               0.807309\
1997          A               ...     0               0.696822               0.807309\
1998          O               ...     0               0.696822               0.807309\
1999          S               ...     0               0.696822               0.807309\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/en_gum-ud_he_iahltwiki-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-train.conllu', train_lang_base_path='language_data/UD_English-GUM-master/en_gum-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1473 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1473/1473 [00:01<00:00, 1102.82it/s]\
Loaded 1472 sentences from disk.\
length of bert outputs 1473\
On layer 12\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9609756097560975, 'O': 0.8592896174863388\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    12               0.960976                0.85929\
1             A               ...    12               0.960976                0.85929\
2             O               ...    12               0.960976                0.85929\
3             S               ...    12               0.960976                0.85929\
4     S-passive               ...    12               0.960976                0.85929\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    12               0.960976                0.85929\
1996          O               ...    12               0.960976                0.85929\
1997          A               ...    12               0.960976                0.85929\
1998          O               ...    12               0.960976                0.85929\
1999          S               ...    12               0.960976                0.85929\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.912568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    11               0.980488               0.912568\
1             A               ...    11               0.980488               0.912568\
2             O               ...    11               0.980488               0.912568\
3             S               ...    11               0.980488               0.912568\
4     S-passive               ...    11               0.980488               0.912568\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    11               0.980488               0.912568\
1996          O               ...    11               0.980488               0.912568\
1997          A               ...    11               0.980488               0.912568\
1998          O               ...    11               0.980488               0.912568\
1999          S               ...    11               0.980488               0.912568\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9043715846994536\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    10                0.97561               0.904372\
1             A               ...    10                0.97561               0.904372\
2             O               ...    10                0.97561               0.904372\
3             S               ...    10                0.97561               0.904372\
4     S-passive               ...    10                0.97561               0.904372\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    10                0.97561               0.904372\
1996          O               ...    10                0.97561               0.904372\
1997          A               ...    10                0.97561               0.904372\
1998          O               ...    10                0.97561               0.904372\
1999          S               ...    10                0.97561               0.904372\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.924863387978142\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     9               0.980488               0.924863\
1             A               ...     9               0.980488               0.924863\
2             O               ...     9               0.980488               0.924863\
3             S               ...     9               0.980488               0.924863\
4     S-passive               ...     9               0.980488               0.924863\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     9               0.980488               0.924863\
1996          O               ...     9               0.980488               0.924863\
1997          A               ...     9               0.980488               0.924863\
1998          O               ...     9               0.980488               0.924863\
1999          S               ...     9               0.980488               0.924863\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9853658536585366, 'O': 0.9412568306010929\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     8               0.985366               0.941257\
1             A               ...     8               0.985366               0.941257\
2             O               ...     8               0.985366               0.941257\
3             S               ...     8               0.985366               0.941257\
4     S-passive               ...     8               0.985366               0.941257\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     8               0.985366               0.941257\
1996          O               ...     8               0.985366               0.941257\
1997          A               ...     8               0.985366               0.941257\
1998          O               ...     8               0.985366               0.941257\
1999          S               ...     8               0.985366               0.941257\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9804878048780488, 'O': 0.9398907103825137\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     7               0.980488               0.939891\
1             A               ...     7               0.980488               0.939891\
2             O               ...     7               0.980488               0.939891\
3             S               ...     7               0.980488               0.939891\
4     S-passive               ...     7               0.980488               0.939891\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     7               0.980488               0.939891\
1996          O               ...     7               0.980488               0.939891\
1997          A               ...     7               0.980488               0.939891\
1998          O               ...     7               0.980488               0.939891\
1999          S               ...     7               0.980488               0.939891\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.975609756097561, 'O': 0.9275956284153005\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     6                0.97561               0.927596\
1             A               ...     6                0.97561               0.927596\
2             O               ...     6                0.97561               0.927596\
3             S               ...     6                0.97561               0.927596\
4     S-passive               ...     6                0.97561               0.927596\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     6                0.97561               0.927596\
1996          O               ...     6                0.97561               0.927596\
1997          A               ...     6                0.97561               0.927596\
1998          O               ...     6                0.97561               0.927596\
1999          S               ...     6                0.97561               0.927596\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9707317073170731, 'O': 0.9016393442622951\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     5               0.970732               0.901639\
1             A               ...     5               0.970732               0.901639\
2             O               ...     5               0.970732               0.901639\
3             S               ...     5               0.970732               0.901639\
4     S-passive               ...     5               0.970732               0.901639\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     5               0.970732               0.901639\
1996          O               ...     5               0.970732               0.901639\
1997          A               ...     5               0.970732               0.901639\
1998          O               ...     5               0.970732               0.901639\
1999          S               ...     5               0.970732               0.901639\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9121951219512195, 'O': 0.8265027322404371\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     4               0.912195               0.826503\
1             A               ...     4               0.912195               0.826503\
2             O               ...     4               0.912195               0.826503\
3             S               ...     4               0.912195               0.826503\
4     S-passive               ...     4               0.912195               0.826503\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     4               0.912195               0.826503\
1996          O               ...     4               0.912195               0.826503\
1997          A               ...     4               0.912195               0.826503\
1998          O               ...     4               0.912195               0.826503\
1999          S               ...     4               0.912195               0.826503\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9365853658536586, 'O': 0.8155737704918032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     3               0.936585               0.815574\
1             A               ...     3               0.936585               0.815574\
2             O               ...     3               0.936585               0.815574\
3             S               ...     3               0.936585               0.815574\
4     S-passive               ...     3               0.936585               0.815574\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     3               0.936585               0.815574\
1996          O               ...     3               0.936585               0.815574\
1997          A               ...     3               0.936585               0.815574\
1998          O               ...     3               0.936585               0.815574\
1999          S               ...     3               0.936585               0.815574\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.8585365853658536, 'O': 0.7172131147540983\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     2               0.858537               0.717213\
1             A               ...     2               0.858537               0.717213\
2             O               ...     2               0.858537               0.717213\
3             S               ...     2               0.858537               0.717213\
4     S-passive               ...     2               0.858537               0.717213\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     2               0.858537               0.717213\
1996          O               ...     2               0.858537               0.717213\
1997          A               ...     2               0.858537               0.717213\
1998          O               ...     2               0.858537               0.717213\
1999          S               ...     2               0.858537               0.717213\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7804878048780488, 'O': 0.7090163934426229\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     1               0.780488               0.709016\
1             A               ...     1               0.780488               0.709016\
2             O               ...     1               0.780488               0.709016\
3             S               ...     1               0.780488               0.709016\
4     S-passive               ...     1               0.780488               0.709016\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     1               0.780488               0.709016\
1996          O               ...     1               0.780488               0.709016\
1997          A               ...     1               0.780488               0.709016\
1998          O               ...     1               0.780488               0.709016\
1999          S               ...     1               0.780488               0.709016\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_en_gum-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7902439024390244, 'O': 0.6653005464480874\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     0               0.790244               0.665301\
1             A               ...     0               0.790244               0.665301\
2             O               ...     0               0.790244               0.665301\
3             S               ...     0               0.790244               0.665301\
4     S-passive               ...     0               0.790244               0.665301\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     0               0.790244               0.665301\
1996          O               ...     0               0.790244               0.665301\
1997          A               ...     0               0.790244               0.665301\
1998          O               ...     0               0.790244               0.665301\
1999          S               ...     0               0.790244               0.665301\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/fr_gsd-ud_he_iahltwiki-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-train.conllu', train_lang_base_path='language_data/UD_French-GSD-master/fr_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1473 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1473/1473 [00:01<00:00, 1229.32it/s]\
Loaded 1472 sentences from disk.\
length of bert outputs 1473\
On layer 12\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9293286219081273\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    12               0.958763               0.929329\
1             A               ...    12               0.958763               0.929329\
2             O               ...    12               0.958763               0.929329\
3             S               ...    12               0.958763               0.929329\
4     S-passive               ...    12               0.958763               0.929329\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    12               0.958763               0.929329\
1996          O               ...    12               0.958763               0.929329\
1997          A               ...    12               0.958763               0.929329\
1998          O               ...    12               0.958763               0.929329\
1999          S               ...    12               0.958763               0.929329\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9752650176678446\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    11               0.958763               0.975265\
1             A               ...    11               0.958763               0.975265\
2             O               ...    11               0.958763               0.975265\
3             S               ...    11               0.958763               0.975265\
4     S-passive               ...    11               0.958763               0.975265\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    11               0.958763               0.975265\
1996          O               ...    11               0.958763               0.975265\
1997          A               ...    11               0.958763               0.975265\
1998          O               ...    11               0.958763               0.975265\
1999          S               ...    11               0.958763               0.975265\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    10               0.958763               0.961131\
1             A               ...    10               0.958763               0.961131\
2             O               ...    10               0.958763               0.961131\
3             S               ...    10               0.958763               0.961131\
4     S-passive               ...    10               0.958763               0.961131\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    10               0.958763               0.961131\
1996          O               ...    10               0.958763               0.961131\
1997          A               ...    10               0.958763               0.961131\
1998          O               ...    10               0.958763               0.961131\
1999          S               ...    10               0.958763               0.961131\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     9               0.958763               0.971731\
1             A               ...     9               0.958763               0.971731\
2             O               ...     9               0.958763               0.971731\
3             S               ...     9               0.958763               0.971731\
4     S-passive               ...     9               0.958763               0.971731\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     9               0.958763               0.971731\
1996          O               ...     9               0.958763               0.971731\
1997          A               ...     9               0.958763               0.971731\
1998          O               ...     9               0.958763               0.971731\
1999          S               ...     9               0.958763               0.971731\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9611307420494699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     8               0.958763               0.961131\
1             A               ...     8               0.958763               0.961131\
2             O               ...     8               0.958763               0.961131\
3             S               ...     8               0.958763               0.961131\
4     S-passive               ...     8               0.958763               0.961131\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     8               0.958763               0.961131\
1996          O               ...     8               0.958763               0.961131\
1997          A               ...     8               0.958763               0.961131\
1998          O               ...     8               0.958763               0.961131\
1999          S               ...     8               0.958763               0.961131\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9587628865979382, 'O': 0.9717314487632509\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     7               0.958763               0.971731\
1             A               ...     7               0.958763               0.971731\
2             O               ...     7               0.958763               0.971731\
3             S               ...     7               0.958763               0.971731\
4     S-passive               ...     7               0.958763               0.971731\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     7               0.958763               0.971731\
1996          O               ...     7               0.958763               0.971731\
1997          A               ...     7               0.958763               0.971731\
1998          O               ...     7               0.958763               0.971731\
1999          S               ...     7               0.958763               0.971731\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9681978798586572\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     6               0.938144               0.968198\
1             A               ...     6               0.938144               0.968198\
2             O               ...     6               0.938144               0.968198\
3             S               ...     6               0.938144               0.968198\
4     S-passive               ...     6               0.938144               0.968198\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     6               0.938144               0.968198\
1996          O               ...     6               0.938144               0.968198\
1997          A               ...     6               0.938144               0.968198\
1998          O               ...     6               0.938144               0.968198\
1999          S               ...     6               0.938144               0.968198\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9690721649484536, 'O': 0.9434628975265018\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     5               0.969072               0.943463\
1             A               ...     5               0.969072               0.943463\
2             O               ...     5               0.969072               0.943463\
3             S               ...     5               0.969072               0.943463\
4     S-passive               ...     5               0.969072               0.943463\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     5               0.969072               0.943463\
1996          O               ...     5               0.969072               0.943463\
1997          A               ...     5               0.969072               0.943463\
1998          O               ...     5               0.969072               0.943463\
1999          S               ...     5               0.969072               0.943463\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9175257731958762, 'O': 0.9469964664310954\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     4               0.917526               0.946996\
1             A               ...     4               0.917526               0.946996\
2             O               ...     4               0.917526               0.946996\
3             S               ...     4               0.917526               0.946996\
4     S-passive               ...     4               0.917526               0.946996\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     4               0.917526               0.946996\
1996          O               ...     4               0.917526               0.946996\
1997          A               ...     4               0.917526               0.946996\
1998          O               ...     4               0.917526               0.946996\
1999          S               ...     4               0.917526               0.946996\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9381443298969072, 'O': 0.9363957597173145\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     3               0.938144               0.936396\
1             A               ...     3               0.938144               0.936396\
2             O               ...     3               0.938144               0.936396\
3             S               ...     3               0.938144               0.936396\
4     S-passive               ...     3               0.938144               0.936396\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     3               0.938144               0.936396\
1996          O               ...     3               0.938144               0.936396\
1997          A               ...     3               0.938144               0.936396\
1998          O               ...     3               0.938144               0.936396\
1999          S               ...     3               0.938144               0.936396\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7835051546391752, 'O': 0.7950530035335689\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     2               0.783505               0.795053\
1             A               ...     2               0.783505               0.795053\
2             O               ...     2               0.783505               0.795053\
3             S               ...     2               0.783505               0.795053\
4     S-passive               ...     2               0.783505               0.795053\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     2               0.783505               0.795053\
1996          O               ...     2               0.783505               0.795053\
1997          A               ...     2               0.783505               0.795053\
1998          O               ...     2               0.783505               0.795053\
1999          S               ...     2               0.783505               0.795053\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7938144329896907, 'O': 0.773851590106007\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     1               0.793814               0.773852\
1             A               ...     1               0.793814               0.773852\
2             O               ...     1               0.793814               0.773852\
3             S               ...     1               0.793814               0.773852\
4     S-passive               ...     1               0.793814               0.773852\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     1               0.793814               0.773852\
1996          O               ...     1               0.793814               0.773852\
1997          A               ...     1               0.793814               0.773852\
1998          O               ...     1               0.793814               0.773852\
1999          S               ...     1               0.793814               0.773852\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_fr_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7216494845360825, 'O': 0.8162544169611308\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     0               0.721649               0.816254\
1             A               ...     0               0.721649               0.816254\
2             O               ...     0               0.721649               0.816254\
3             S               ...     0               0.721649               0.816254\
4     S-passive               ...     0               0.721649               0.816254\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     0               0.721649               0.816254\
1996          O               ...     0               0.721649               0.816254\
1997          A               ...     0               0.721649               0.816254\
1998          O               ...     0               0.721649               0.816254\
1999          S               ...     0               0.721649               0.816254\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/de_gsd-ud_he_iahltwiki-ud-train.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-train.conllu', train_lang_base_path='language_data/UD_German-GSD-master/de_gsd-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.pkl\
There are 2000 relevant tokens, and 1473 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-train_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1473/1473 [00:01<00:00, 1117.49it/s]\
Loaded 1472 sentences from disk.\
length of bert outputs 1473\
On layer 12\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.8455598455598455, 'O': 0.8731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    12                0.84556               0.873118\
1             A               ...    12                0.84556               0.873118\
2             O               ...    12                0.84556               0.873118\
3             S               ...    12                0.84556               0.873118\
4     S-passive               ...    12                0.84556               0.873118\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    12                0.84556               0.873118\
1996          O               ...    12                0.84556               0.873118\
1997          A               ...    12                0.84556               0.873118\
1998          O               ...    12                0.84556               0.873118\
1999          S               ...    12                0.84556               0.873118\
\
[2000 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.8803088803088803, 'O': 0.896774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    11               0.880309               0.896774\
1             A               ...    11               0.880309               0.896774\
2             O               ...    11               0.880309               0.896774\
3             S               ...    11               0.880309               0.896774\
4     S-passive               ...    11               0.880309               0.896774\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    11               0.880309               0.896774\
1996          O               ...    11               0.880309               0.896774\
1997          A               ...    11               0.880309               0.896774\
1998          O               ...    11               0.880309               0.896774\
1999          S               ...    11               0.880309               0.896774\
\
[2000 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.915057915057915, 'O': 0.9225806451612903\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...    10               0.915058               0.922581\
1             A               ...    10               0.915058               0.922581\
2             O               ...    10               0.915058               0.922581\
3             S               ...    10               0.915058               0.922581\
4     S-passive               ...    10               0.915058               0.922581\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...    10               0.915058               0.922581\
1996          O               ...    10               0.915058               0.922581\
1997          A               ...    10               0.915058               0.922581\
1998          O               ...    10               0.915058               0.922581\
1999          S               ...    10               0.915058               0.922581\
\
[2000 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9034749034749034, 'O': 0.9096774193548387\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     9               0.903475               0.909677\
1             A               ...     9               0.903475               0.909677\
2             O               ...     9               0.903475               0.909677\
3             S               ...     9               0.903475               0.909677\
4     S-passive               ...     9               0.903475               0.909677\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     9               0.903475               0.909677\
1996          O               ...     9               0.903475               0.909677\
1997          A               ...     9               0.903475               0.909677\
1998          O               ...     9               0.903475               0.909677\
1999          S               ...     9               0.903475               0.909677\
\
[2000 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.8918918918918919, 'O': 0.9139784946236559\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     8               0.891892               0.913978\
1             A               ...     8               0.891892               0.913978\
2             O               ...     8               0.891892               0.913978\
3             S               ...     8               0.891892               0.913978\
4     S-passive               ...     8               0.891892               0.913978\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     8               0.891892               0.913978\
1996          O               ...     8               0.891892               0.913978\
1997          A               ...     8               0.891892               0.913978\
1998          O               ...     8               0.891892               0.913978\
1999          S               ...     8               0.891892               0.913978\
\
[2000 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9111969111969112, 'O': 0.8924731182795699\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     7               0.911197               0.892473\
1             A               ...     7               0.911197               0.892473\
2             O               ...     7               0.911197               0.892473\
3             S               ...     7               0.911197               0.892473\
4     S-passive               ...     7               0.911197               0.892473\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     7               0.911197               0.892473\
1996          O               ...     7               0.911197               0.892473\
1997          A               ...     7               0.911197               0.892473\
1998          O               ...     7               0.911197               0.892473\
1999          S               ...     7               0.911197               0.892473\
\
[2000 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.888030888030888, 'O': 0.8903225806451613\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     6               0.888031               0.890323\
1             A               ...     6               0.888031               0.890323\
2             O               ...     6               0.888031               0.890323\
3             S               ...     6               0.888031               0.890323\
4     S-passive               ...     6               0.888031               0.890323\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     6               0.888031               0.890323\
1996          O               ...     6               0.888031               0.890323\
1997          A               ...     6               0.888031               0.890323\
1998          O               ...     6               0.888031               0.890323\
1999          S               ...     6               0.888031               0.890323\
\
[2000 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.803088803088803, 'O': 0.8408602150537634\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     5               0.803089                0.84086\
1             A               ...     5               0.803089                0.84086\
2             O               ...     5               0.803089                0.84086\
3             S               ...     5               0.803089                0.84086\
4     S-passive               ...     5               0.803089                0.84086\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     5               0.803089                0.84086\
1996          O               ...     5               0.803089                0.84086\
1997          A               ...     5               0.803089                0.84086\
1998          O               ...     5               0.803089                0.84086\
1999          S               ...     5               0.803089                0.84086\
\
[2000 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.8262548262548263, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     4               0.826255               0.756989\
1             A               ...     4               0.826255               0.756989\
2             O               ...     4               0.826255               0.756989\
3             S               ...     4               0.826255               0.756989\
4     S-passive               ...     4               0.826255               0.756989\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     4               0.826255               0.756989\
1996          O               ...     4               0.826255               0.756989\
1997          A               ...     4               0.826255               0.756989\
1998          O               ...     4               0.826255               0.756989\
1999          S               ...     4               0.826255               0.756989\
\
[2000 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.806949806949807, 'O': 0.7870967741935484\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     3                0.80695               0.787097\
1             A               ...     3                0.80695               0.787097\
2             O               ...     3                0.80695               0.787097\
3             S               ...     3                0.80695               0.787097\
4     S-passive               ...     3                0.80695               0.787097\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     3                0.80695               0.787097\
1996          O               ...     3                0.80695               0.787097\
1997          A               ...     3                0.80695               0.787097\
1998          O               ...     3                0.80695               0.787097\
1999          S               ...     3                0.80695               0.787097\
\
[2000 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.8258064516129032\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     2               0.722008               0.825806\
1             A               ...     2               0.722008               0.825806\
2             O               ...     2               0.722008               0.825806\
3             S               ...     2               0.722008               0.825806\
4     S-passive               ...     2               0.722008               0.825806\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     2               0.722008               0.825806\
1996          O               ...     2               0.722008               0.825806\
1997          A               ...     2               0.722008               0.825806\
1998          O               ...     2               0.722008               0.825806\
1999          S               ...     2               0.722008               0.825806\
\
[2000 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.6756756756756757, 'O': 0.7569892473118279\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     1               0.675676               0.756989\
1             A               ...     1               0.675676               0.756989\
2             O               ...     1               0.675676               0.756989\
3             S               ...     1               0.675676               0.756989\
4     S-passive               ...     1               0.675676               0.756989\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     1               0.675676               0.756989\
1996          O               ...     1               0.675676               0.756989\
1997          A               ...     1               0.675676               0.756989\
1998          O               ...     1               0.675676               0.756989\
1999          S               ...     1               0.675676               0.756989\
\
[2000 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_de_gsd-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.722007722007722, 'O': 0.6731182795698925\}\
Examples # 2000\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-aux': 4, 'S-expletive': 5, 'S-passive': 6\}\
There are 2000 examples to evaluate on.\
           role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0     S-passive               ...     0               0.722008               0.673118\
1             A               ...     0               0.722008               0.673118\
2             O               ...     0               0.722008               0.673118\
3             S               ...     0               0.722008               0.673118\
4     S-passive               ...     0               0.722008               0.673118\
...         ...  ...     ...  ...   ...                    ...                    ...\
1995          A               ...     0               0.722008               0.673118\
1996          O               ...     0               0.722008               0.673118\
1997          A               ...     0               0.722008               0.673118\
1998          O               ...     0               0.722008               0.673118\
1999          S               ...     0               0.722008               0.673118\
\
[2000 rows x 11 columns]\
To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\
args: Namespace(all_major_cases=False, average_embs=False, balance=True, erg_abs=False, nom_acc=False, only_ao=True, output_fn='latest_run/he_iahltwiki-ud_he_iahltwiki-ud-test.conllu_0', reeval_src_test=False, seed=0, test_lang_fn='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud-test.conllu', train_lang_base_path='language_data/UD_Hebrew-IAHLTwiki-master/he_iahltwiki-ud')\
Just set the seed to 0\
Classifiers already trained!\
Loading the dest test set, with limit 2000\
Loading all of the tokens and non-bert stuff from cached_datasets/all_features_aso_exps_he_iahltwiki-ud-test_aso_unbalanced_2000.pkl\
There are 624 relevant tokens, and 393 overall sentences\
Bert vectors file is cached_bert_vectors/all_features_aso_exps_he_iahltwiki-ud-test_aso_unbalanced_2000.hdf5\
[Loading from disk]: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 393/393 [00:00<00:00, 1549.36it/s]\
Loaded 392 sentences from disk.\
length of bert outputs 393\
On layer 12\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_12_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8722466960352423\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...    12               0.978723               0.872247\
1      O               ...    12               0.978723               0.872247\
2      A               ...    12               0.978723               0.872247\
3      O               ...    12               0.978723               0.872247\
4      O               ...    12               0.978723               0.872247\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...    12               0.978723               0.872247\
620    S               ...    12               0.978723               0.872247\
621    S               ...    12               0.978723               0.872247\
622    S               ...    12               0.978723               0.872247\
623    O               ...    12               0.978723               0.872247\
\
[624 rows x 11 columns]\
On layer 11\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_11_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.8986784140969163\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...    11               0.978723               0.898678\
1      O               ...    11               0.978723               0.898678\
2      A               ...    11               0.978723               0.898678\
3      O               ...    11               0.978723               0.898678\
4      O               ...    11               0.978723               0.898678\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...    11               0.978723               0.898678\
620    S               ...    11               0.978723               0.898678\
621    S               ...    11               0.978723               0.898678\
622    S               ...    11               0.978723               0.898678\
623    O               ...    11               0.978723               0.898678\
\
[624 rows x 11 columns]\
On layer 10\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_10_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9295154185022027\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...    10               0.978723               0.929515\
1      O               ...    10               0.978723               0.929515\
2      A               ...    10               0.978723               0.929515\
3      O               ...    10               0.978723               0.929515\
4      O               ...    10               0.978723               0.929515\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...    10               0.978723               0.929515\
620    S               ...    10               0.978723               0.929515\
621    S               ...    10               0.978723               0.929515\
622    S               ...    10               0.978723               0.929515\
623    O               ...    10               0.978723               0.929515\
\
[624 rows x 11 columns]\
On layer 9\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_9_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.920704845814978\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     9               0.989362               0.920705\
1      O               ...     9               0.989362               0.920705\
2      A               ...     9               0.989362               0.920705\
3      O               ...     9               0.989362               0.920705\
4      O               ...     9               0.989362               0.920705\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     9               0.989362               0.920705\
620    S               ...     9               0.989362               0.920705\
621    S               ...     9               0.989362               0.920705\
622    S               ...     9               0.989362               0.920705\
623    O               ...     9               0.989362               0.920705\
\
[624 rows x 11 columns]\
On layer 8\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_8_exproles!\
src_test_accuracy: \{'A': 0.9893617021276596, 'O': 0.9295154185022027\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     8               0.989362               0.929515\
1      O               ...     8               0.989362               0.929515\
2      A               ...     8               0.989362               0.929515\
3      O               ...     8               0.989362               0.929515\
4      O               ...     8               0.989362               0.929515\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     8               0.989362               0.929515\
620    S               ...     8               0.989362               0.929515\
621    S               ...     8               0.989362               0.929515\
622    S               ...     8               0.989362               0.929515\
623    O               ...     8               0.989362               0.929515\
\
[624 rows x 11 columns]\
On layer 7\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_7_exproles!\
src_test_accuracy: \{'A': 0.9787234042553191, 'O': 0.9251101321585903\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     7               0.978723                0.92511\
1      O               ...     7               0.978723                0.92511\
2      A               ...     7               0.978723                0.92511\
3      O               ...     7               0.978723                0.92511\
4      O               ...     7               0.978723                0.92511\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     7               0.978723                0.92511\
620    S               ...     7               0.978723                0.92511\
621    S               ...     7               0.978723                0.92511\
622    S               ...     7               0.978723                0.92511\
623    O               ...     7               0.978723                0.92511\
\
[624 rows x 11 columns]\
On layer 6\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_6_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.920704845814978\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     6               0.957447               0.920705\
1      O               ...     6               0.957447               0.920705\
2      A               ...     6               0.957447               0.920705\
3      O               ...     6               0.957447               0.920705\
4      O               ...     6               0.957447               0.920705\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     6               0.957447               0.920705\
620    S               ...     6               0.957447               0.920705\
621    S               ...     6               0.957447               0.920705\
622    S               ...     6               0.957447               0.920705\
623    O               ...     6               0.957447               0.920705\
\
[624 rows x 11 columns]\
On layer 5\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_5_exproles!\
src_test_accuracy: \{'A': 0.9680851063829787, 'O': 0.8634361233480177\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     5               0.968085               0.863436\
1      O               ...     5               0.968085               0.863436\
2      A               ...     5               0.968085               0.863436\
3      O               ...     5               0.968085               0.863436\
4      O               ...     5               0.968085               0.863436\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     5               0.968085               0.863436\
620    S               ...     5               0.968085               0.863436\
621    S               ...     5               0.968085               0.863436\
622    S               ...     5               0.968085               0.863436\
623    O               ...     5               0.968085               0.863436\
\
[624 rows x 11 columns]\
On layer 4\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_4_exproles!\
src_test_accuracy: \{'A': 0.9574468085106383, 'O': 0.7973568281938326\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     4               0.957447               0.797357\
1      O               ...     4               0.957447               0.797357\
2      A               ...     4               0.957447               0.797357\
3      O               ...     4               0.957447               0.797357\
4      O               ...     4               0.957447               0.797357\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     4               0.957447               0.797357\
620    S               ...     4               0.957447               0.797357\
621    S               ...     4               0.957447               0.797357\
622    S               ...     4               0.957447               0.797357\
623    O               ...     4               0.957447               0.797357\
\
[624 rows x 11 columns]\
On layer 3\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_3_exproles!\
src_test_accuracy: \{'A': 0.9148936170212766, 'O': 0.8105726872246696\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     3               0.914894               0.810573\
1      O               ...     3               0.914894               0.810573\
2      A               ...     3               0.914894               0.810573\
3      O               ...     3               0.914894               0.810573\
4      O               ...     3               0.914894               0.810573\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     3               0.914894               0.810573\
620    S               ...     3               0.914894               0.810573\
621    S               ...     3               0.914894               0.810573\
622    S               ...     3               0.914894               0.810573\
623    O               ...     3               0.914894               0.810573\
\
[624 rows x 11 columns]\
On layer 2\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_2_exproles!\
src_test_accuracy: \{'A': 0.7872340425531915, 'O': 0.6740088105726872\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     2               0.787234               0.674009\
1      O               ...     2               0.787234               0.674009\
2      A               ...     2               0.787234               0.674009\
3      O               ...     2               0.787234               0.674009\
4      O               ...     2               0.787234               0.674009\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     2               0.787234               0.674009\
620    S               ...     2               0.787234               0.674009\
621    S               ...     2               0.787234               0.674009\
622    S               ...     2               0.787234               0.674009\
623    O               ...     2               0.787234               0.674009\
\
[624 rows x 11 columns]\
On layer 1\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_1_exproles!\
src_test_accuracy: \{'A': 0.7659574468085106, 'O': 0.6916299559471366\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     1               0.765957                0.69163\
1      O               ...     1               0.765957                0.69163\
2      A               ...     1               0.765957                0.69163\
3      O               ...     1               0.765957                0.69163\
4      O               ...     1               0.765957                0.69163\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     1               0.765957                0.69163\
620    S               ...     1               0.765957                0.69163\
621    S               ...     1               0.765957                0.69163\
622    S               ...     1               0.765957                0.69163\
623    O               ...     1               0.765957                0.69163\
\
[624 rows x 11 columns]\
On layer 0\
Loaded case classifier from classifiers/aso_he_iahltwiki-ud_0_ao_balanced_0_exproles!\
src_test_accuracy: \{'A': 0.7127659574468085, 'O': 0.788546255506608\}\
Examples # 624\
labeldict \{'A': 0, 'O': 1, 'A-passive': 2, 'S': 3, 'S-passive': 4\}\
There are 624 examples to evaluate on.\
    role case animacy  ... layer source_test_accuracy_A source_test_accuracy_O\
0      O               ...     0               0.712766               0.788546\
1      O               ...     0               0.712766               0.788546\
2      A               ...     0               0.712766               0.788546\
3      O               ...     0               0.712766               0.788546\
4      O               ...     0               0.712766               0.788546\
..   ...  ...     ...  ...   ...                    ...                    ...\
619    S               ...     0               0.712766               0.788546\
620    S               ...     0               0.712766               0.788546\
621    S               ...     0               0.712766               0.788546\
622    S               ...     0               0.712766               0.788546\
623    O               ...     0               0.712766               0.788546\
\
[624 rows x 11 columns]\
(erg_nom) Nick deep-subjecthood-custom % }